{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6465cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 0.54593 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williams/anaconda3/envs/egpt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train acc 33.46%  test acc 42.11%\n",
      "Epoch 02: train acc 46.32%  test acc 49.63%\n",
      "Epoch 03: train acc 52.18%  test acc 51.40%\n",
      "Epoch 04: train acc 55.91%  test acc 58.05%\n",
      "Epoch 05: train acc 58.67%  test acc 60.36%\n",
      "Epoch 06: train acc 60.84%  test acc 62.72%\n",
      "Epoch 07: train acc 62.39%  test acc 63.98%\n",
      "Epoch 08: train acc 64.09%  test acc 66.32%\n",
      "Epoch 09: train acc 65.35%  test acc 66.15%\n",
      "Epoch 10: train acc 66.41%  test acc 65.86%\n",
      "Base model sparsity: 0.0000\n",
      "Layer-wise EMP summary:\n",
      " Linear(id=6060751744)          | out= 384 in= 128 | avg N_eff=86.7 | sparsity= 32.2%\n",
      "Linear(id=6060746848)          | out= 128 in= 128 | avg N_eff=81.6 | sparsity= 36.3%\n",
      "Linear(id=6060751216)          | out= 256 in= 128 | avg N_eff=86.8 | sparsity= 32.2%\n",
      "Linear(id=6060747376)          | out= 128 in= 256 | avg N_eff=165.7 | sparsity= 35.3%\n",
      "Linear(id=6060752320)          | out= 384 in= 128 | avg N_eff=88.9 | sparsity= 30.6%\n",
      "Linear(id=6060750976)          | out= 128 in= 128 | avg N_eff=87.1 | sparsity= 32.0%\n",
      "Linear(id=6124831024)          | out= 256 in= 128 | avg N_eff=88.6 | sparsity= 30.8%\n",
      "Linear(id=6124839568)          | out= 128 in= 256 | avg N_eff=168.3 | sparsity= 34.3%\n",
      "Linear(id=6124834864)          | out= 384 in= 128 | avg N_eff=88.3 | sparsity= 31.0%\n",
      "Linear(id=6124833184)          | out= 128 in= 128 | avg N_eff=87.0 | sparsity= 32.0%\n",
      "Linear(id=6124836688)          | out= 256 in= 128 | avg N_eff=88.0 | sparsity= 31.2%\n",
      "Linear(id=6124833616)          | out= 128 in= 256 | avg N_eff=166.9 | sparsity= 34.8%\n",
      "Linear(id=6124837072)          | out= 384 in= 128 | avg N_eff=87.8 | sparsity= 31.4%\n",
      "Linear(id=6124837744)          | out= 128 in= 128 | avg N_eff=86.2 | sparsity= 32.7%\n",
      "Linear(id=6124837120)          | out= 256 in= 128 | avg N_eff=88.8 | sparsity= 30.6%\n",
      "Linear(id=6124830784)          | out= 128 in= 256 | avg N_eff=163.9 | sparsity= 36.0%\n",
      "Linear(id=6124832512)          | out=  10 in= 128 | avg N_eff=87.7 | sparsity= 31.5%\n",
      "EMP sparsity: 0.3209\n",
      "EMP-pruned ViT — test acc 64.93%  (loss 0.9986)\n"
     ]
    }
   ],
   "source": [
    "# ===== Tiny Vision Transformer (CIFAR-10) + Activation-EMP pruning =====\n",
    "import math, copy, time, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --------- Reuse pruning utils (paste from the first block or import them) ----------\n",
    "\n",
    "@torch.no_grad()\n",
    "def model_sparsity(model: nn.Module) -> float:\n",
    "    total, zeros = 0, 0\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.dim() >= 2 and 'weight' in n:\n",
    "            total += p.numel()\n",
    "            zeros += (p == 0).sum().item()\n",
    "    return zeros / max(total, 1)\n",
    "\n",
    "# ---- Step 1: collect E[|x|] (per in-feature) for each Linear via forward hooks\n",
    "@torch.no_grad()\n",
    "def collect_input_magnitudes(model: nn.Module,\n",
    "                             data_loader,\n",
    "                             device,\n",
    "                             num_batches: int = 10):\n",
    "    model.eval()\n",
    "    # list Linear modules in traversal order\n",
    "    linear_list = [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
    "    sums = []\n",
    "    counts = []\n",
    "    handles = []\n",
    "\n",
    "    for m in linear_list:\n",
    "        sums.append(torch.zeros(m.in_features, device=device))\n",
    "        counts.append(torch.tensor(0, device=device))\n",
    "\n",
    "    index_of = {id(m): i for i, m in enumerate(linear_list)}\n",
    "\n",
    "    def hook_fn(module, inputs, output):\n",
    "        idx = index_of[id(module)]\n",
    "        x = inputs[0].detach()\n",
    "        # flatten all leading dims except last: [..., in_features]\n",
    "        x2d = x.flatten(0, -2)  # (B*..., in_features)\n",
    "        sums[idx] += x2d.abs().sum(dim=0)\n",
    "        counts[idx] += x2d.shape[0]\n",
    "\n",
    "    for m in linear_list:\n",
    "        handles.append(m.register_forward_hook(hook_fn))\n",
    "\n",
    "    seen = 0\n",
    "    for data, target in data_loader:\n",
    "        data = data.to(device)\n",
    "        _ = model(data)\n",
    "        seen += 1\n",
    "        if seen >= num_batches:\n",
    "            break\n",
    "\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "\n",
    "    mags = [s / torch.clamp(c.float(), min=1.0) for s, c in zip(sums, counts)]\n",
    "    # Return in the same order as linear_list\n",
    "    return linear_list, mags\n",
    "\n",
    "# ---- Step 2: build the activation-aware mask from N_eff on |W| * E|x|\n",
    "@torch.no_grad()\n",
    "def get_linear_mask_emp(module: nn.Linear,\n",
    "                        in_mag: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        module: nn.Linear with weight shape [out, in]\n",
    "        in_mag: tensor [in] = E[|x|] for this module's input\n",
    "    Returns:\n",
    "        mask (bool) with same shape as weight\n",
    "        neff_row (long) length = out_features\n",
    "    \"\"\"\n",
    "    W = module.weight.data  # [out, in]\n",
    "    # contributions per input to each neuron:\n",
    "    contrib = W.abs() * in_mag.unsqueeze(0)  # [out, in]\n",
    "    row_sum = contrib.sum(dim=1, keepdim=True).clamp(min=1e-12)\n",
    "    norm = contrib / row_sum                 # \\hat c_ji\n",
    "\n",
    "    neff = torch.floor(1.0 / norm.pow(2).sum(dim=1)).clamp(min=1, max=W.shape[1]).long()  # [out]\n",
    "\n",
    "    # sort each row by importance and keep top neff[j]\n",
    "    _, idx = torch.sort(norm, dim=1, descending=True)\n",
    "    out, in_ = W.shape\n",
    "    ranks = torch.arange(in_, device=W.device).unsqueeze(0).expand(out, in_)\n",
    "    keep_sorted = ranks < neff.unsqueeze(1)   # [out, in] (sorted order)\n",
    "\n",
    "    mask = torch.zeros_like(W, dtype=torch.bool)\n",
    "    mask.scatter_(1, idx, keep_sorted)\n",
    "    return mask, neff\n",
    "\n",
    "# ---- Step 3: prune with EMP (optional L1 row re-normalization)\n",
    "@torch.no_grad()\n",
    "def prune_model_emp_activation(model: nn.Module,\n",
    "                               calib_loader,\n",
    "                               device,\n",
    "                               num_calib_batches: int = 10,\n",
    "                               renormalize: bool = False):\n",
    "    pruned = copy.deepcopy(model).to(device)\n",
    "    linear_list, mags = collect_input_magnitudes(pruned, calib_loader, device, num_batches=num_calib_batches)\n",
    "\n",
    "    layer_neff = {}\n",
    "    for lin, mu in zip(linear_list, mags):\n",
    "        W = lin.weight.data\n",
    "        old_row_l1 = W.abs().sum(dim=1, keepdim=True)\n",
    "        mask, neff = get_linear_mask_emp(lin, mu.to(W.device))\n",
    "        # apply mask\n",
    "        W.mul_(mask)\n",
    "        if renormalize:\n",
    "            new_row_l1 = W.abs().sum(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "            scale = old_row_l1 / new_row_l1\n",
    "            W.mul_(scale)\n",
    "        layer_neff[id(lin)] = {\n",
    "            \"name\": getattr(lin, \"_emp_name\", None),\n",
    "            \"neff_row\": neff.detach().cpu(),\n",
    "            \"avg_neff\": neff.float().mean().item(),\n",
    "            \"in_features\": W.shape[1],\n",
    "            \"out_features\": W.shape[0],\n",
    "            \"layer_sparsity\": float((~mask).sum().item() / mask.numel())\n",
    "        }\n",
    "\n",
    "    return pruned, layer_neff\n",
    "\n",
    "# ---- Helper: pretty summary\n",
    "def summarize_emp(layer_neff_dict):\n",
    "    lines = []\n",
    "    for k, v in layer_neff_dict.items():\n",
    "        name = v.get(\"name\") or f\"Linear(id={k})\"\n",
    "        lines.append(\n",
    "            f\"{name:30s} | out={v['out_features']:4d} in={v['in_features']:4d} \"\n",
    "            f\"| avg N_eff={v['avg_neff']:.1f} | sparsity={v['layer_sparsity']*100:5.1f}%\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ---- (Optional) attach names to ease reading\n",
    "def tag_linear_names(model: nn.Module):\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m._emp_name = name\n",
    "\n",
    "\n",
    "# --------- Model: Patch embedding, Encoder block, and ViT head ----------\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=128):\n",
    "        super().__init__()\n",
    "        assert img_size % patch_size == 0\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "    def forward(self, x):                   # x: [B,3,H,W]\n",
    "        x = self.proj(x)                    # [B,embed,H/P,W/P]\n",
    "        x = x.flatten(2).transpose(1, 2)    # [B, N, embed]\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, p=0.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
    "        self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, attn_drop=0.0, proj_drop=0.0):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):         # x: [B, N, C]\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
    "        q, k, v = qkv.unbind(dim=2)     # each: [B, N, H, D]\n",
    "        q = q.transpose(1, 2)            # [B, H, N, D]\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale        # [B,H,N,N]\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        out = attn @ v                                       # [B,H,N,D]\n",
    "        out = out.transpose(1, 2).reshape(B, N, C)           # [B,N,C]\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "        return out\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=2.0, drop=0.0, attn_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = SelfAttention(dim, num_heads, attn_drop, drop)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp  = MLP(dim, int(dim * mlp_ratio), p=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class TinyViT(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_chans=3,\n",
    "                 num_classes=10, embed_dim=128, depth=4, num_heads=4, mlp_ratio=2.0, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.patch = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
    "        self.pos = nn.Parameter(torch.zeros(1, self.patch.num_patches, embed_dim))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(embed_dim, num_heads, mlp_ratio, drop, drop) for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch(x) + self.pos\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)         # global average over patches (no class token)\n",
    "        x = self.head(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# --------- Data: CIFAR-10 (32x32) ----------\n",
    "def get_cifar10_loaders(batch_size=128, num_workers=2):\n",
    "    train_tf = T.Compose([\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ])\n",
    "    test_tf = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ])\n",
    "    train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tf)\n",
    "    test  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tf)\n",
    "    return (DataLoader(train, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True),\n",
    "            DataLoader(test,  batch_size=256,       shuffle=False, num_workers=num_workers, pin_memory=True))\n",
    "\n",
    "# --------- Train / Test ----------\n",
    "def train_one_epoch(model, loader, opt, device):\n",
    "    model.train()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = F.nll_loss(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_loss/total, 100*correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = F.nll_loss(out, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_loss/total, 100*correct/total\n",
    "\n",
    "# --------- Run everything ----------\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0); random.seed(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_loader, test_loader = get_cifar10_loaders()\n",
    "    model = TinyViT(embed_dim=128, depth=4, num_heads=4, mlp_ratio=2.0, drop=0.1).to(device)\n",
    "\n",
    "    print(\"Params:\", sum(p.numel() for p in model.parameters())/1e6, \"M\")\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "    # Train a few epochs (tune as desired)\n",
    "    epochs = 10\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, opt, device)\n",
    "        te_loss, te_acc = evaluate(model, test_loader, device)\n",
    "        print(f\"Epoch {ep:02d}: train acc {tr_acc:5.2f}%  test acc {te_acc:5.2f}%\")\n",
    "\n",
    "    base_sparsity = model_sparsity(model)\n",
    "    print(f\"Base model sparsity: {base_sparsity:.4f}\")\n",
    "\n",
    "    # Activation-EMP prune using a small calibration slice of the train set\n",
    "    pruned, layer_neff = prune_model_emp_activation(\n",
    "        model, calib_loader=train_loader, device=device, num_calib_batches=8, renormalize=False\n",
    "    )\n",
    "    print(\"Layer-wise EMP summary:\\n\", summarize_emp(layer_neff))\n",
    "    print(f\"EMP sparsity: {model_sparsity(pruned):.4f}\")\n",
    "\n",
    "    # Evaluate pruned model\n",
    "    te_loss, te_acc = evaluate(pruned, test_loader, device)\n",
    "    print(f\"EMP-pruned ViT — test acc {te_acc:5.2f}%  (loss {te_loss:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6166602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline ViT…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train acc 14.53%  test acc 23.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02: train acc 28.50%  test acc 37.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03: train acc 39.15%  test acc 45.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04: train acc 45.27%  test acc 52.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05: train acc 49.40%  test acc 55.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06: train acc 51.95%  test acc 58.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07: train acc 53.92%  test acc 58.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08: train acc 55.99%  test acc 61.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09: train acc 57.34%  test acc 62.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train acc 58.90%  test acc 62.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train acc 60.26%  test acc 64.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train acc 61.53%  test acc 64.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train acc 62.29%  test acc 66.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train acc 63.49%  test acc 67.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train acc 64.27%  test acc 67.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train acc 64.81%  test acc 67.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train acc 65.64%  test acc 69.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train acc 65.95%  test acc 69.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train acc 66.15%  test acc 69.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train acc 66.50%  test acc 69.45%\n",
      "Base model sparsity: 0.0000\n",
      "        Baseline ViT — test acc 69.45%  (loss 0.9024)\n",
      "Layer-wise Row-NEFF summary:\n",
      " blocks.0.attn.qkv              | avg N_eff=133.3 | sparsity= 36.5%\n",
      " blocks.0.attn.proj             | avg N_eff=134.0 | sparsity= 36.2%\n",
      " blocks.0.mlp.fc1               | avg N_eff=133.7 | sparsity= 36.4%\n",
      " blocks.0.mlp.fc2               | avg N_eff=534.3 | sparsity= 36.4%\n",
      " blocks.1.attn.qkv              | avg N_eff=133.4 | sparsity= 36.4%\n",
      " blocks.1.attn.proj             | avg N_eff=133.4 | sparsity= 36.5%\n",
      " blocks.1.mlp.fc1               | avg N_eff=133.4 | sparsity= 36.4%\n",
      " blocks.1.mlp.fc2               | avg N_eff=535.4 | sparsity= 36.3%\n",
      " blocks.2.attn.qkv              | avg N_eff=133.5 | sparsity= 36.4%\n",
      " blocks.2.attn.proj             | avg N_eff=133.7 | sparsity= 36.4%\n",
      " blocks.2.mlp.fc1               | avg N_eff=133.5 | sparsity= 36.4%\n",
      " blocks.2.mlp.fc2               | avg N_eff=534.7 | sparsity= 36.4%\n",
      " blocks.3.attn.qkv              | avg N_eff=133.2 | sparsity= 36.5%\n",
      " blocks.3.attn.proj             | avg N_eff=133.4 | sparsity= 36.4%\n",
      " blocks.3.mlp.fc1               | avg N_eff=133.8 | sparsity= 36.3%\n",
      " blocks.3.mlp.fc2               | avg N_eff=534.6 | sparsity= 36.4%\n",
      " blocks.4.attn.qkv              | avg N_eff=133.5 | sparsity= 36.4%\n",
      " blocks.4.attn.proj             | avg N_eff=133.6 | sparsity= 36.4%\n",
      " blocks.4.mlp.fc1               | avg N_eff=133.3 | sparsity= 36.5%\n",
      " blocks.4.mlp.fc2               | avg N_eff=535.0 | sparsity= 36.4%\n",
      " blocks.5.attn.qkv              | avg N_eff=134.2 | sparsity= 36.2%\n",
      " blocks.5.attn.proj             | avg N_eff=133.7 | sparsity= 36.4%\n",
      " blocks.5.mlp.fc1               | avg N_eff=133.7 | sparsity= 36.3%\n",
      " blocks.5.mlp.fc2               | avg N_eff=534.3 | sparsity= 36.4%\n",
      " head                           | avg N_eff=140.4 | sparsity= 34.2%\n",
      "\n",
      "Row-NEFF sparsity: 0.3629\n",
      " Row-NEFF pruned ViT — test acc 69.27%  (loss 0.9064)\n",
      "Layer-wise EMP (activation) summary:\n",
      " blocks.0.attn.qkv              | avg N_eff=157.1 | sparsity= 38.6%\n",
      " blocks.0.attn.proj             | avg N_eff=137.4 | sparsity= 46.3%\n",
      " blocks.0.mlp.fc1               | avg N_eff=158.9 | sparsity= 37.9%\n",
      " blocks.0.mlp.fc2               | avg N_eff=600.4 | sparsity= 41.4%\n",
      " blocks.1.attn.qkv              | avg N_eff=159.5 | sparsity= 37.7%\n",
      " blocks.1.attn.proj             | avg N_eff=150.7 | sparsity= 41.1%\n",
      " blocks.1.mlp.fc1               | avg N_eff=159.7 | sparsity= 37.6%\n",
      " blocks.1.mlp.fc2               | avg N_eff=616.1 | sparsity= 39.8%\n",
      " blocks.2.attn.qkv              | avg N_eff=158.9 | sparsity= 37.9%\n",
      " blocks.2.attn.proj             | avg N_eff=152.4 | sparsity= 40.5%\n",
      " blocks.2.mlp.fc1               | avg N_eff=159.3 | sparsity= 37.8%\n",
      " blocks.2.mlp.fc2               | avg N_eff=604.3 | sparsity= 41.0%\n",
      " blocks.3.attn.qkv              | avg N_eff=156.8 | sparsity= 38.7%\n",
      " blocks.3.attn.proj             | avg N_eff=151.0 | sparsity= 41.0%\n",
      " blocks.3.mlp.fc1               | avg N_eff=158.8 | sparsity= 38.0%\n",
      " blocks.3.mlp.fc2               | avg N_eff=607.8 | sparsity= 40.6%\n",
      " blocks.4.attn.qkv              | avg N_eff=157.0 | sparsity= 38.7%\n",
      " blocks.4.attn.proj             | avg N_eff=152.5 | sparsity= 40.4%\n",
      " blocks.4.mlp.fc1               | avg N_eff=157.9 | sparsity= 38.3%\n",
      " blocks.4.mlp.fc2               | avg N_eff=610.2 | sparsity= 40.4%\n",
      " blocks.5.attn.qkv              | avg N_eff=157.6 | sparsity= 38.4%\n",
      " blocks.5.attn.proj             | avg N_eff=152.5 | sparsity= 40.4%\n",
      " blocks.5.mlp.fc1               | avg N_eff=158.2 | sparsity= 38.2%\n",
      " blocks.5.mlp.fc2               | avg N_eff=605.4 | sparsity= 40.9%\n",
      " head                           | avg N_eff=159.4 | sparsity= 37.7%\n",
      "\n",
      "EMP sparsity: 0.3917\n",
      "      EMP-pruned ViT — test acc 69.49%  (loss 0.9129)\n"
     ]
    }
   ],
   "source": [
    "# EMP vs Row-NEFF pruning on a Vision Transformer (CIFAR-10)\n",
    "# -----------------------------------------------------------\n",
    "# Requirements: torch, torchvision, numpy\n",
    "# Optional: tqdm (for pretty progress bars)\n",
    "\n",
    "import math, os, copy, random, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    TQDM = True\n",
    "except Exception:\n",
    "    TQDM = False\n",
    "\n",
    "# -----------------------------\n",
    "# Utils\n",
    "# -----------------------------\n",
    "def set_seed(seed: int = 1337):\n",
    "    random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def accuracy(logits, targets):\n",
    "    pred = logits.argmax(dim=1)\n",
    "    return (pred == targets).float().mean().item()\n",
    "\n",
    "def count_zeros(t: torch.Tensor) -> int:\n",
    "    return (t == 0).sum().item()\n",
    "\n",
    "def model_sparsity(model: nn.Module) -> float:\n",
    "    total = 0; zeros = 0\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.ndim >= 2 and \"weight\" in n:\n",
    "            total += p.numel()\n",
    "            zeros += count_zeros(p)\n",
    "    return zeros / max(total, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# Data\n",
    "# -----------------------------\n",
    "def get_cifar10(batch_size=128, num_workers=2):\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std  = (0.2470, 0.2435, 0.2616)\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.4,0.4,0.4,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    test_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "    train = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_tf)\n",
    "    test  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_tf)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=256, shuffle=False,\n",
    "                                              num_workers=num_workers, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# -----------------------------\n",
    "# ViT components\n",
    "# -----------------------------\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Stochastic depth (per sample)\"\"\"\n",
    "    def __init__(self, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training: return x\n",
    "        keep = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        rnd = x.new_empty(shape).bernoulli_(keep)\n",
    "        return x * rnd / keep\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=256):\n",
    "        super().__init__()\n",
    "        assert img_size % patch_size == 0\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "    def forward(self, x):\n",
    "        # B, C, H, W -> B, N, D\n",
    "        x = self.proj(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x); x = self.act(x); x = self.drop(x)\n",
    "        x = self.fc2(x); x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=True, attn_drop=0.0, proj_drop=0.0):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x)                         # B, N, 3C\n",
    "        qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim).permute(2,0,3,1,4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]          # each: B, heads, N, head_dim\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = (attn @ v).transpose(1,2).reshape(B,N,C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.0, attn_drop=0.0, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path1 = DropPath(drop_path)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = MLP(dim, int(dim * mlp_ratio), drop=drop)\n",
    "        self.drop_path2 = DropPath(drop_path)\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path1(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path2(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_size=32, patch=4, in_chans=3, num_classes=10,\n",
    "                 emb_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, drop=0.1, attn_drop=0.1, drop_path=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbed(img_size, patch, in_chans, emb_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + num_patches, emb_dim))\n",
    "        self.pos_drop = nn.Dropout(drop)\n",
    "\n",
    "        dpr = torch.linspace(0, drop_path, steps=depth).tolist()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(emb_dim, num_heads, mlp_ratio, drop, attn_drop, dpr[i])\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(emb_dim)\n",
    "        self.head = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        self.apply(self._init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.patch_embed(x)\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        for blk in self.blocks: x = blk(x)\n",
    "        x = self.norm(x)[:, 0]      # CLS\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Eval\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class TrainCfg:\n",
    "    epochs: int = 20\n",
    "    lr: float = 3e-4\n",
    "    warmup_epochs: int = 2\n",
    "    weight_decay: float = 0.05\n",
    "    label_smoothing: float = 0.1\n",
    "    grad_clip: float = 1.0\n",
    "\n",
    "def train_one_epoch(model, loader, opt, device, loss_fn, scheduler=None):\n",
    "    model.train()\n",
    "    total_acc, total = 0.0, 0\n",
    "    iterator = tqdm(loader, leave=False) if TQDM else loader\n",
    "    for x, y in iterator:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        if scheduler is not None and hasattr(scheduler, \"optimizer\"):  # for some schedulers\n",
    "            pass\n",
    "        if math.isfinite(cfg.grad_clip): nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "        opt.step()\n",
    "        total_acc += accuracy(logits.detach(), y) * x.size(0)\n",
    "        total += x.size(0)\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    return total_acc / max(total,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, loss_fn=None):\n",
    "    model.eval()\n",
    "    total_acc, total, total_loss = 0.0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        total_acc += accuracy(logits, y) * x.size(0)\n",
    "        if loss_fn is not None:\n",
    "            total_loss += F.cross_entropy(logits, y, reduction=\"sum\").item()\n",
    "        total += x.size(0)\n",
    "    return total_acc / max(total,1), (total_loss / max(total,1) if loss_fn is not None else None)\n",
    "\n",
    "# -----------------------------\n",
    "# NEFF helpers (weights-only)\n",
    "# -----------------------------\n",
    "def per_row_neff_from_weight(W: torch.Tensor) -> torch.Tensor:\n",
    "    # W: [out, in]\n",
    "    absW = W.abs()\n",
    "    denom = absW.sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "    p = absW / denom\n",
    "    neff = torch.floor(1.0 / p.pow(2).sum(dim=1)).clamp(min=1, max=W.size(1))\n",
    "    return neff  # [out]\n",
    "\n",
    "def get_linear_mask_per_row(module: nn.Linear) -> torch.Tensor:\n",
    "    W = module.weight.data\n",
    "    out, in_ = W.shape\n",
    "    absW = W.abs()\n",
    "    p = absW / absW.sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "    neff = torch.floor(1.0 / (p.pow(2).sum(dim=1))).clamp_(min=1, max=in_).long()\n",
    "    contrib = absW  # weight-only\n",
    "    _, idx = torch.sort(contrib, dim=1, descending=True)\n",
    "    ranks = torch.arange(in_, device=W.device).unsqueeze(0).expand_as(idx)\n",
    "    mask_sorted = ranks < neff.unsqueeze(1)\n",
    "    mask = torch.zeros_like(W, dtype=torch.bool)\n",
    "    mask.scatter_(1, idx, mask_sorted)\n",
    "    return mask\n",
    "\n",
    "def prune_model_neff_per_row(model: nn.Module, renorm=False) -> Tuple[nn.Module, List[Tuple[str,float,float]]]:\n",
    "    pruned = copy.deepcopy(model)\n",
    "    layer_info = []\n",
    "    with torch.no_grad():\n",
    "        for name, m in pruned.named_modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                mask = get_linear_mask_per_row(m).to(m.weight.device)\n",
    "                m.weight.mul_(mask)\n",
    "                if renorm:\n",
    "                    s = m.weight.abs().sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "                    m.weight.div_(s)  # optional\n",
    "                neff = per_row_neff_from_weight(m.weight).float().mean().item()\n",
    "                layer_spars = count_zeros(m.weight) / m.weight.numel()\n",
    "                layer_info.append((f\"{name}\", neff, layer_spars))\n",
    "    return pruned, layer_info\n",
    "\n",
    "# -----------------------------\n",
    "# Activation-aware EMP (W*x)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def collect_activation_means(model: nn.Module, loader, device, num_batches=8) -> Dict[nn.Linear, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    For each Linear layer, estimate E[|x|] per input channel (last dim).\n",
    "    \"\"\"\n",
    "    stats_sum: Dict[nn.Linear, torch.Tensor] = {}\n",
    "    stats_count: Dict[nn.Linear, int] = {}\n",
    "    handles = []\n",
    "\n",
    "    def register(m: nn.Linear):\n",
    "        stats_sum[m] = torch.zeros(m.in_features, device=device)\n",
    "        stats_count[m] = 0\n",
    "        def hook(mod, inp, out):\n",
    "            x = inp[0].detach()\n",
    "            # reduce over all dims except the last (feature dim)\n",
    "            red_dims = tuple(range(x.dim() - 1))\n",
    "            s = x.abs().sum(dim=red_dims)\n",
    "            stats_sum[mod] += s\n",
    "            stats_count[mod] += (x.numel() // mod.in_features)\n",
    "        return m.register_forward_hook(hook)\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            handles.append(register(m))\n",
    "\n",
    "    model.eval()\n",
    "    it = iter(loader)\n",
    "    for b in range(num_batches):\n",
    "        try:\n",
    "            x, _ = next(it)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        model(x)\n",
    "\n",
    "    for h in handles: h.remove()\n",
    "    means = {m: (stats_sum[m] / max(stats_count[m],1)).clamp_min(1e-12) for m in stats_sum.keys()}\n",
    "    return means\n",
    "\n",
    "def prune_model_emp_activation(model: nn.Module, calib_loader, device, num_calib_batches=8, renorm=False):\n",
    "    \"\"\"\n",
    "    Activation-aware EMP pruning: keep, in each row, the top N_eff elements using\n",
    "    p_ij ∝ |w_ij| * E[|x_j|]\n",
    "    \"\"\"\n",
    "    pruned = copy.deepcopy(model).to(device)\n",
    "    act_means = collect_activation_means(pruned, calib_loader, device, num_batches=num_calib_batches)\n",
    "\n",
    "    layer_info = []\n",
    "    with torch.no_grad():\n",
    "        for name, m in pruned.named_modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                W = m.weight.data\n",
    "                out, in_ = W.shape\n",
    "                mean_abs_x = act_means[m]  # [in]\n",
    "                contrib = W.abs() * mean_abs_x.unsqueeze(0)  # [out, in]\n",
    "                denom = contrib.sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "                p = contrib / denom\n",
    "                neff = torch.floor(1.0 / p.pow(2).sum(dim=1)).clamp_(min=1, max=in_).long()\n",
    "\n",
    "                # build mask row-wise\n",
    "                _, idx = torch.sort(contrib, dim=1, descending=True)\n",
    "                ranks = torch.arange(in_, device=W.device).unsqueeze(0).expand_as(idx)\n",
    "                mask_sorted = ranks < neff.unsqueeze(1)\n",
    "                mask = torch.zeros_like(W, dtype=torch.bool)\n",
    "                mask.scatter_(1, idx, mask_sorted)\n",
    "                m.weight.mul_(mask)\n",
    "                if renorm:\n",
    "                    s = m.weight.abs().sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "                    m.weight.div_(s)\n",
    "\n",
    "                # report\n",
    "                avg_neff = neff.float().mean().item()\n",
    "                layer_spars = count_zeros(m.weight) / m.weight.numel()\n",
    "                layer_info.append((f\"{name}\", avg_neff, layer_spars))\n",
    "\n",
    "    return pruned, layer_info\n",
    "\n",
    "# -----------------------------\n",
    "# Reporting helpers\n",
    "# -----------------------------\n",
    "def print_layerwise_report(tag: str, layer_info: List[Tuple[str,float,float]]):\n",
    "    print(f\"Layer-wise {tag} summary:\")\n",
    "    for (name, neff_avg, spars) in layer_info:\n",
    "        # try to parse layer shape for nicer printing if possible\n",
    "        print(f\" {name:<30s} | avg N_eff={neff_avg:5.1f} | sparsity={100*spars:5.1f}%\")\n",
    "    print()\n",
    "\n",
    "def eval_and_report(model, test_loader, device, tag=\"Model\"):\n",
    "    acc, loss = evaluate(model, test_loader, device, loss_fn=True)\n",
    "    print(f\"{tag:>20s} — test acc {acc*100:5.2f}%  (loss {loss:.4f})\")\n",
    "    return acc, loss\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(123)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_loader, test_loader = get_cifar10(batch_size=128, num_workers=2)\n",
    "\n",
    "    # Build a stronger baseline than a tiny ViT, but still lightweight\n",
    "    model = ViT(\n",
    "        img_size=32, patch=4, emb_dim=256, depth=6, num_heads=8,\n",
    "        mlp_ratio=4.0, drop=0.1, attn_drop=0.1, drop_path=0.1, num_classes=10\n",
    "    ).to(device)\n",
    "\n",
    "    cfg = TrainCfg(epochs=20, lr=3e-4, warmup_epochs=2, weight_decay=0.05, label_smoothing=0.1, grad_clip=1.0)\n",
    "\n",
    "    # Optimizer + cosine schedule with warmup\n",
    "    opt = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=(0.9, 0.999))\n",
    "    sched = CosineAnnealingLR(opt, T_max=cfg.epochs - cfg.warmup_epochs)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)\n",
    "\n",
    "    # Warmup loop\n",
    "    warmup_steps = cfg.warmup_epochs * len(train_loader)\n",
    "    if warmup_steps > 0:\n",
    "        warmup_factor = cfg.lr / warmup_steps\n",
    "        cur_lr = 0.0\n",
    "\n",
    "    print(\"Training baseline ViT…\")\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        if epoch <= cfg.warmup_epochs:\n",
    "            # linear warmup\n",
    "            for pgroup in opt.param_groups:\n",
    "                pgroup[\"lr\"] = min(cfg.lr, (epoch-1)*len(train_loader)*warmup_factor + warmup_factor*1)\n",
    "        else:\n",
    "            # cosine decay after warmup\n",
    "            pass\n",
    "\n",
    "        train_acc = train_one_epoch(model, train_loader, opt, device, loss_fn,\n",
    "                                    scheduler=None if epoch <= cfg.warmup_epochs else sched)\n",
    "        test_acc, _ = evaluate(model, test_loader, device, loss_fn=True)\n",
    "        print(f\"Epoch {epoch:02d}: train acc {train_acc*100:5.2f}%  test acc {test_acc*100:5.2f}%\")\n",
    "\n",
    "    print(f\"Base model sparsity: {model_sparsity(model):.4f}\")\n",
    "    base_acc, base_loss = eval_and_report(model, test_loader, device, tag=\"Baseline ViT\")\n",
    "\n",
    "    # ---------------- Row-NEFF pruning ----------------\n",
    "    row_model, row_info = prune_model_neff_per_row(model, renorm=False)\n",
    "    print_layerwise_report(\"Row-NEFF\", row_info)\n",
    "    print(f\"Row-NEFF sparsity: {model_sparsity(row_model):.4f}\")\n",
    "    eval_and_report(row_model, test_loader, device, tag=\"Row-NEFF pruned ViT\")\n",
    "\n",
    "    # --------------- Activation EMP (W*x) -------------\n",
    "    # Use a small calibration subset (first few batches of training loader)\n",
    "    emp_model, emp_info = prune_model_emp_activation(model, calib_loader=train_loader,\n",
    "                                                     device=device, num_calib_batches=8, renorm=False)\n",
    "    print_layerwise_report(\"EMP (activation)\", emp_info)\n",
    "    print(f\"EMP sparsity: {model_sparsity(emp_model):.4f}\")\n",
    "    eval_and_report(emp_model, test_loader, device, tag=\"EMP-pruned ViT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668f8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
