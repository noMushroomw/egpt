{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6928d5d9",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f4c39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "folder = \"test_results\"\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1c176",
   "metadata": {},
   "source": [
    "# track neff and sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f41656e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pc(module:nn.Module, beta=1.0, method='magnitude') -> torch.Tensor:\n",
    "    x = module.weight.data\n",
    "    output_size, input_size = x.shape\n",
    "    if method == 'mean':\n",
    "        x = x - x.mean(dim=0, keepdim=True)\n",
    "    x_norm = torch.abs(x) / torch.sum(torch.abs(x), dim=0, keepdim=True)\n",
    "    neff = 1/torch.sum((x_norm ** 2), dim=0, keepdim=True).squeeze(0)\n",
    "    r_neff = torch.floor(beta * neff)\n",
    "    \n",
    "    _, indices = torch.sort(x_norm, dim=0, descending=True)\n",
    "    range_tensor = torch.arange(output_size, device=x.device).unsqueeze(0).expand(input_size, -1).T\n",
    "    sorted_mask = range_tensor < r_neff\n",
    "    \n",
    "    mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "    mask.scatter_(0, indices, sorted_mask)\n",
    "    return mask, torch.floor(neff)\n",
    "\n",
    "def model_pc(model, renormalize=False, beta=1.0, method='magnitude'):\n",
    "    model = copy.deepcopy(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            mask, neff = mask_pc(module, beta=beta, method=method)\n",
    "            mask = mask.to(module.weight.device)\n",
    "            with torch.no_grad():\n",
    "                pre = module.weight.abs().sum(dim=0, keepdim=True)\n",
    "                module.weight *= mask\n",
    "                if renormalize:\n",
    "                    post = module.weight.abs().sum(dim=0, keepdim=True)\n",
    "                    module.weight.mul_(pre / post)\n",
    "    return model, neff\n",
    "\n",
    "def mask_pr(module:nn.Module, beta=1.0, method='magnitude') -> torch.Tensor:\n",
    "    x = module.weight.data\n",
    "    output_size, input_size = x.shape\n",
    "    if method == 'mean':\n",
    "        x = x - x.mean(dim=1, keepdim=True)\n",
    "    x_norm = torch.abs(x) / torch.sum(torch.abs(x), dim=1, keepdim=True)\n",
    "    neff = 1/torch.sum((x_norm ** 2), dim=1, keepdim=True).squeeze(0)\n",
    "    r_neff = torch.floor(beta * neff)\n",
    "    \n",
    "    _, indices = torch.sort(x_norm, dim=1, descending=True)\n",
    "    range_tensor = torch.arange(input_size, device=x.device).unsqueeze(0).expand(output_size, -1)\n",
    "    sorted_mask = range_tensor < r_neff\n",
    "\n",
    "    mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "    mask.scatter_(1, indices, sorted_mask)\n",
    "    return mask, torch.floor(neff)\n",
    "\n",
    "def model_pr(model, renormalize=False, beta=1.0, method='magnitude'):\n",
    "    model = copy.deepcopy(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            mask, neff = mask_pr(module, beta=beta, method=method)\n",
    "            mask = mask.to(module.weight.device)\n",
    "            with torch.no_grad():\n",
    "                pre = module.weight.abs().sum(dim=1, keepdim=True)\n",
    "                module.weight *= mask\n",
    "                if renormalize:\n",
    "                    post = module.weight.abs().sum(dim=1, keepdim=True)\n",
    "                    module.weight.mul_(pre / post)\n",
    "    return model, neff\n",
    "\n",
    "def mask_block(module:nn.Module, beta=1.0, method='magnitude') -> torch.Tensor:\n",
    "    x = module.weight.data\n",
    "    x = x.view(-1)\n",
    "    if method == 'mean':\n",
    "        x = x - torch.mean(x)\n",
    "    x_norm = torch.abs(x) / torch.sum(torch.abs(x))\n",
    "    neff = 1/torch.sum((x_norm ** 2))\n",
    "    r_neff = torch.floor(beta * neff)\n",
    "\n",
    "    _, indices = torch.sort(x_norm, descending=True)\n",
    "    range_tensor = torch.arange(len(x), device=x.device)\n",
    "    sorted_mask = range_tensor < r_neff\n",
    "\n",
    "    mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "    mask.scatter_(0, indices, sorted_mask)\n",
    "    mask = mask.view_as(module.weight)\n",
    "    return mask, torch.floor(neff)\n",
    "\n",
    "def model_block(model, renormalize=False, beta=1.0, method='magnitude'):\n",
    "    model = copy.deepcopy(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            mask, neff = mask_block(module, beta=beta, method=method)\n",
    "            mask = mask.to(module.weight.device)\n",
    "            with torch.no_grad():\n",
    "                pre = module.weight.abs().sum(dim=0, keepdim=True)\n",
    "                module.weight *= mask\n",
    "                if renormalize:\n",
    "                    post = module.weight.abs().sum(dim=0, keepdim=True)\n",
    "                    module.weight.mul_(pre / post)\n",
    "    return model, neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b6b3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sparsity(model):\n",
    "    \"\"\"Calculate the sparsity of the model\"\"\"\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_params += param.numel()\n",
    "            zero_params += torch.sum(param == 0).item()\n",
    "    \n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity\n",
    "\n",
    "def per_layer_neff(model):\n",
    "    \"\"\"Calculate the effective parameters (Neff) per layer\"\"\"\n",
    "    neff = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            layer_neff = torch.sum(param != 0).item()\n",
    "            neff[name] = layer_neff\n",
    "    return neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4bb1a99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Dataset setup\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model class with optional dropout\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}'\n",
    "                  f'accuracy: {100. * correct / len(train_loader.dataset):.2f}%')\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Testing function\n",
    "def test(model, device, test_loader, times=1):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    for _ in range(times):\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(test_loss)\n",
    "\n",
    "    if times == 1:\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, '\n",
    "              f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n",
    "\n",
    "        return test_loss, accuracy\n",
    "    \n",
    "    else:\n",
    "        return loss_list, accuracy_list, sum(accuracy_list)/times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5444f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.336801\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.740998\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.975131\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.596963\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.400453\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.388022\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.276383\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.491773\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.401877\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.248366\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.430661\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.119773\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.366112\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.342821\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.206117\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.256983\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.343654\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.298574\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.135859\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.262895\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.318111\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.180471\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.269334\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.202193\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.137717\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299121\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.304826\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.179927\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.337010\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.212953\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.210862\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.319052\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.073951\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.103585\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.033072\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.056638\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.078244\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.126657\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.126536\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087746\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.019918\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.108123\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.109212\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.045144\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.045881\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.045384\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.014527\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.067094\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.105807\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.041174\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.054957\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.047012\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.041959\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.051921\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.021517\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.003562\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.013777\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.023011\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.048203\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.007227\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.126901\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.011657\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.030574\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.052003\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.020894\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304248\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.412852\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.399190\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.105077\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.294292\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.132620\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.270185\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.071319\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.057532\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.089060\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.055600\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.140800\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.079185\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.027230\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.042466\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.013548\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035789\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.044104\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.131261\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.134299\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.130614\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.109895\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.014530\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.064510\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.053031\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.016075\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.097032\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.015942\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.059870\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.071253\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.075258\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.043145\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.057754\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.068445\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.045399\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.018945\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.008947\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.018511\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.078820\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.117087\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.008489\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.059892\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.014117\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.022026\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.099770\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.012794\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.015960\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.003045\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.006607\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006102\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.009051\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.003092\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.006835\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.057926\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.112015\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000722\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.013751\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.070793\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.018219\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.061468\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.025059\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.033334\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.007009\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.114242\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.003740\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.007029\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.005666\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.012634\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.057717\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.039357\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.001220\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.002869\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.003533\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.003897\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.012181\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306667\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.189133\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.198737\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.430116\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.050039\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.303409\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.131737\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.080853\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.169661\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.023931\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.061088\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.185309\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.130157\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.014587\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.011300\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014500\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.018533\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.077154\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.150608\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.126512\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.033514\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.005074\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.028828\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.062078\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.017036\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.030474\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.004825\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.035943\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.070917\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.017290\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001604\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.043697\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.098056\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.067630\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.013199\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.019478\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.047693\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.015751\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.009935\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.037038\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.035734\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001831\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.013125\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.045538\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.002205\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.011823\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.007184\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.023901\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.083045\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.047369\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.004838\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.003184\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.028028\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.007265\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.006952\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.023918\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.003941\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.014730\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.125627\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.004011\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.004544\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.005059\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.012505\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.039477\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.007158\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.013612\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.014953\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.016384\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.003137\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.030371\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.032758\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001372\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.007574\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.008795\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.044726\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.083279\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.003522\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000925\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.024596\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.018930\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.044172\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000092\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.076588\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.039178\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.031234\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.004001\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.021407\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.001426\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.043484\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000791\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.052982\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.016959\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.026752\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000390\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.006066\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.062768\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.002219\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.002112\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.018383\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.018298\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303976\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.325536\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.080480\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.075344\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.074129\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.037831\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.047361\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.053022\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.029623\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.101543\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.027969\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.076280\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.154679\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.178399\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.136256\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.034201\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.053711\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.125197\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.191160\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.195514\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.002586\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.162177\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.038154\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.030621\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.009365\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.024477\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.020900\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.011967\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001078\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.121331\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.013666\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.012296\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.031017\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001679\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009822\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000966\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.108762\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.019234\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.020998\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.011794\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000284\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.006975\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.047728\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.025421\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.196110\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.019116\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.003146\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.142360\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.003494\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.013496\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.016081\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.001592\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.001139\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.023194\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.000194\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.049868\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.017571\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.000708\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.004633\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.007750\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000512\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.001060\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.023297\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.020186\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.121146\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.075396\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.000878\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.051134\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.002829\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.024782\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.079686\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.000616\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000605\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000139\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001152\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000185\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.015427\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000117\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.051842\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000316\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.029628\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.018317\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.164576\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.001878\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.008324\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000115\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.038778\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000149\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.003378\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.088736\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.067423\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.005022\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.008146\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.171249\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.023009\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.002920\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000009\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000274\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.003667\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000020\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.010068\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.001760\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.004464\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.112383\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000191\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000522\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.029845\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000343\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000010\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000247\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.001986\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.091017\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.011539\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.004045\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000081\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.082673\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.008172\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000033\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.012096\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000170\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000005\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000150\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.050742\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000495\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000354\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000022\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000040\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000175\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000873\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000204\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000311\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000100\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.002889\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000111\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.005658\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.008060\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.006217\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000195\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.012330\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000011\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000381\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.038377\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000228\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000467\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309554\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.376872\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.072315\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.041158\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.121441\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.044660\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.154412\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.021115\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.082620\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.018888\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.166938\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001028\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.022394\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.228825\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.063918\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.028815\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.077155\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.018321\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.059954\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.075035\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.005778\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.101058\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.043399\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.006159\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.002906\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.100983\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.074435\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.011074\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.042527\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.036516\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.020740\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.020642\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025181\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.007905\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.049208\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.006632\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001341\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.063939\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.082869\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.004031\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001014\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.097976\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.007902\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.006041\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000359\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.093313\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.003251\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001099\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.023723\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000493\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000990\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.013621\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.002415\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.018405\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.006573\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000201\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.000389\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.027063\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.012459\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.019294\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.076399\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.014313\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.092434\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.005764\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.006712\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.030194\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.038186\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.023406\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.013654\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.010657\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.004436\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.104952\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001653\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000594\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.019118\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000286\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.090560\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.007755\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000034\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.051943\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.001219\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.023016\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.027054\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.001362\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000338\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000172\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.001796\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.004264\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000773\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000336\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.005653\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.003268\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.309010\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000221\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.008428\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.122797\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.005712\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000888\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.012354\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.030924\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.027775\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.129333\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.011180\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.002172\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000013\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.001085\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.012779\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.045266\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000079\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.009540\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000135\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.004797\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.007420\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.002716\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.010891\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.069947\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000002\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.058907\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.031136\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000641\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000062\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.266711\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.049314\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.013563\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.003304\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.007240\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.075447\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000047\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.002971\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.004185\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.022584\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.027037\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.014820\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.001560\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000302\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.001203\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000020\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.005378\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.071574\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.001239\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.006612\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.010060\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000241\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.079751\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.014203\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000318\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000343\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000040\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.008184\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.005958\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.009531\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000093\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000672\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000057\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000081\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000087\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000093\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000406\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000065\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.047036\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000174\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.269685\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.004404\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000436\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.012610\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.019939\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.029362\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000002\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000022\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.117640\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000707\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000404\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.055652\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.193713\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000144\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.075874\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000019\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000011\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000971\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000097\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.018757\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000119\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.037863\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000007\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000009\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000398\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.002290\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000259\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000355\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000005\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000390\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000334\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000219\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000864\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.001183\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.002827\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.016017\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000069\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.590781\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.002256\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000228\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000537\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000239\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000388\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.043741\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.001617\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000012\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.001380\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000271\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.055359\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.002388\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.005658\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000476\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000869\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000009\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.009568\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000064\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000232\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.001491\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000027\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.136272\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.132480\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000177\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.027544\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000150\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.001015\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000017\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.006134\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.001490\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000098\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000402\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000005\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000007\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.001760\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306518\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.146941\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.084236\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.108629\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.044296\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.095029\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.011094\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.273272\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.050951\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.048539\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.019938\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.100357\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.020600\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.045163\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.100000\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.025260\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.056310\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.215479\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.215081\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.021178\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.133810\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000732\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.150676\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.230493\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.006587\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.050065\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.037702\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.008268\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.010875\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.058705\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.091638\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003761\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000278\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.138523\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.003085\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.074617\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000638\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.005963\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.022782\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.004390\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000586\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.055054\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.004585\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.053123\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.011291\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.022727\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.014088\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.166144\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.162087\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006282\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000226\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.002082\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.000649\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.030540\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.007349\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000043\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001625\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.000318\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003225\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.030923\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.026181\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.000150\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000104\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.006497\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.015347\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000422\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.001963\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.034750\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000253\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.096268\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000400\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.000186\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.013914\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.011160\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.036752\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.006933\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.002511\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.030261\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.187176\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.005220\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.027173\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.020540\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.000997\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.043685\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.005641\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000057\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.009313\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.095800\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.001419\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001072\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.043203\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.023162\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.004982\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.004392\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.089259\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.076072\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000031\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.061372\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000494\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000717\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000026\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.003212\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.002328\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.001191\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.001559\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.017321\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000051\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.002471\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000349\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.004832\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.002730\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.001077\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.187062\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000248\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000503\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.004297\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.010300\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000040\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.001558\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.007983\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000234\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.003706\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.004318\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000119\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000745\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000009\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.007841\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.020860\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.030131\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.054126\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000076\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.011898\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.003850\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.043030\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.009169\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.012813\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.119576\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000494\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.001483\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000041\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.015575\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.002590\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000009\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.001041\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.267326\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000178\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000085\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.258220\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.005799\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.002761\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.017088\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000195\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000938\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000149\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.012568\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.003246\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000007\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.014603\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000018\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.002928\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.017912\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000218\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.122357\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.002163\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000003\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.004228\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000004\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000067\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000226\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.002893\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000168\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.099444\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.010608\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000091\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.001031\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000046\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000642\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000051\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.009980\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000048\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.272526\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000009\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.003518\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.018805\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.020065\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000440\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.092981\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.823849\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.008960\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000648\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000293\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.094061\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000198\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.140660\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000505\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.002409\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.020103\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.001686\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000095\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.010862\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000032\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.039856\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.003285\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000226\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.026712\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000352\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000088\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.001950\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000193\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000058\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000819\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.005076\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.001695\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.001080\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.001480\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000225\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.001028\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000106\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000104\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000507\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000104\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.001527\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.001068\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000700\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.172259\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000092\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.001668\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000034\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.003071\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.040955\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.032357\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000316\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.003055\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.001523\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000075\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000434\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000199\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.001326\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.028732\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.001191\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000051\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000007\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000009\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000027\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000022\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.001478\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000012\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000023\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000080\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000207\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000594\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.024136\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000060\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000027\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000043\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.000508\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000210\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.002794\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.013172\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000670\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.014674\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000155\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000069\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000012\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000080\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000032\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.001198\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000196\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000107\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000058\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000003\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000002\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000178\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.050467\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.059944\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000052\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000159\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000163\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000903\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.016766\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000016\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000212\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.014708\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.004593\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000013\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000904\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000032\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000011\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000002\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.006141\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.007865\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000194\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000007\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.020896\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.003199\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000676\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.002272\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000011\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.445680\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000002\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000020\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000203\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.002214\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.001252\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000012\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.000018\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000003\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000572\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000010\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000410\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.001832\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.136877\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000040\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000040\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000002\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000019\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000031\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000789\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.004253\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.031836\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000034\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.002679\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.032580\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000125\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.115424\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000004\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.002411\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000177\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000015\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000004\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000374\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000050\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000063\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.001114\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.002241\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000266\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000018\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.060768\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000006\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000179\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.006275\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000024\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000693\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000201\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000050\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000039\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000013\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.000002\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000186\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000005\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.000002\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.000175\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000025\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.000122\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000186\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.028932\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000089\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 1.359448\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.001560\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000854\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.005905\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000004\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000012\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000012\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.009309\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.000023\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000000\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000301\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000017\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.004575\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.007157\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000016\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.012073\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.004400\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000007\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000201\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000014\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000008\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000032\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.024246\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.061041\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000176\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.000033\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.007103\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000085\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.001573\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000117\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.004852\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000460\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.051841\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000007\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000017\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000046\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.004853\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.001474\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000814\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000002\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000283\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000006\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.011662\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000202\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.001490\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.007053\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000183\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000094\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000056\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000004\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.212480\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.052027\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000019\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000006\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.009487\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000357\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000029\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000055\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.003436\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000006\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000007\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000024\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000002\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.034645\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.084962\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000022\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.008107\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.178535\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000102\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000274\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000030\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000000\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000167\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.032161\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000088\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000119\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000003\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000001\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.048802\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000004\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000042\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000001\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000172\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000587\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000495\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000592\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000002\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000454\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000062\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000009\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000000\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000001\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.001226\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.001878\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.005541\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.102967\n",
      "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000056\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.012685\n"
     ]
    }
   ],
   "source": [
    "# Model configurations\n",
    "model_configs = {\n",
    "    'Model_1_Underfit': {\n",
    "        'hidden_size': [64, 32, 16],  # Very shallow, only 1 small hidden layer\n",
    "        'lr': 1e-4,  # Lower learning rate\n",
    "        'epochs': 5,  # Fewer epochs\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Underfitted: Too simple (1 layer, 32 units)'\n",
    "    },\n",
    "    'Model_2_Slight_Underfit': {\n",
    "        'hidden_size': [256, 128, 64],  # 2 small layers\n",
    "        'lr': 5e-4,\n",
    "        'epochs': 8,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Slightly underfitted: Simple architecture'\n",
    "    },\n",
    "    'Model_3_Well_Trained': {\n",
    "        'hidden_size': [512, 256, 128],  # Moderate depth and width\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.2,  # Some regularization\n",
    "        'description': 'Well-trained: Balanced architecture with dropout'\n",
    "    },\n",
    "    'Model_4_Well_Trained_Deep': {\n",
    "        'hidden_size': [1024, 512, 256],  # Deeper but with dropout\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 20,\n",
    "        'dropout': 0.3,  # More dropout for regularization\n",
    "        'description': 'Well-trained: Deeper with good regularization'\n",
    "    },\n",
    "    'Model_5_Overfit': {\n",
    "        'hidden_size': [2048, 1024, 1024],  # Very deep and wide\n",
    "        'lr': 1e-3,  # Higher learning rate\n",
    "        'epochs': 30,  # Many epochs\n",
    "        'dropout': 0.0,  # No regularization\n",
    "        'description': 'Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_6_Extra_Overfit': {\n",
    "        'hidden_size': [4096, 2048, 1024],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 50,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_7_Extra_Overfit': {\n",
    "        'hidden_size': [8192, 4096, 2048],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 100,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
    "    model.save(f'models/MNIST_model/{model_name}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed6b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "result = {\n",
    "    'model_name': [],\n",
    "    'test_accuracy': [],\n",
    "    'model_sparsity': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9573f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 53,018\n",
      "model name: Model_1_Underfit, test accuracy: 93.61%\n",
      "per column magnitude pruning test accuracy: 91.23%, sparsity: 0.3608\n",
      "per row magnitude pruning test accuracy: 91.85%, sparsity: 0.3415\n",
      "per block magnitude pruning test accuracy: 92.98%, sparsity: 0.3692\n",
      "mean column mean pruning test accuracy: 87.77%, sparsity: 0.3666\n",
      "mean row mean pruning test accuracy: 92.44%, sparsity: 0.3692\n",
      "mean block mean pruning test accuracy: 89.83%, sparsity: 0.3692\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 242,762\n",
      "model name: Model_2_Slight_Underfit, test accuracy: 97.99%\n",
      "per column magnitude pruning test accuracy: 97.62%, sparsity: 0.4369\n",
      "per row magnitude pruning test accuracy: 97.90%, sparsity: 0.3551\n",
      "per block magnitude pruning test accuracy: 97.84%, sparsity: 0.4367\n",
      "mean column mean pruning test accuracy: 97.45%, sparsity: 0.4163\n",
      "mean row mean pruning test accuracy: 97.35%, sparsity: 0.4367\n",
      "mean block mean pruning test accuracy: 97.84%, sparsity: 0.4367\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 567,434\n",
      "model name: Model_3_Well_Trained, test accuracy: 98.49%\n",
      "per column magnitude pruning test accuracy: 98.36%, sparsity: 0.4068\n",
      "per row magnitude pruning test accuracy: 98.46%, sparsity: 0.3479\n",
      "per block magnitude pruning test accuracy: 98.49%, sparsity: 0.4072\n",
      "mean column mean pruning test accuracy: 98.32%, sparsity: 0.3998\n",
      "mean row mean pruning test accuracy: 98.48%, sparsity: 0.4072\n",
      "mean block mean pruning test accuracy: 98.47%, sparsity: 0.4072\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 1,462,538\n",
      "model name: Model_4_Well_Trained_Deep, test accuracy: 98.56%\n",
      "per column magnitude pruning test accuracy: 98.50%, sparsity: 0.4006\n",
      "per row magnitude pruning test accuracy: 98.53%, sparsity: 0.3515\n",
      "per block magnitude pruning test accuracy: 98.56%, sparsity: 0.4020\n",
      "mean column mean pruning test accuracy: 98.37%, sparsity: 0.3965\n",
      "mean row mean pruning test accuracy: 98.55%, sparsity: 0.4020\n",
      "mean block mean pruning test accuracy: 98.56%, sparsity: 0.4020\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 4,765,706\n",
      "model name: Model_5_Overfit, test accuracy: 97.85%\n",
      "per column magnitude pruning test accuracy: 97.74%, sparsity: 0.5458\n",
      "per row magnitude pruning test accuracy: 97.62%, sparsity: 0.4470\n",
      "per block magnitude pruning test accuracy: 97.94%, sparsity: 0.5606\n",
      "mean column mean pruning test accuracy: 96.26%, sparsity: 0.4597\n",
      "mean row mean pruning test accuracy: 97.35%, sparsity: 0.5606\n",
      "mean block mean pruning test accuracy: 97.46%, sparsity: 0.5606\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 13,714,442\n",
      "model name: Model_6_Extra_Overfit, test accuracy: 98.22%\n",
      "per column magnitude pruning test accuracy: 97.38%, sparsity: 0.6555\n",
      "per row magnitude pruning test accuracy: 98.11%, sparsity: 0.4814\n",
      "per block magnitude pruning test accuracy: 98.17%, sparsity: 0.6650\n",
      "mean column mean pruning test accuracy: 88.33%, sparsity: 0.4937\n",
      "mean row mean pruning test accuracy: 97.80%, sparsity: 0.6650\n",
      "mean block mean pruning test accuracy: 98.23%, sparsity: 0.6650\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 48,400,394\n",
      "model name: Model_7_Extra_Overfit, test accuracy: 98.30%\n",
      "per column magnitude pruning test accuracy: 69.69%, sparsity: 0.7802\n",
      "per row magnitude pruning test accuracy: 97.93%, sparsity: 0.4917\n",
      "per block magnitude pruning test accuracy: 98.27%, sparsity: 0.7870\n",
      "mean column mean pruning test accuracy: 41.01%, sparsity: 0.5066\n",
      "mean row mean pruning test accuracy: 97.41%, sparsity: 0.7870\n",
      "mean block mean pruning test accuracy: 98.22%, sparsity: 0.7870\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8032f",
   "metadata": {},
   "source": [
    "# renormalize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b5f1976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 53,018\n",
      "Model Name: Model_1_Underfit, Test Accuracy: 93.61%\n",
      "Renormalized Model test accuracy: 91.83%, Sparsity: 0.35\n",
      "Model test accuracy: 91.85%, Sparsity: 0.35\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 242,762\n",
      "Model Name: Model_2_Slight_Underfit, Test Accuracy: 97.99%\n",
      "Renormalized Model test accuracy: 97.88%, Sparsity: 0.42\n",
      "Model test accuracy: 97.90%, Sparsity: 0.42\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 567,434\n",
      "Model Name: Model_3_Well_Trained, Test Accuracy: 98.49%\n",
      "Renormalized Model test accuracy: 98.48%, Sparsity: 0.40\n",
      "Model test accuracy: 98.46%, Sparsity: 0.40\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 1,462,538\n",
      "Model Name: Model_4_Well_Trained_Deep, Test Accuracy: 98.56%\n",
      "Renormalized Model test accuracy: 98.54%, Sparsity: 0.39\n",
      "Model test accuracy: 98.53%, Sparsity: 0.39\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 4,765,706\n",
      "Model Name: Model_5_Overfit, Test Accuracy: 97.85%\n",
      "Renormalized Model test accuracy: 97.45%, Sparsity: 0.44\n",
      "Model test accuracy: 97.62%, Sparsity: 0.44\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 13,714,442\n",
      "Model Name: Model_6_Extra_Overfit, Test Accuracy: 98.22%\n",
      "Renormalized Model test accuracy: 97.91%, Sparsity: 0.49\n",
      "Model test accuracy: 98.11%, Sparsity: 0.49\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 48,400,394\n",
      "Model Name: Model_7_Extra_Overfit, Test Accuracy: 98.30%\n",
      "Renormalized Model test accuracy: 97.47%, Sparsity: 0.51\n",
      "Model test accuracy: 97.93%, Sparsity: 0.51\n"
     ]
    }
   ],
   "source": [
    "renormal_result = {\n",
    "    'test_accuracy': [],\n",
    "    'model_sparsity': [],\n",
    "}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "    test_loss, test_accuracy, model_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(model_test_accuracy)\n",
    "    renormal_result['model_sparsity'].append(0.0)\n",
    "\n",
    "    row_pruning_renormalize, renormalize_neff = model_pr(model, renormalize=True)\n",
    "    row_pruning, neff = model_pr(model, renormalize=False)\n",
    "\n",
    "    # Test the pruned models\n",
    "    test_loss, test_accuracy, accuracy_mean = test(row_pruning_renormalize, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(accuracy_mean)\n",
    "    renormal_result['model_sparsity'].append(model_sparsity(row_pruning_renormalize))\n",
    "\n",
    "    test_loss, test_accuracy, accuracy_mean = test(row_pruning, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(accuracy_mean)\n",
    "    renormal_result['model_sparsity'].append(model_sparsity(row_pruning))\n",
    "\n",
    "    print(f\"Model Name: {model_name}, Test Accuracy: {model_test_accuracy:.2f}%\")\n",
    "    print(f\"Renormalized Model test accuracy: {renormal_result['test_accuracy'][-2]:.2f}%, Sparsity: {renormal_result['model_sparsity'][-2]:.2f}\")\n",
    "    print(f\"Model test accuracy: {renormal_result['test_accuracy'][-1]:.2f}%, Sparsity: {renormal_result['model_sparsity'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6504e5a",
   "metadata": {},
   "source": [
    "# Different activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "daeaaff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class with optional dropout\n",
    "class geluLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(geluLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.gelu(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "# Model class with optional dropout\n",
    "class SigmoidLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(SigmoidLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.sigmoid(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "        \n",
    "# Model class with optional dropout\n",
    "class tanhLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=[512, 512, 512], dropout_rate=0.0):\n",
    "        super(tanhLinearModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        prev_size = input_size\n",
    "        for size in hidden_size:\n",
    "            self.layers.append(nn.Linear(prev_size, size))\n",
    "            prev_size = size\n",
    "            \n",
    "        self.output = nn.Linear(prev_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = F.tanh(layer(x))\n",
    "            x = self.dropout(x)  # Apply dropout after activation\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa8bafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304690accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.168648accuracy: 10.12%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.678000accuracy: 27.10%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.444747accuracy: 45.23%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.432465accuracy: 63.78%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.391825accuracy: 0.09%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.318685accuracy: 19.05%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.414670accuracy: 38.14%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.334073accuracy: 57.33%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.321233accuracy: 76.60%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.228103accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.259478accuracy: 19.59%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.314006accuracy: 39.15%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.199908accuracy: 58.81%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.248183accuracy: 78.45%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.242582accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.162302accuracy: 19.74%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.379541accuracy: 39.58%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.334836accuracy: 59.48%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.153192accuracy: 79.33%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.121833accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.162228accuracy: 20.03%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.204725accuracy: 40.01%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.207404accuracy: 60.05%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.129721accuracy: 80.08%\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295523accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.220739accuracy: 17.66%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.148731accuracy: 37.41%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.122989accuracy: 57.50%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.269012accuracy: 77.72%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.149288accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.085592accuracy: 20.62%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.036000accuracy: 41.25%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.143184accuracy: 61.88%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.140646accuracy: 82.57%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.059326accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.012233accuracy: 20.96%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.067928accuracy: 41.87%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.102553accuracy: 62.74%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.014919accuracy: 83.61%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.095528accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.039766accuracy: 21.08%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.031562accuracy: 42.07%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.007650accuracy: 63.05%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.161220accuracy: 83.99%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.009697accuracy: 0.11%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.027447accuracy: 21.20%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.001677accuracy: 42.28%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.005410accuracy: 63.30%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.025366accuracy: 84.34%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.056694accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.003657accuracy: 21.25%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.009458accuracy: 42.37%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.034413accuracy: 63.47%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.002269accuracy: 84.57%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.009212accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.005291accuracy: 21.31%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.023412accuracy: 42.49%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.063987accuracy: 63.62%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.032774accuracy: 84.78%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.037667accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001547accuracy: 21.31%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.018087accuracy: 42.48%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.037602accuracy: 63.67%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.011014accuracy: 84.85%\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.318991accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.279123accuracy: 17.01%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.274227accuracy: 36.37%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.298819accuracy: 56.29%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.132603accuracy: 76.42%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.160526accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.097661accuracy: 20.53%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.120694accuracy: 41.06%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.091716accuracy: 61.59%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.038609accuracy: 82.18%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.097484accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.060043accuracy: 20.84%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.108489accuracy: 41.58%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.134392accuracy: 62.31%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.125946accuracy: 83.10%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.108715accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.099645accuracy: 20.99%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.084938accuracy: 41.86%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.177739accuracy: 62.74%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.118546accuracy: 83.67%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004869accuracy: 0.11%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002570accuracy: 21.07%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.116396accuracy: 42.06%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.018606accuracy: 63.03%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.121940accuracy: 84.02%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.130721accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.007224accuracy: 21.13%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.016391accuracy: 42.17%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.007948accuracy: 63.22%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.010642accuracy: 84.28%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.061628accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.042896accuracy: 21.23%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.003443accuracy: 42.30%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.027259accuracy: 63.40%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.028930accuracy: 84.44%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.036909accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.024007accuracy: 21.21%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.049094accuracy: 42.34%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.007517accuracy: 63.47%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.052331accuracy: 84.57%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.017107accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.072178accuracy: 21.27%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.015487accuracy: 42.42%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.097856accuracy: 63.55%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.025552accuracy: 84.66%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.004123accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000130accuracy: 21.30%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.019388accuracy: 42.49%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.008284accuracy: 63.65%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.024975accuracy: 84.77%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.008259accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.013619accuracy: 21.30%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.029082accuracy: 42.47%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.011489accuracy: 63.60%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.019928accuracy: 84.70%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.007107accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.005552accuracy: 21.29%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.005363accuracy: 42.50%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.011063accuracy: 63.69%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.036625accuracy: 84.86%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.044023accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.012922accuracy: 21.28%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.067956accuracy: 42.48%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.001550accuracy: 63.68%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.019110accuracy: 84.87%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.012411accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.016860accuracy: 21.28%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.046135accuracy: 42.49%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.012393accuracy: 63.69%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.072313accuracy: 84.88%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.002518accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001066accuracy: 21.35%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.007153accuracy: 42.56%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.004201accuracy: 63.76%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001013accuracy: 84.95%\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298719accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.394028accuracy: 17.52%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.287335accuracy: 37.19%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.189833accuracy: 57.23%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.209217accuracy: 77.49%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.104004accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.066380accuracy: 20.66%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.142744accuracy: 41.22%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.128840accuracy: 61.88%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.052212accuracy: 82.55%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.163634accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.012248accuracy: 20.93%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.083856accuracy: 41.72%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.107100accuracy: 62.51%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.046374accuracy: 83.37%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.033324accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.046960accuracy: 21.06%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.038837accuracy: 42.01%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.102989accuracy: 62.90%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.056838accuracy: 83.80%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.030851accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.018410accuracy: 21.12%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.043568accuracy: 42.12%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.104439accuracy: 63.11%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.024681accuracy: 84.09%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.006533accuracy: 0.11%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.074880accuracy: 21.18%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.003208accuracy: 42.23%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.038566accuracy: 63.30%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.029385accuracy: 84.29%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.029936accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.017114accuracy: 21.22%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.033183accuracy: 42.30%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.019678accuracy: 63.37%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.002985accuracy: 84.43%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000997accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.070892accuracy: 21.23%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.003298accuracy: 42.35%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.054977accuracy: 63.42%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.072808accuracy: 84.51%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.084936accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.015894accuracy: 21.22%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.012475accuracy: 42.38%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.004945accuracy: 63.55%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.064531accuracy: 84.67%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.003605accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000869accuracy: 21.26%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.002113accuracy: 42.39%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.138129accuracy: 63.52%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.103910accuracy: 84.67%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.017150accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.065737accuracy: 21.27%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.028582accuracy: 42.42%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000716accuracy: 63.58%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.027104accuracy: 84.75%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.039303accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.008417accuracy: 21.27%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.002339accuracy: 42.42%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.053617accuracy: 63.62%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000854accuracy: 84.80%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.015736accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.001385accuracy: 21.27%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.006115accuracy: 42.49%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.018792accuracy: 63.65%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.176026accuracy: 84.81%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002458accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.024624accuracy: 21.35%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.013267accuracy: 42.56%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.047883accuracy: 63.76%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001957accuracy: 84.90%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.005812accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.014813accuracy: 21.29%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.062758accuracy: 42.47%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000591accuracy: 63.70%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.004649accuracy: 84.88%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.004094accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.013593accuracy: 21.30%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.012995accuracy: 42.53%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.239697accuracy: 63.74%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.001745accuracy: 84.92%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.001725accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000369accuracy: 21.32%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.026867accuracy: 42.52%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.050812accuracy: 63.73%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.002158accuracy: 84.95%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.039030accuracy: 0.10%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.013282accuracy: 21.32%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000046accuracy: 42.56%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.011121accuracy: 63.77%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000495accuracy: 84.99%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.012540accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.001227accuracy: 21.32%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.022649accuracy: 42.54%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.003962accuracy: 63.73%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.085787accuracy: 84.97%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.029386accuracy: 0.10%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.003012accuracy: 21.30%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.046687accuracy: 42.52%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.108623accuracy: 63.74%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.004061accuracy: 84.99%\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302364accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.325553accuracy: 19.10%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.263549accuracy: 39.18%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.280737accuracy: 59.54%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.092800accuracy: 79.91%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.216673accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.165694accuracy: 20.77%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.086793accuracy: 41.40%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.138168accuracy: 62.16%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.094011accuracy: 82.88%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.053239accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.085061accuracy: 21.06%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.063823accuracy: 41.98%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.078302accuracy: 62.82%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.088181accuracy: 83.66%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.009571accuracy: 0.11%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005834accuracy: 21.12%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.001674accuracy: 42.12%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.044834accuracy: 63.09%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.063350accuracy: 84.08%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.039332accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.151479accuracy: 21.18%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.066078accuracy: 42.15%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.011802accuracy: 63.18%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.014345accuracy: 84.19%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.033131accuracy: 0.11%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.003740accuracy: 21.24%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001205accuracy: 42.35%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.089243accuracy: 63.41%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.010082accuracy: 84.45%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.043936accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.005409accuracy: 21.24%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.033874accuracy: 42.39%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000475accuracy: 63.51%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.120839accuracy: 84.59%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.087706accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005517accuracy: 21.24%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.011558accuracy: 42.31%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.006872accuracy: 63.43%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.032458accuracy: 84.55%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.026233accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.039075accuracy: 21.27%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.127705accuracy: 42.37%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001011accuracy: 63.47%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.112503accuracy: 84.60%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000069accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002626accuracy: 21.24%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.035862accuracy: 42.44%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002579accuracy: 63.62%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.004868accuracy: 84.80%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.070427accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.067087accuracy: 21.35%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.013520accuracy: 42.53%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.023096accuracy: 63.63%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.000949accuracy: 84.77%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.032110accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.011360accuracy: 21.32%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.003360accuracy: 42.46%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.034326accuracy: 63.63%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001299accuracy: 84.78%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000094accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.006776accuracy: 21.26%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.057287accuracy: 42.50%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000826accuracy: 63.69%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.002870accuracy: 84.89%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.100250accuracy: 0.10%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.044133accuracy: 21.31%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000012accuracy: 42.49%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000535accuracy: 63.74%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.077399accuracy: 84.92%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.102895accuracy: 0.10%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.010839accuracy: 21.20%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.009886accuracy: 42.35%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.002280accuracy: 63.57%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.077970accuracy: 84.78%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.012196accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.001908accuracy: 21.37%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.173601accuracy: 42.62%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000508accuracy: 63.86%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.279014accuracy: 85.06%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.002781accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.034684accuracy: 21.29%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.021437accuracy: 42.50%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000101accuracy: 63.66%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.163914accuracy: 84.85%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.001923accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.012980accuracy: 21.34%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.009233accuracy: 42.59%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.001636accuracy: 63.80%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.000147accuracy: 85.02%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000310accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.003360accuracy: 21.33%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.001996accuracy: 42.56%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.006245accuracy: 63.81%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.012331accuracy: 85.00%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000042accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.002726accuracy: 21.32%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.081068accuracy: 42.51%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000751accuracy: 63.75%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000186accuracy: 84.99%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.010531accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000833accuracy: 21.35%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.015484accuracy: 42.60%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000042accuracy: 63.86%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.008135accuracy: 85.10%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.004337accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.007066accuracy: 21.35%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000007accuracy: 42.62%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000289accuracy: 63.87%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000082accuracy: 85.12%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000072accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.054803accuracy: 21.37%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.022661accuracy: 42.59%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.007431accuracy: 63.82%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000094accuracy: 85.05%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000166accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.012101accuracy: 21.35%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.003463accuracy: 42.54%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.002313accuracy: 63.78%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.020932accuracy: 85.00%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.001541accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000420accuracy: 21.31%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000187accuracy: 42.58%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.016856accuracy: 63.84%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000037accuracy: 85.09%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.056906accuracy: 0.10%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.001571accuracy: 21.40%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000850accuracy: 42.66%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.006265accuracy: 63.80%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000077accuracy: 85.02%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.009708accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.217809accuracy: 21.36%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.003590accuracy: 42.60%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.000357accuracy: 63.88%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000242accuracy: 85.15%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.077646accuracy: 0.10%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000181accuracy: 21.36%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.002263accuracy: 42.59%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000118accuracy: 63.83%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000708accuracy: 85.11%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000026accuracy: 0.11%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.040288accuracy: 21.39%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.164018accuracy: 42.65%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.070025accuracy: 63.87%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.001326accuracy: 85.08%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000004accuracy: 0.11%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.011160accuracy: 21.36%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000006accuracy: 42.62%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000012accuracy: 63.86%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000065accuracy: 85.14%\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301155accuracy: 0.02%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.107280accuracy: 18.96%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.115482accuracy: 38.98%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.067423accuracy: 59.22%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.249653accuracy: 79.59%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.235870accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.043394accuracy: 20.77%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.077390accuracy: 41.42%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.047171accuracy: 62.17%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.059550accuracy: 82.89%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.092377accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.307023accuracy: 21.01%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.027030accuracy: 41.85%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.306912accuracy: 62.73%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.072393accuracy: 83.61%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001309accuracy: 0.11%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.025062accuracy: 21.04%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.021867accuracy: 41.96%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.111375accuracy: 62.90%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.015959accuracy: 83.80%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.104879accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.015392accuracy: 21.16%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.017046accuracy: 42.19%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.061594accuracy: 63.22%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.174143accuracy: 84.23%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.028474accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.002972accuracy: 21.21%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.006501accuracy: 42.23%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.051274accuracy: 63.24%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.009717accuracy: 84.26%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.076872accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.133627accuracy: 21.20%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.005377accuracy: 42.30%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.031200accuracy: 63.34%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.067757accuracy: 84.48%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.008367accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000436accuracy: 21.26%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.022251accuracy: 42.38%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.026246accuracy: 63.49%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000538accuracy: 84.58%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.126425accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002277accuracy: 21.23%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.001455accuracy: 42.31%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.004244accuracy: 63.46%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.065112accuracy: 84.57%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.009008accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.001568accuracy: 21.20%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.005246accuracy: 42.32%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.044345accuracy: 63.41%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000250accuracy: 84.57%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.006692accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.004625accuracy: 21.30%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.027116accuracy: 42.48%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.001659accuracy: 63.64%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.102342accuracy: 84.70%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.018441accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.006138accuracy: 21.28%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.047743accuracy: 42.46%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003952accuracy: 63.62%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.011342accuracy: 84.81%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001350accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.058523accuracy: 21.35%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.279388accuracy: 42.52%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.061320accuracy: 63.72%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000381accuracy: 84.85%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000039accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.027891accuracy: 21.27%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.002809accuracy: 42.44%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.002606accuracy: 63.65%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.003762accuracy: 84.80%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.053975accuracy: 0.10%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.088696accuracy: 21.34%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000149accuracy: 42.55%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.096501accuracy: 63.74%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000438accuracy: 84.92%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000119accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.030434accuracy: 21.36%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.007874accuracy: 42.53%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000277accuracy: 63.71%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000553accuracy: 84.92%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.135286accuracy: 0.10%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.004482accuracy: 21.30%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.000398accuracy: 42.52%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.012689accuracy: 63.76%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000012accuracy: 84.97%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.005370accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.003089accuracy: 21.33%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.350750accuracy: 42.56%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.028025accuracy: 63.78%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.002321accuracy: 85.03%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000039accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000015accuracy: 21.37%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.009407accuracy: 42.58%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.014067accuracy: 63.85%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000644accuracy: 85.08%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.015221accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.002964accuracy: 21.37%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000001accuracy: 42.61%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000613accuracy: 63.79%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.001023accuracy: 84.97%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001098accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000516accuracy: 21.38%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.65%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000908accuracy: 63.91%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.002784accuracy: 85.15%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000043accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000014accuracy: 21.34%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.001891accuracy: 42.54%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.005024accuracy: 63.78%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.011697accuracy: 85.01%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000220accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000523accuracy: 21.30%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.079122accuracy: 42.55%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000641accuracy: 63.79%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.03%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.001366accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000409accuracy: 21.37%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000086accuracy: 42.58%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.001174accuracy: 63.83%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.007139accuracy: 85.05%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.001110accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000118accuracy: 21.37%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.002454accuracy: 42.65%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000003accuracy: 63.93%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.16%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.001540accuracy: 0.11%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000570accuracy: 21.39%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000035accuracy: 42.69%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.012258accuracy: 63.91%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000003accuracy: 85.14%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000589accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000001accuracy: 21.41%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.019562accuracy: 42.65%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.020823accuracy: 63.89%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.12%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000010accuracy: 0.11%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000273accuracy: 21.40%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000013accuracy: 42.68%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000002accuracy: 63.91%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000651accuracy: 85.16%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.001007accuracy: 0.11%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.001862accuracy: 21.34%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.392163accuracy: 42.58%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000809accuracy: 63.79%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000598accuracy: 85.00%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.005598accuracy: 0.11%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000177accuracy: 21.38%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000415accuracy: 42.67%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 63.94%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000012accuracy: 85.22%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.005471accuracy: 0.11%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000192accuracy: 21.37%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.62%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000891accuracy: 63.89%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.14%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.006725accuracy: 0.11%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.009115accuracy: 21.40%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.027139accuracy: 42.68%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.004252accuracy: 63.95%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000024accuracy: 85.22%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000510accuracy: 0.11%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.003586accuracy: 21.41%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.035229accuracy: 42.67%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000070accuracy: 63.95%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.012112accuracy: 85.20%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.078660accuracy: 0.10%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.002991accuracy: 21.36%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.002985accuracy: 42.66%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000295accuracy: 63.94%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.18%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.002551accuracy: 0.11%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.039388accuracy: 21.30%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.005477accuracy: 42.52%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000111accuracy: 63.81%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000102accuracy: 85.10%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000402accuracy: 0.11%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000071accuracy: 21.39%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.028884accuracy: 42.65%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.001143accuracy: 63.95%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.002508accuracy: 85.23%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000131accuracy: 0.11%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.008325accuracy: 21.41%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000007accuracy: 42.73%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.000005accuracy: 64.03%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000013accuracy: 85.33%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.127977accuracy: 0.10%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.042577accuracy: 21.32%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000469accuracy: 42.60%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000049accuracy: 63.84%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.002576accuracy: 85.11%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.005077accuracy: 0.11%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000523accuracy: 21.37%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000013accuracy: 42.66%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.004777accuracy: 63.92%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000137accuracy: 85.16%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.033787accuracy: 0.10%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000035accuracy: 21.38%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.066758accuracy: 42.66%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000117accuracy: 63.89%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.019070accuracy: 85.15%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000211accuracy: 0.11%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000050accuracy: 21.40%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000009accuracy: 42.69%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.000878accuracy: 64.00%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000119accuracy: 85.30%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.085031accuracy: 0.10%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000263accuracy: 21.42%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000017accuracy: 42.72%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000632accuracy: 63.98%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.005664accuracy: 85.24%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.116588accuracy: 0.10%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.031201accuracy: 21.36%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000014accuracy: 42.61%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000022accuracy: 63.89%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.16%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.003118accuracy: 0.11%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.39%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000090accuracy: 42.67%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000820accuracy: 63.96%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.004587accuracy: 85.22%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000051accuracy: 0.11%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000103accuracy: 21.41%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000019accuracy: 42.71%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000086accuracy: 63.98%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.015673accuracy: 85.25%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.005362accuracy: 0.11%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000033accuracy: 21.41%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000082accuracy: 42.73%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000020accuracy: 64.03%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.001698accuracy: 85.34%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000012accuracy: 0.11%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.081246accuracy: 21.43%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.152930accuracy: 42.66%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000348accuracy: 63.93%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000027accuracy: 85.24%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000024accuracy: 0.11%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000018accuracy: 21.39%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000769accuracy: 42.66%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000871accuracy: 63.95%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.004121accuracy: 85.24%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000002accuracy: 0.11%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000027accuracy: 21.41%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.008902accuracy: 42.71%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000058accuracy: 64.00%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.32%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.366779accuracy: 0.10%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.302862accuracy: 21.32%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000044accuracy: 42.59%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.002539accuracy: 63.85%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.038087accuracy: 85.17%\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308858accuracy: 0.02%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.210012accuracy: 18.72%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.148413accuracy: 38.62%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.151072accuracy: 58.85%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.077454accuracy: 79.22%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.129905accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.215257accuracy: 20.73%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.039686accuracy: 41.39%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.146448accuracy: 62.02%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.041179accuracy: 82.73%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.024362accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.074695accuracy: 20.91%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.015582accuracy: 41.68%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.100192accuracy: 62.47%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.098291accuracy: 83.18%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.035353accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.016535accuracy: 21.02%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.038572accuracy: 41.91%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.013309accuracy: 62.84%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.137347accuracy: 83.74%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.049699accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.029219accuracy: 21.13%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.054180accuracy: 42.01%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.001270accuracy: 62.98%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.137079accuracy: 83.95%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.092231accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.008277accuracy: 21.09%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.029362accuracy: 42.15%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.324900accuracy: 63.16%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.153185accuracy: 84.09%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.149531accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003531accuracy: 21.20%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025815accuracy: 42.29%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.007147accuracy: 63.36%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.033838accuracy: 84.38%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.043847accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000474accuracy: 21.14%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.118323accuracy: 42.22%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.010276accuracy: 63.28%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.002681accuracy: 84.31%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.025219accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.048553accuracy: 21.26%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.064662accuracy: 42.36%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.246232accuracy: 63.47%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.104949accuracy: 84.54%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.117615accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.025172accuracy: 21.23%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.005315accuracy: 42.41%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.003907accuracy: 63.49%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.003975accuracy: 84.62%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.010977accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.001756accuracy: 21.32%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.010164accuracy: 42.45%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.023918accuracy: 63.54%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.054874accuracy: 84.60%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.010200accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.035456accuracy: 21.26%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.039861accuracy: 42.42%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.073151accuracy: 63.59%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.003567accuracy: 84.74%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.002693accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.002455accuracy: 21.28%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.170187accuracy: 42.44%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.035781accuracy: 63.52%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000148accuracy: 84.70%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.009286accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002475accuracy: 21.29%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.097404accuracy: 42.45%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.041240accuracy: 63.59%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.000528accuracy: 84.76%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.075165accuracy: 0.10%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.006066accuracy: 21.31%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.080423accuracy: 42.52%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.041685accuracy: 63.74%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000219accuracy: 84.95%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000074accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.000016accuracy: 21.30%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.008485accuracy: 42.53%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.078474accuracy: 63.71%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.101577accuracy: 84.84%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.008248accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.000102accuracy: 21.29%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.057676accuracy: 42.48%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.200501accuracy: 63.65%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.029251accuracy: 84.83%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.004296accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.003607accuracy: 21.36%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.079215accuracy: 42.61%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000275accuracy: 63.84%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.030054accuracy: 85.06%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.036801accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.016540accuracy: 21.33%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.001130accuracy: 42.59%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.001748accuracy: 63.83%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.003462accuracy: 85.09%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000570accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000126accuracy: 21.34%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.003355accuracy: 42.59%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.009580accuracy: 63.78%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.046749accuracy: 84.96%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.001135accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000112accuracy: 21.29%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000946accuracy: 42.49%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000007accuracy: 63.69%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.000221accuracy: 84.91%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000062accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000361accuracy: 21.35%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.037475accuracy: 42.60%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000492accuracy: 63.80%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.034478accuracy: 85.04%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.005217accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000012accuracy: 21.35%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.024336accuracy: 42.61%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.124741accuracy: 63.81%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000080accuracy: 85.06%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000207accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.008163accuracy: 21.33%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.023099accuracy: 42.53%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.001013accuracy: 63.78%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.006107accuracy: 85.04%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000051accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000134accuracy: 21.41%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.014904accuracy: 42.66%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.098949accuracy: 63.94%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.006124accuracy: 85.20%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000074accuracy: 0.11%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000008accuracy: 21.39%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.022411accuracy: 42.59%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.033248accuracy: 63.79%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000131accuracy: 85.06%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.001056accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000064accuracy: 21.37%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000009accuracy: 42.61%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.014701accuracy: 63.84%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000404accuracy: 85.07%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.003165accuracy: 0.11%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000033accuracy: 21.38%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.032257accuracy: 42.56%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.013258accuracy: 63.80%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000018accuracy: 85.06%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.014595accuracy: 0.10%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000013accuracy: 21.37%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000254accuracy: 42.63%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 63.87%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.018328accuracy: 85.09%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.000293accuracy: 0.11%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.047559accuracy: 21.37%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000955accuracy: 42.64%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.102650accuracy: 63.88%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000004accuracy: 85.13%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.005374accuracy: 0.11%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000005accuracy: 21.38%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.027342accuracy: 42.67%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.000087accuracy: 63.94%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000052accuracy: 85.18%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000177accuracy: 0.11%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.001778accuracy: 21.38%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000435accuracy: 42.65%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000259accuracy: 63.90%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.038195accuracy: 85.17%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000102accuracy: 0.11%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.042016accuracy: 21.36%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000425accuracy: 42.62%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000631accuracy: 63.89%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000231accuracy: 85.17%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.002417accuracy: 0.11%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.001480accuracy: 21.37%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000086accuracy: 42.65%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.005049accuracy: 63.94%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000153accuracy: 85.23%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.009493accuracy: 0.11%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.001919accuracy: 21.40%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.69%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000009accuracy: 63.95%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000153accuracy: 85.21%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000234accuracy: 0.11%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.001267accuracy: 21.35%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.108191accuracy: 42.60%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.000018accuracy: 63.87%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000013accuracy: 85.13%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000594accuracy: 0.11%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.713232accuracy: 21.36%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000252accuracy: 42.62%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.029421accuracy: 63.83%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.12%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.002378accuracy: 0.11%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.001179accuracy: 21.38%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000699accuracy: 42.66%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 63.96%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000027accuracy: 85.23%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000655accuracy: 0.11%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000005accuracy: 21.39%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.004191accuracy: 42.66%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.012964accuracy: 63.90%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000313accuracy: 85.16%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000143accuracy: 0.11%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.000059accuracy: 21.40%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000001accuracy: 42.67%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000292accuracy: 63.91%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000014accuracy: 85.15%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.001124accuracy: 0.11%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.003150accuracy: 21.39%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.000501accuracy: 42.68%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.065674accuracy: 63.97%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.012888accuracy: 85.24%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.040258accuracy: 21.34%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.003610accuracy: 42.63%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000049accuracy: 63.87%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000111accuracy: 85.14%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000085accuracy: 0.11%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000023accuracy: 21.41%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.050237accuracy: 42.70%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.001711accuracy: 64.00%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000341accuracy: 85.28%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000032accuracy: 0.11%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.279204accuracy: 21.42%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000060accuracy: 42.71%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.000022accuracy: 63.98%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.001414accuracy: 85.25%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000424accuracy: 0.11%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000099accuracy: 21.38%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000883accuracy: 42.65%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000204accuracy: 63.94%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.002716accuracy: 85.24%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000006accuracy: 0.11%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.000429accuracy: 21.38%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000955accuracy: 42.64%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000066accuracy: 63.95%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.22%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000004accuracy: 0.11%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.002398accuracy: 21.39%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000022accuracy: 42.68%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.002830accuracy: 63.95%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000467accuracy: 85.24%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000012accuracy: 0.11%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000007accuracy: 21.41%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000391accuracy: 42.69%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000034accuracy: 63.96%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000005accuracy: 85.24%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000140accuracy: 0.11%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.001334accuracy: 21.35%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000119accuracy: 42.63%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.024672accuracy: 63.95%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.001361accuracy: 85.24%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.009292accuracy: 21.42%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.007047accuracy: 42.73%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000008accuracy: 64.05%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.35%\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.000081accuracy: 21.40%\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.070435accuracy: 42.68%\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 63.98%\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.049271accuracy: 85.22%\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.027650accuracy: 0.10%\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000015accuracy: 21.38%\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.017604accuracy: 42.69%\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.016565accuracy: 63.96%\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000144accuracy: 85.23%\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000070accuracy: 0.11%\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.000845accuracy: 21.40%\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.001096accuracy: 42.67%\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.001664accuracy: 63.98%\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.27%\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.000865accuracy: 0.11%\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.40%\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.000019accuracy: 42.71%\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.000042accuracy: 63.99%\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000250accuracy: 85.29%\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.43%\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.000361accuracy: 42.71%\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000354accuracy: 63.98%\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.002028accuracy: 85.24%\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000007accuracy: 0.11%\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.000805accuracy: 21.41%\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000072accuracy: 42.69%\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000011accuracy: 63.98%\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000053accuracy: 85.27%\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.070729accuracy: 21.41%\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000169accuracy: 42.63%\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000007accuracy: 63.91%\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000059accuracy: 85.18%\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.000005accuracy: 0.11%\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.000107accuracy: 21.41%\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000029accuracy: 42.73%\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000005accuracy: 64.01%\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000889accuracy: 85.32%\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.42%\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000170accuracy: 42.75%\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000026accuracy: 64.05%\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.000409accuracy: 85.29%\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.002885accuracy: 0.11%\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.42%\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.69%\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.005036accuracy: 63.96%\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.000017accuracy: 85.24%\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.155830accuracy: 0.10%\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.001279accuracy: 21.35%\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.000020accuracy: 42.64%\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.004611accuracy: 63.94%\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000135accuracy: 85.23%\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.147307accuracy: 0.10%\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.004095accuracy: 21.39%\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000290accuracy: 42.68%\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000316accuracy: 63.96%\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000812accuracy: 85.26%\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.000002accuracy: 21.42%\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.73%\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.000508accuracy: 64.03%\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.013083accuracy: 85.30%\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000059accuracy: 0.11%\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000082accuracy: 21.43%\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000072accuracy: 42.75%\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.000007accuracy: 64.06%\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.37%\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000963accuracy: 0.11%\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000399accuracy: 21.39%\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.021820accuracy: 42.67%\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.000013accuracy: 63.92%\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.015142accuracy: 85.22%\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000445accuracy: 0.11%\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.000002accuracy: 21.41%\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.000027accuracy: 42.72%\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.001553accuracy: 64.01%\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000006accuracy: 85.26%\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000223accuracy: 0.11%\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000080accuracy: 21.41%\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.72%\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000054accuracy: 64.03%\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.32%\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000015accuracy: 0.11%\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.000673accuracy: 21.41%\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.003507accuracy: 42.71%\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000028accuracy: 64.03%\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000014accuracy: 85.36%\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.000067accuracy: 0.11%\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000213accuracy: 21.44%\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000058accuracy: 42.77%\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 64.11%\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.000006accuracy: 85.44%\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.44%\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000554accuracy: 42.77%\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000019accuracy: 64.11%\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000660accuracy: 85.39%\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.069174accuracy: 0.10%\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 1.939280accuracy: 21.31%\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.022618accuracy: 42.58%\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.000036accuracy: 63.83%\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000019accuracy: 85.12%\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.42%\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.066333accuracy: 42.72%\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.000065accuracy: 64.02%\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.000047accuracy: 85.32%\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.000703accuracy: 0.11%\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000082accuracy: 21.41%\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000786accuracy: 42.73%\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.048300accuracy: 64.01%\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000041accuracy: 85.30%\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.000001accuracy: 21.41%\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.000004accuracy: 42.72%\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.007199accuracy: 64.05%\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.000013accuracy: 85.37%\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000005accuracy: 21.43%\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.008565accuracy: 42.75%\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.000008accuracy: 64.04%\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.000026accuracy: 85.31%\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.006099accuracy: 0.11%\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.073911accuracy: 21.42%\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.005083accuracy: 42.71%\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.000002accuracy: 64.00%\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.017254accuracy: 85.27%\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.037705accuracy: 0.10%\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000058accuracy: 21.41%\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000135accuracy: 42.71%\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000049accuracy: 64.00%\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000004accuracy: 85.32%\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000536accuracy: 0.11%\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000490accuracy: 21.39%\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000223accuracy: 42.70%\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.000057accuracy: 63.98%\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.28%\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.000289accuracy: 0.11%\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000214accuracy: 21.39%\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000000accuracy: 42.66%\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.005165accuracy: 63.94%\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.003742accuracy: 85.23%\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.001688accuracy: 0.11%\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.262827accuracy: 21.39%\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.002027accuracy: 42.70%\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000638accuracy: 63.96%\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000002accuracy: 85.26%\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000000accuracy: 0.11%\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.001272accuracy: 21.40%\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.70%\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000798accuracy: 64.00%\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.000187accuracy: 85.31%\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000040accuracy: 0.11%\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.000069accuracy: 21.42%\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.015271accuracy: 42.74%\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000002accuracy: 64.06%\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000002accuracy: 85.35%\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.005883accuracy: 0.11%\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.091622accuracy: 21.39%\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000102accuracy: 42.72%\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.000721accuracy: 64.02%\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.207593accuracy: 85.31%\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.020017accuracy: 0.11%\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000147accuracy: 21.42%\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.007292accuracy: 42.71%\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 64.02%\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.33%\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000531accuracy: 0.11%\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000015accuracy: 21.41%\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000022accuracy: 42.73%\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000048accuracy: 64.05%\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.000424accuracy: 85.36%\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000016accuracy: 0.11%\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000000accuracy: 21.43%\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000001accuracy: 42.74%\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 64.07%\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000002accuracy: 85.39%\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.000049accuracy: 0.11%\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.000216accuracy: 21.41%\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.000004accuracy: 42.68%\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000021accuracy: 63.98%\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000171accuracy: 85.27%\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000004accuracy: 0.11%\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.026438accuracy: 21.41%\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000317accuracy: 42.73%\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.050743accuracy: 64.06%\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000091accuracy: 85.38%\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000245accuracy: 0.11%\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000020accuracy: 21.41%\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000174accuracy: 42.72%\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 64.04%\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.360546accuracy: 85.36%\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000045accuracy: 0.11%\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.039768accuracy: 21.39%\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000028accuracy: 42.63%\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000571accuracy: 63.91%\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000010accuracy: 85.18%\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000021accuracy: 0.11%\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.000058accuracy: 21.39%\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000055accuracy: 42.70%\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.038847accuracy: 64.01%\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000006accuracy: 85.33%\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000025accuracy: 0.11%\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.000432accuracy: 21.43%\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.73%\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000211accuracy: 64.03%\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.35%\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000413accuracy: 0.11%\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000002accuracy: 21.43%\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.020032accuracy: 42.74%\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.000000accuracy: 64.05%\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000002accuracy: 85.35%\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000002accuracy: 0.11%\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000013accuracy: 21.42%\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.040486accuracy: 42.70%\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000080accuracy: 63.99%\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000114accuracy: 85.30%\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000002accuracy: 0.11%\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.004400accuracy: 21.42%\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.000467accuracy: 42.70%\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 63.99%\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.28%\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000023accuracy: 0.11%\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.000001accuracy: 21.42%\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000005accuracy: 42.73%\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.044024accuracy: 64.02%\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000455accuracy: 85.30%\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.000556accuracy: 0.11%\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000105accuracy: 21.41%\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000011accuracy: 42.67%\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000002accuracy: 63.98%\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.003031accuracy: 85.30%\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000234accuracy: 0.11%\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000551accuracy: 21.41%\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.71%\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 64.03%\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.000000accuracy: 85.35%\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000038accuracy: 0.11%\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000003accuracy: 21.43%\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000005accuracy: 42.74%\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.000072accuracy: 64.06%\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.014318accuracy: 85.37%\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.000709accuracy: 0.11%\n",
      "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000007accuracy: 21.39%\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.002673accuracy: 42.70%\n",
      "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.261964accuracy: 63.99%\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000004accuracy: 85.30%\n",
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.287143accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.292379accuracy: 2.04%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.255115accuracy: 6.18%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.217235accuracy: 12.18%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.129441accuracy: 19.85%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.092273accuracy: 0.04%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.028236accuracy: 8.04%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.981114accuracy: 15.86%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.906374accuracy: 23.95%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.837579accuracy: 32.16%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.817091accuracy: 0.04%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.786000accuracy: 8.44%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.752276accuracy: 16.82%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.662348accuracy: 25.28%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.671401accuracy: 33.81%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.578267accuracy: 0.05%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.605885accuracy: 8.78%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.588878accuracy: 17.69%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.565345accuracy: 26.62%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.622411accuracy: 35.75%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.549931accuracy: 0.05%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.521550accuracy: 9.67%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.410263accuracy: 19.99%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.413620accuracy: 30.69%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.412103accuracy: 42.18%\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.392396accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.392616accuracy: 8.95%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.760792accuracy: 25.22%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.679388accuracy: 43.92%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.411951accuracy: 63.18%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.220167accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.323633accuracy: 20.00%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.360428accuracy: 40.03%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.195941accuracy: 60.16%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.176627accuracy: 80.36%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.075498accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.118569accuracy: 20.61%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.055809accuracy: 41.13%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.046261accuracy: 61.70%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.128139accuracy: 82.30%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.114091accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.110225accuracy: 20.84%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.030145accuracy: 41.62%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.073638accuracy: 62.37%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.056509accuracy: 83.16%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.100989accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.061725accuracy: 21.03%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.011662accuracy: 41.92%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.080547accuracy: 62.81%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.077755accuracy: 83.75%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.033932accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.025187accuracy: 21.15%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.033815accuracy: 42.21%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.032575accuracy: 63.20%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.040653accuracy: 84.17%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.007821accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.009136accuracy: 21.21%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.023576accuracy: 42.34%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.018706accuracy: 63.41%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009532accuracy: 84.48%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.018773accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.035144accuracy: 21.29%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.014407accuracy: 42.47%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.047442accuracy: 63.60%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.007526accuracy: 84.71%\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.260972accuracy: 0.02%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.331024accuracy: 7.85%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.887540accuracy: 22.35%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.604375accuracy: 39.87%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.523998accuracy: 58.47%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.592212accuracy: 0.09%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.415752accuracy: 19.48%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.256750accuracy: 39.01%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.145979accuracy: 58.76%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.288505accuracy: 78.60%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.241876accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.159713accuracy: 20.11%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.337284accuracy: 40.23%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.114272accuracy: 60.42%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.134388accuracy: 80.67%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038864accuracy: 0.11%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.290318accuracy: 20.52%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.169037accuracy: 40.91%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.367036accuracy: 61.31%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.066922accuracy: 81.71%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.163589accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.100143accuracy: 20.61%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.053955accuracy: 41.11%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.103013accuracy: 61.68%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.186143accuracy: 82.27%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.189108accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.062651accuracy: 20.80%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.083414accuracy: 41.47%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.097075accuracy: 62.16%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.133140accuracy: 82.88%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.020233accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.066830accuracy: 20.88%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.059243accuracy: 41.67%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.075271accuracy: 62.42%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.054296accuracy: 83.24%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.030036accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.053914accuracy: 20.98%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.046944accuracy: 41.77%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.058560accuracy: 62.55%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.042638accuracy: 83.44%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.079563accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.085060accuracy: 21.01%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.030152accuracy: 41.91%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.033925accuracy: 62.76%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.090827accuracy: 83.62%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.068092accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.023001accuracy: 21.07%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.020684accuracy: 41.96%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.054706accuracy: 62.90%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.037779accuracy: 83.81%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.057601accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.005319accuracy: 21.09%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.017781accuracy: 42.10%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.083901accuracy: 63.04%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.134784accuracy: 83.98%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.026259accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.039214accuracy: 21.12%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.033425accuracy: 42.15%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.051166accuracy: 63.16%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.013221accuracy: 84.19%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.043929accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.070231accuracy: 21.13%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.048745accuracy: 42.14%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.024873accuracy: 63.11%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.012958accuracy: 84.14%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.011839accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.101872accuracy: 21.17%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.024261accuracy: 42.25%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.023891accuracy: 63.29%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.018055accuracy: 84.36%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.010014accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.012000accuracy: 21.17%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.011046accuracy: 42.26%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.013942accuracy: 63.36%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.012864accuracy: 84.46%\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.483198accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.735607accuracy: 10.13%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.604515accuracy: 27.98%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.293351accuracy: 46.99%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.207230accuracy: 66.23%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.386422accuracy: 0.09%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.273964accuracy: 19.86%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.486340accuracy: 39.74%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.225558accuracy: 59.68%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.358232accuracy: 79.81%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.153254accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.274446accuracy: 20.39%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.248186accuracy: 40.67%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062116accuracy: 61.05%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.324582accuracy: 81.48%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.076872accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.123588accuracy: 20.63%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.061501accuracy: 41.21%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.198748accuracy: 61.78%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.081733accuracy: 82.33%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.123425accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.236115accuracy: 20.80%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.106659accuracy: 41.53%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.028376accuracy: 62.23%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.096935accuracy: 82.94%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.013581accuracy: 0.11%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.184028accuracy: 20.88%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.067747accuracy: 41.62%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.145207accuracy: 62.46%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.014500accuracy: 83.28%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.028862accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.020649accuracy: 20.95%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.022631accuracy: 41.77%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.085245accuracy: 62.63%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.020432accuracy: 83.53%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.109280accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.129048accuracy: 21.09%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.016339accuracy: 42.02%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.025888accuracy: 62.94%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.003591accuracy: 83.82%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.014938accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.061620accuracy: 21.14%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.147383accuracy: 42.07%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.016647accuracy: 63.06%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.116827accuracy: 84.03%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.017894accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.016679accuracy: 21.15%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.125755accuracy: 42.18%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.019461accuracy: 63.23%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.033003accuracy: 84.16%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.008329accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.019755accuracy: 21.16%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.005799accuracy: 42.18%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.023261accuracy: 63.24%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.002051accuracy: 84.31%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.071020accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.060072accuracy: 21.17%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.010778accuracy: 42.25%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.059333accuracy: 63.30%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001065accuracy: 84.41%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.046721accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.127281accuracy: 21.24%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.001298accuracy: 42.38%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.003616accuracy: 63.45%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.107230accuracy: 84.56%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.010559accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.045979accuracy: 21.25%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.285141accuracy: 42.37%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.012997accuracy: 63.46%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.005571accuracy: 84.58%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.011058accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.028326accuracy: 21.28%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.015902accuracy: 42.42%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.088230accuracy: 63.52%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.002481accuracy: 84.65%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.012418accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.022589accuracy: 21.27%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.004840accuracy: 42.41%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.211331accuracy: 63.56%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.070012accuracy: 84.69%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.093005accuracy: 0.10%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.011268accuracy: 21.28%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.012853accuracy: 42.46%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.010366accuracy: 63.63%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.037362accuracy: 84.79%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.002985accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.094047accuracy: 21.28%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.100831accuracy: 42.45%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.010014accuracy: 63.66%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.082434accuracy: 84.86%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.017928accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000479accuracy: 21.29%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.011764accuracy: 42.49%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.011578accuracy: 63.68%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.021290accuracy: 84.86%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.004507accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.014642accuracy: 21.31%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000988accuracy: 42.52%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000903accuracy: 63.72%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.047265accuracy: 84.90%\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.365671accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.256171accuracy: 15.76%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.251030accuracy: 35.61%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.173727accuracy: 55.79%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.251507accuracy: 76.12%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.173463accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.055792accuracy: 20.80%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.158273accuracy: 41.43%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.284019accuracy: 62.10%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.012671accuracy: 82.90%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.229384accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.012934accuracy: 21.05%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.066840accuracy: 41.99%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.081808accuracy: 62.93%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.005280accuracy: 83.80%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.022001accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.090329accuracy: 21.19%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003793accuracy: 42.21%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.129123accuracy: 63.20%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.039976accuracy: 84.20%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.056557accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.018833accuracy: 21.24%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.131402accuracy: 42.34%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.040038accuracy: 63.39%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.079033accuracy: 84.46%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.023080accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.044880accuracy: 21.26%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.019663accuracy: 42.36%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000802accuracy: 63.44%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.022204accuracy: 84.57%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000922accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.015398accuracy: 21.31%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000882accuracy: 42.47%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.035513accuracy: 63.59%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.101427accuracy: 84.73%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.124453accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.018462accuracy: 21.30%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.114590accuracy: 42.46%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.002994accuracy: 63.65%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.008175accuracy: 84.84%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.004399accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000840accuracy: 21.33%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.008012accuracy: 42.51%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001035accuracy: 63.71%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.148253accuracy: 84.88%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.058993accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.006539accuracy: 21.31%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.036547accuracy: 42.55%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.034435accuracy: 63.75%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.003269accuracy: 84.97%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.003552accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.002472accuracy: 21.34%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.070840accuracy: 42.55%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.007568accuracy: 63.76%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.042738accuracy: 84.94%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000184accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.002171accuracy: 21.33%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.029149accuracy: 42.56%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.015428accuracy: 63.76%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.001337accuracy: 84.98%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.024968accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.003732accuracy: 21.33%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.005769accuracy: 42.51%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.015087accuracy: 63.77%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000498accuracy: 85.00%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000817accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.024052accuracy: 21.37%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000340accuracy: 42.62%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000916accuracy: 63.85%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.057885accuracy: 85.10%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.011319accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001224accuracy: 21.35%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000099accuracy: 42.61%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000667accuracy: 63.85%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.000172accuracy: 85.11%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000105accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.007215accuracy: 21.36%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.002553accuracy: 42.61%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.007088accuracy: 63.84%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.012199accuracy: 85.08%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.006881accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.011156accuracy: 21.36%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.002313accuracy: 42.65%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.034509accuracy: 63.87%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.000101accuracy: 85.11%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.052918accuracy: 0.10%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.000960accuracy: 21.40%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.012254accuracy: 42.69%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.008033accuracy: 63.97%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001181accuracy: 85.18%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.006075accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000188accuracy: 21.38%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000155accuracy: 42.62%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000288accuracy: 63.90%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.000190accuracy: 85.16%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.001369accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.005275accuracy: 21.38%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000934accuracy: 42.66%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.020053accuracy: 63.91%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.003013accuracy: 85.16%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.000343accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000361accuracy: 21.39%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000179accuracy: 42.68%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.001303accuracy: 63.91%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.002112accuracy: 85.14%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000273accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000019accuracy: 21.38%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000738accuracy: 42.60%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.000538accuracy: 63.91%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.001124accuracy: 85.17%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.033470accuracy: 0.10%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.000667accuracy: 21.41%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.000204accuracy: 42.67%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.004729accuracy: 63.93%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.017920accuracy: 85.23%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000074accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.000037accuracy: 21.40%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.010997accuracy: 42.67%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.005244accuracy: 63.92%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.026152accuracy: 85.17%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.000024accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.000911accuracy: 21.34%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000201accuracy: 42.61%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000102accuracy: 63.87%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.006812accuracy: 85.12%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.000238accuracy: 0.11%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.002757accuracy: 21.40%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.039409accuracy: 42.68%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.001396accuracy: 63.96%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000068accuracy: 85.25%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000436accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000313accuracy: 21.38%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000258accuracy: 42.66%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.003903accuracy: 63.94%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000602accuracy: 85.21%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.002858accuracy: 0.11%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.001565accuracy: 21.39%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.010425accuracy: 42.68%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.008691accuracy: 63.98%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.000819accuracy: 85.22%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000183accuracy: 0.11%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000007accuracy: 21.41%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.001160accuracy: 42.68%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000081accuracy: 63.97%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.016738accuracy: 85.25%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.075424accuracy: 0.10%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.000179accuracy: 21.41%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000035accuracy: 42.69%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.000023accuracy: 63.96%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.000290accuracy: 85.25%\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.361125accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.215731accuracy: 15.39%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.144111accuracy: 35.29%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.268330accuracy: 55.56%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.191061accuracy: 75.94%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.076371accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.048517accuracy: 20.81%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.230285accuracy: 41.58%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.054646accuracy: 62.27%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.138605accuracy: 83.08%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.068830accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.044509accuracy: 21.04%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.059908accuracy: 42.01%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.018601accuracy: 62.99%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.012281accuracy: 83.90%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.170884accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.003161accuracy: 21.21%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.009260accuracy: 42.25%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.059265accuracy: 63.24%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.109436accuracy: 84.20%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.003470accuracy: 0.11%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001802accuracy: 21.26%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.023837accuracy: 42.38%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.013720accuracy: 63.45%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.017793accuracy: 84.53%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.057645accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.002302accuracy: 21.26%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.047220accuracy: 42.37%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.006344accuracy: 63.49%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.109531accuracy: 84.61%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.017458accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003032accuracy: 21.30%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002714accuracy: 42.49%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001248accuracy: 63.66%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009219accuracy: 84.80%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001545accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.007316accuracy: 21.31%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001879accuracy: 42.52%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.008213accuracy: 63.73%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.002762accuracy: 84.90%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.010610accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001182accuracy: 21.33%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.007457accuracy: 42.52%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.011827accuracy: 63.68%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.002721accuracy: 84.86%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.005592accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.012436accuracy: 21.34%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000098accuracy: 42.55%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.008570accuracy: 63.74%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.046178accuracy: 84.93%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.004408accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.000834accuracy: 21.38%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.002777accuracy: 42.63%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.002503accuracy: 63.87%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.000175accuracy: 85.09%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000938accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.000407accuracy: 21.36%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.001057accuracy: 42.62%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.002705accuracy: 63.83%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000854accuracy: 85.03%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.002210accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.067344accuracy: 21.38%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000257accuracy: 42.66%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.003845accuracy: 63.89%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.048005accuracy: 85.09%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002762accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002013accuracy: 21.36%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000896accuracy: 42.62%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.010954accuracy: 63.86%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.031900accuracy: 85.05%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000611accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.001642accuracy: 21.34%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.004522accuracy: 42.59%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.006060accuracy: 63.84%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.011314accuracy: 85.08%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.008662accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.009272accuracy: 21.36%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000075accuracy: 42.57%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000992accuracy: 63.84%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.000337accuracy: 85.10%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000748accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.001409accuracy: 21.36%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.004748accuracy: 42.61%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.002683accuracy: 63.88%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.001084accuracy: 85.12%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000791accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.000525accuracy: 21.39%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.011635accuracy: 42.62%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.001696accuracy: 63.88%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.047992accuracy: 85.11%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.013888accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000453accuracy: 21.37%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000030accuracy: 42.66%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000343accuracy: 63.91%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.006679accuracy: 85.16%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.004248accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000171accuracy: 21.38%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000047accuracy: 42.66%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.009830accuracy: 63.95%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000100accuracy: 85.19%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.008383accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000479accuracy: 21.39%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.008110accuracy: 42.65%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000058accuracy: 63.93%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.001939accuracy: 85.17%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000022accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000214accuracy: 21.40%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.000302accuracy: 42.70%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.003555accuracy: 63.96%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000881accuracy: 85.20%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000046accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.001727accuracy: 21.37%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.001070accuracy: 42.62%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000640accuracy: 63.88%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.001022accuracy: 85.16%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000112accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.020086accuracy: 21.40%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000192accuracy: 42.70%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.000038accuracy: 63.98%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.000292accuracy: 85.25%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.028151accuracy: 0.10%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.014150accuracy: 21.30%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000470accuracy: 42.57%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.100759accuracy: 63.85%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000091accuracy: 85.14%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.009804accuracy: 0.11%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.000829accuracy: 21.40%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.000324accuracy: 42.72%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000213accuracy: 64.00%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000236accuracy: 85.27%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.000874accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.000156accuracy: 21.38%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.014151accuracy: 42.66%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.001005accuracy: 63.94%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.079301accuracy: 85.21%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.002169accuracy: 0.11%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000053accuracy: 21.41%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.005527accuracy: 42.67%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000055accuracy: 63.93%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.004353accuracy: 85.17%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.026647accuracy: 0.10%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000409accuracy: 21.41%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.000069accuracy: 42.69%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.000063accuracy: 64.00%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.000013accuracy: 85.29%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.140453accuracy: 0.10%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.014007accuracy: 21.40%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.005931accuracy: 42.70%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.014324accuracy: 63.96%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.011021accuracy: 85.21%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.013035accuracy: 0.10%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.000182accuracy: 21.39%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000081accuracy: 42.69%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.001764accuracy: 63.95%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.000300accuracy: 85.23%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.002078accuracy: 0.11%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.000037accuracy: 21.36%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.000079accuracy: 42.65%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.006531accuracy: 63.94%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000016accuracy: 85.20%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000750accuracy: 0.11%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.014101accuracy: 21.35%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.000738accuracy: 42.63%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.000015accuracy: 63.90%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000422accuracy: 85.20%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.000449accuracy: 0.11%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000027accuracy: 21.41%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.000027accuracy: 42.70%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.000329accuracy: 63.99%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000045accuracy: 85.29%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.030312accuracy: 0.10%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000148accuracy: 21.39%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000072accuracy: 42.68%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000411accuracy: 63.97%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.016190accuracy: 85.24%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.006710accuracy: 0.11%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000683accuracy: 21.40%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000445accuracy: 42.70%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.016425accuracy: 63.97%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.057748accuracy: 85.24%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000020accuracy: 0.11%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.000696accuracy: 21.40%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.021532accuracy: 42.67%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.001410accuracy: 63.94%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000279accuracy: 85.22%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.000051accuracy: 0.11%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000057accuracy: 21.41%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000187accuracy: 42.69%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000028accuracy: 64.01%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000261accuracy: 85.30%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.003578accuracy: 0.11%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.001058accuracy: 21.40%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.000144accuracy: 42.66%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.003972accuracy: 63.92%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.000133accuracy: 85.21%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.001216accuracy: 0.11%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.030596accuracy: 21.39%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000709accuracy: 42.66%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000426accuracy: 63.95%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000014accuracy: 85.22%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.000015accuracy: 0.11%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.023864accuracy: 21.38%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.001913accuracy: 42.66%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.009404accuracy: 63.96%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000297accuracy: 85.24%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000155accuracy: 0.11%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.000139accuracy: 21.42%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000950accuracy: 42.71%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000446accuracy: 64.02%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000682accuracy: 85.30%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.002508accuracy: 0.11%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.000035accuracy: 21.42%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000010accuracy: 42.73%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.000733accuracy: 64.02%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000005accuracy: 85.33%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000015accuracy: 0.11%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.003460accuracy: 21.37%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.076297accuracy: 42.66%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.012508accuracy: 63.94%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.001226accuracy: 85.23%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000568accuracy: 0.11%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.000360accuracy: 21.38%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000581accuracy: 42.66%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.000236accuracy: 63.95%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000038accuracy: 85.23%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000046accuracy: 0.11%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.014217accuracy: 21.41%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000065accuracy: 42.73%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.006552accuracy: 64.03%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000097accuracy: 85.34%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000032accuracy: 0.11%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000045accuracy: 21.41%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.003069accuracy: 42.67%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.009571accuracy: 63.92%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000035accuracy: 85.20%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000107accuracy: 0.11%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000128accuracy: 21.41%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000006accuracy: 42.73%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.056740accuracy: 64.01%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.003754accuracy: 85.31%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000146accuracy: 0.11%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.002206accuracy: 21.41%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.000132accuracy: 42.71%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.002089accuracy: 63.99%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000975accuracy: 85.26%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000009accuracy: 0.11%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000179accuracy: 21.39%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000212accuracy: 42.71%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000227accuracy: 64.00%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.001336accuracy: 85.29%\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324400accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.355080accuracy: 12.83%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.139620accuracy: 32.70%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.369486accuracy: 52.87%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.191348accuracy: 73.21%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.055686accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.124652accuracy: 20.88%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.026103accuracy: 41.65%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.050447accuracy: 62.38%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.009289accuracy: 83.10%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.109757accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.004641accuracy: 21.08%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.028371accuracy: 41.98%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.076623accuracy: 62.86%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.051451accuracy: 83.80%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.007215accuracy: 0.11%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.110316accuracy: 21.17%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.002235accuracy: 42.21%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.115982accuracy: 63.24%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.020712accuracy: 84.23%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.049168accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.004725accuracy: 21.20%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.036623accuracy: 42.28%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.036355accuracy: 63.38%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.025968accuracy: 84.45%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.111035accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.003089accuracy: 21.23%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.074819accuracy: 42.38%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.003452accuracy: 63.51%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.002641accuracy: 84.65%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.025258accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.004517accuracy: 21.27%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.014485accuracy: 42.44%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001138accuracy: 63.59%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.005887accuracy: 84.70%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.004276accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.023657accuracy: 21.34%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.009420accuracy: 42.53%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001398accuracy: 63.67%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009429accuracy: 84.86%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.154041accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.056742accuracy: 21.32%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.016018accuracy: 42.47%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.017671accuracy: 63.66%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.003069accuracy: 84.81%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.011103accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000270accuracy: 21.37%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.004069accuracy: 42.55%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.098542accuracy: 63.76%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.002416accuracy: 84.96%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000471accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.074483accuracy: 21.33%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.004363accuracy: 42.55%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.012658accuracy: 63.78%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.070719accuracy: 84.97%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.002300accuracy: 0.11%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.035998accuracy: 21.37%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.010487accuracy: 42.58%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.031343accuracy: 63.80%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.058117accuracy: 85.03%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.074662accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.003459accuracy: 21.32%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.004021accuracy: 42.57%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000246accuracy: 63.83%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.000887accuracy: 85.03%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002554accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.060088accuracy: 21.37%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.013114accuracy: 42.60%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000537accuracy: 63.83%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.000033accuracy: 85.03%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000131accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.000804accuracy: 21.37%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.000416accuracy: 42.62%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000031accuracy: 63.87%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001194accuracy: 85.11%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000139accuracy: 0.11%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.001288accuracy: 21.37%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.000193accuracy: 42.61%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.021451accuracy: 63.81%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.005435accuracy: 85.06%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.002866accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.001980accuracy: 21.39%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.002642accuracy: 42.63%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000112accuracy: 63.87%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.010270accuracy: 85.11%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.013686accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.006774accuracy: 21.36%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.000147accuracy: 42.60%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.078533accuracy: 63.85%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.001151accuracy: 85.11%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.111774accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000245accuracy: 21.37%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.000957accuracy: 42.67%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.004738accuracy: 63.87%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.001220accuracy: 85.08%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.009728accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.000130accuracy: 21.39%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.000133accuracy: 42.68%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000242accuracy: 63.94%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.000071accuracy: 85.20%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.010406accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000095accuracy: 21.40%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000198accuracy: 42.68%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.000709accuracy: 63.94%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.030134accuracy: 85.20%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.000340accuracy: 0.11%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.000262accuracy: 21.37%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.011874accuracy: 42.64%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.024170accuracy: 63.90%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.009464accuracy: 85.16%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000588accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.002084accuracy: 21.40%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.000544accuracy: 42.64%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.000074accuracy: 63.89%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.000157accuracy: 85.13%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.000514accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.007003accuracy: 21.39%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000088accuracy: 42.67%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.013748accuracy: 63.96%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.002045accuracy: 85.15%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.016445accuracy: 0.10%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.076065accuracy: 21.38%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.068079accuracy: 42.64%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.000177accuracy: 63.92%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.002151accuracy: 85.15%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.005137accuracy: 0.11%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.001406accuracy: 21.39%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.022880accuracy: 42.67%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000480accuracy: 63.94%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.003265accuracy: 85.21%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.004142accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.085007accuracy: 21.40%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.000336accuracy: 42.66%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.001696accuracy: 63.90%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.000247accuracy: 85.17%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.000048accuracy: 0.11%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.003457accuracy: 21.37%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.001744accuracy: 42.67%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.000795accuracy: 63.94%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.036986accuracy: 85.21%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000162accuracy: 0.11%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.000166accuracy: 21.36%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.028970accuracy: 42.66%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.038035accuracy: 63.91%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.002920accuracy: 85.18%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.047190accuracy: 0.10%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.008534accuracy: 21.39%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.004051accuracy: 42.68%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.001276accuracy: 63.98%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.023431accuracy: 85.25%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.015099accuracy: 0.10%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.048831accuracy: 21.36%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.000107accuracy: 42.63%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.028542accuracy: 63.91%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.001222accuracy: 85.18%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.000124accuracy: 0.11%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.002443accuracy: 21.38%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.003497accuracy: 42.67%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000178accuracy: 63.96%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.000612accuracy: 85.24%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.000216accuracy: 0.11%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.000780accuracy: 21.34%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.063839accuracy: 42.58%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.001184accuracy: 63.88%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.000332accuracy: 85.09%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.009864accuracy: 0.11%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.000336accuracy: 21.40%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.022610accuracy: 42.66%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.005740accuracy: 63.95%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.024770accuracy: 85.23%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.001700accuracy: 0.11%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.000037accuracy: 21.39%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.000329accuracy: 42.71%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.000777accuracy: 64.02%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.000061accuracy: 85.32%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000016accuracy: 0.11%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.000177accuracy: 21.32%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.000344accuracy: 42.58%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.008343accuracy: 63.84%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.000382accuracy: 85.12%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.000030accuracy: 0.11%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.021710accuracy: 21.36%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.000427accuracy: 42.62%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.001579accuracy: 63.88%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.002619accuracy: 85.12%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.006969accuracy: 0.11%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.000061accuracy: 21.38%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.000016accuracy: 42.66%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.000010accuracy: 63.93%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.000087accuracy: 85.18%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.006008accuracy: 0.11%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.000019accuracy: 21.39%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.002255accuracy: 42.65%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.000199accuracy: 63.91%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.019464accuracy: 85.18%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000727accuracy: 0.11%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.004229accuracy: 21.37%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.000058accuracy: 42.63%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.000245accuracy: 63.93%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.000069accuracy: 85.20%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.003888accuracy: 0.11%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.000418accuracy: 21.42%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.001058accuracy: 42.73%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.005255accuracy: 64.02%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.000031accuracy: 85.29%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000095accuracy: 0.11%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.026422accuracy: 21.38%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.000004accuracy: 42.65%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.000059accuracy: 63.92%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000039accuracy: 85.20%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.000416accuracy: 0.11%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.003550accuracy: 21.41%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.000156accuracy: 42.68%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.049688accuracy: 63.95%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000164accuracy: 85.22%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.000007accuracy: 0.11%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.000104accuracy: 21.37%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.000618accuracy: 42.65%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.023313accuracy: 63.90%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000237accuracy: 85.16%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.000253accuracy: 0.11%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.020993accuracy: 21.40%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.000039accuracy: 42.71%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.001620accuracy: 63.99%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000037accuracy: 85.28%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000095accuracy: 0.11%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.003643accuracy: 21.34%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.000067accuracy: 42.58%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.000012accuracy: 63.88%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.008761accuracy: 85.17%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000655accuracy: 0.11%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.000004accuracy: 21.40%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.000389accuracy: 42.71%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.000008accuracy: 63.98%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.000284accuracy: 85.28%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000171accuracy: 0.11%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.000110accuracy: 21.41%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.000798accuracy: 42.71%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.000003accuracy: 64.02%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.000091accuracy: 85.32%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.113840accuracy: 0.10%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.000236accuracy: 21.40%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.013105accuracy: 42.65%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.000147accuracy: 63.91%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.016396accuracy: 85.17%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.000571accuracy: 0.11%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.000572accuracy: 21.37%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.000062accuracy: 42.66%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.000319accuracy: 63.94%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.001112accuracy: 85.20%\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.000751accuracy: 0.11%\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.022852accuracy: 21.38%\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.000533accuracy: 42.66%\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.002229accuracy: 63.94%\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.000256accuracy: 85.20%\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.000239accuracy: 0.11%\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.000121accuracy: 21.41%\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.000028accuracy: 42.70%\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.000154accuracy: 63.99%\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.000014accuracy: 85.29%\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.000335accuracy: 0.11%\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.002665accuracy: 21.37%\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.002486accuracy: 42.63%\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.040532accuracy: 63.89%\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.002998accuracy: 85.17%\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.010947accuracy: 0.10%\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.000596accuracy: 21.39%\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.082804accuracy: 42.68%\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.002244accuracy: 63.95%\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.000098accuracy: 85.26%\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.000008accuracy: 0.11%\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.000029accuracy: 21.41%\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.005644accuracy: 42.72%\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.000800accuracy: 63.99%\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.000235accuracy: 85.28%\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.000046accuracy: 0.11%\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.070097accuracy: 21.40%\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.000739accuracy: 42.67%\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.000025accuracy: 63.96%\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.000013accuracy: 85.24%\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000349accuracy: 0.11%\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.000055accuracy: 21.38%\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.000228accuracy: 42.65%\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.000950accuracy: 63.93%\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.000250accuracy: 85.19%\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.116036accuracy: 0.10%\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.017835accuracy: 21.36%\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.000108accuracy: 42.64%\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.000004accuracy: 63.91%\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.000309accuracy: 85.22%\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.002403accuracy: 0.11%\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.000135accuracy: 21.44%\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.000089accuracy: 42.76%\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.000003accuracy: 64.03%\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.022267accuracy: 85.28%\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.022246accuracy: 0.10%\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.000059accuracy: 21.40%\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.007565accuracy: 42.69%\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.000031accuracy: 63.99%\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.041997accuracy: 85.26%\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000793accuracy: 0.11%\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.000070accuracy: 21.39%\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.001087accuracy: 42.69%\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.000033accuracy: 63.98%\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.000041accuracy: 85.28%\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.000012accuracy: 0.11%\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.000008accuracy: 21.41%\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.66%\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.000850accuracy: 63.95%\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.000029accuracy: 85.20%\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.000587accuracy: 0.11%\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.009094accuracy: 21.42%\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.000811accuracy: 42.69%\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.003583accuracy: 63.97%\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.000338accuracy: 85.23%\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.000346accuracy: 0.11%\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.000157accuracy: 21.41%\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.000016accuracy: 42.71%\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.001665accuracy: 64.01%\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.000003accuracy: 85.29%\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.000152accuracy: 0.11%\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.000135accuracy: 21.40%\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.005055accuracy: 42.69%\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.064729accuracy: 63.96%\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.000137accuracy: 85.21%\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.000026accuracy: 0.11%\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.003431accuracy: 21.42%\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.011886accuracy: 42.72%\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.000275accuracy: 63.99%\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.000071accuracy: 85.29%\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.000003accuracy: 0.11%\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.000042accuracy: 21.40%\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.035787accuracy: 42.66%\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.000355accuracy: 63.93%\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.018480accuracy: 85.22%\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.000001accuracy: 0.11%\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.002096accuracy: 21.41%\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.000064accuracy: 42.70%\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.000151accuracy: 64.00%\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.000330accuracy: 85.26%\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.002391accuracy: 0.11%\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.000019accuracy: 21.39%\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.000232accuracy: 42.70%\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.017772accuracy: 63.95%\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.001501accuracy: 85.21%\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.000072accuracy: 0.11%\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.000324accuracy: 21.41%\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.000003accuracy: 42.74%\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.000813accuracy: 64.06%\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.000008accuracy: 85.35%\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.000216accuracy: 0.11%\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.000006accuracy: 21.41%\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.000005accuracy: 42.72%\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.004244accuracy: 64.00%\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.29%\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.000080accuracy: 0.11%\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.008995accuracy: 21.41%\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.000009accuracy: 42.66%\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.011936accuracy: 63.93%\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.001147accuracy: 85.22%\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.001666accuracy: 0.11%\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.000002accuracy: 21.39%\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.000011accuracy: 42.68%\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.000005accuracy: 63.97%\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.000002accuracy: 85.27%\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.001142accuracy: 0.11%\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.001002accuracy: 21.38%\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.002690accuracy: 42.63%\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.000042accuracy: 63.91%\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.054315accuracy: 85.20%\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.002115accuracy: 0.11%\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.000167accuracy: 21.43%\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.025707accuracy: 42.72%\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.007222accuracy: 64.00%\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.028074accuracy: 85.28%\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.000022accuracy: 0.11%\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.128232accuracy: 21.41%\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.008540accuracy: 42.69%\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.010460accuracy: 63.98%\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.003701accuracy: 85.27%\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.000086accuracy: 0.11%\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.000094accuracy: 21.41%\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.000005accuracy: 42.71%\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.000016accuracy: 63.98%\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.000005accuracy: 85.26%\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.001145accuracy: 0.11%\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.000010accuracy: 21.41%\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.000015accuracy: 42.72%\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.007742accuracy: 63.99%\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.000325accuracy: 85.30%\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.001227accuracy: 0.11%\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.000461accuracy: 21.40%\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.000344accuracy: 42.70%\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.003265accuracy: 63.98%\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.000324accuracy: 85.30%\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.000003accuracy: 0.11%\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.000162accuracy: 21.40%\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.000254accuracy: 42.71%\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.000072accuracy: 64.03%\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.35%\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000004accuracy: 0.11%\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.000133accuracy: 21.40%\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.000125accuracy: 42.65%\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.000498accuracy: 63.89%\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.025867accuracy: 85.17%\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000028accuracy: 0.11%\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.054424accuracy: 21.39%\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.000051accuracy: 42.67%\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.000689accuracy: 63.95%\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.000085accuracy: 85.26%\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.000059accuracy: 0.11%\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.000430accuracy: 21.40%\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.000008accuracy: 42.69%\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.006438accuracy: 63.97%\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.001054accuracy: 85.24%\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.001131accuracy: 0.11%\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.000014accuracy: 21.42%\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.000115accuracy: 42.72%\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.000061accuracy: 64.00%\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.056077accuracy: 85.30%\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000011accuracy: 0.11%\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.000096accuracy: 21.40%\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.000398accuracy: 42.68%\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.000026accuracy: 63.95%\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.001107accuracy: 85.25%\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.020598accuracy: 0.10%\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.000050accuracy: 21.38%\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.000004accuracy: 42.68%\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.000373accuracy: 63.98%\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.000026accuracy: 85.29%\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.009670accuracy: 0.11%\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.026800accuracy: 21.40%\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.001742accuracy: 42.69%\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 64.01%\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.000001accuracy: 85.32%\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000826accuracy: 0.11%\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.000827accuracy: 21.37%\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.000193accuracy: 42.66%\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.003833accuracy: 63.97%\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.000624accuracy: 85.26%\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000005accuracy: 0.11%\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.000106accuracy: 21.40%\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.000021accuracy: 42.70%\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.000064accuracy: 63.98%\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.003919accuracy: 85.23%\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.000272accuracy: 0.11%\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.000061accuracy: 21.42%\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.000282accuracy: 42.70%\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.000080accuracy: 64.02%\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.000022accuracy: 85.33%\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.000021accuracy: 0.11%\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.103462accuracy: 21.39%\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.000024accuracy: 42.68%\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.000013accuracy: 63.97%\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.000327accuracy: 85.24%\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.000007accuracy: 0.11%\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.001380accuracy: 21.40%\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.000292accuracy: 42.71%\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.000004accuracy: 64.02%\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.000376accuracy: 85.31%\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.000003accuracy: 0.11%\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.000203accuracy: 21.40%\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.000036accuracy: 42.71%\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.001195accuracy: 64.01%\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.000735accuracy: 85.29%\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.000002accuracy: 0.11%\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.000104accuracy: 21.42%\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.000046accuracy: 42.72%\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.000362accuracy: 64.00%\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.000023accuracy: 85.28%\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.005309accuracy: 0.11%\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.000319accuracy: 21.41%\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.001473accuracy: 42.71%\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 64.04%\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.000075accuracy: 85.34%\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.000091accuracy: 0.11%\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.005685accuracy: 21.41%\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.000002accuracy: 42.71%\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.000135accuracy: 64.01%\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.000073accuracy: 85.28%\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.005915accuracy: 0.11%\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.000109accuracy: 21.41%\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.000008accuracy: 42.71%\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.000003accuracy: 64.00%\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.000976accuracy: 85.27%\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.000106accuracy: 0.11%\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.000697accuracy: 21.41%\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.000025accuracy: 42.71%\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.000097accuracy: 63.99%\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.004600accuracy: 85.27%\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000035accuracy: 0.11%\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.000841accuracy: 21.40%\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.000200accuracy: 42.69%\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.013994accuracy: 63.97%\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.002006accuracy: 85.26%\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.030816accuracy: 0.10%\n",
      "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.000037accuracy: 21.37%\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.031550accuracy: 42.66%\n",
      "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.000001accuracy: 63.95%\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.000014accuracy: 85.26%\n",
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.292167accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.632642accuracy: 11.85%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.409456accuracy: 27.77%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.059157accuracy: 45.16%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.981519accuracy: 63.25%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.964261accuracy: 0.09%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.799456accuracy: 18.78%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.709106accuracy: 37.73%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.610431accuracy: 56.78%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.591240accuracy: 75.91%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.461467accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.403830accuracy: 19.60%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.456923accuracy: 39.16%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.428659accuracy: 58.84%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.383278accuracy: 78.47%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.301205accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.450827accuracy: 19.98%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.369717accuracy: 39.91%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.283350accuracy: 59.93%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.246201accuracy: 79.92%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.220439accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.356351accuracy: 20.30%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.200453accuracy: 40.37%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.211384accuracy: 60.54%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.258956accuracy: 80.78%\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309629accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.402063accuracy: 17.98%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.252703accuracy: 37.66%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.052988accuracy: 57.65%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.176395accuracy: 77.88%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.109932accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.047911accuracy: 20.62%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.059953accuracy: 41.23%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.090782accuracy: 61.87%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.043590accuracy: 82.59%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.133175accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.032824accuracy: 20.98%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.120237accuracy: 41.82%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.022526accuracy: 62.70%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.166041accuracy: 83.53%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.043809accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.162750accuracy: 21.16%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.132996accuracy: 42.15%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.081210accuracy: 63.09%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.177051accuracy: 84.03%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.059775accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.028702accuracy: 21.20%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.102692accuracy: 42.29%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.038735accuracy: 63.36%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.025215accuracy: 84.44%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.036242accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.008250accuracy: 21.27%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.011007accuracy: 42.39%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.016126accuracy: 63.49%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.085163accuracy: 84.56%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.005821accuracy: 0.11%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.043673accuracy: 21.33%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.020436accuracy: 42.52%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.053902accuracy: 63.65%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.007069accuracy: 84.76%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.006339accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000814accuracy: 21.27%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.006204accuracy: 42.48%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.014627accuracy: 63.70%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.018403accuracy: 84.86%\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324757accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.301766accuracy: 17.68%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.312292accuracy: 37.18%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.318011accuracy: 56.89%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.148182accuracy: 76.86%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.086330accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.310498accuracy: 20.41%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.036598accuracy: 40.85%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.292961accuracy: 61.20%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.216084accuracy: 81.66%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.090723accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.191604accuracy: 20.75%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.132963accuracy: 41.33%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.045041accuracy: 61.98%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.026672accuracy: 82.61%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.130332accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.015021accuracy: 20.91%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.269575accuracy: 41.69%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.066981accuracy: 62.43%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.064928accuracy: 83.19%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.080249accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.010322accuracy: 21.00%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.021065accuracy: 41.87%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.139228accuracy: 62.69%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.049389accuracy: 83.55%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.065673accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.031294accuracy: 21.06%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.074245accuracy: 42.01%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.008865accuracy: 62.89%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.032172accuracy: 83.74%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.030864accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.104275accuracy: 21.06%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.028974accuracy: 42.06%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.034771accuracy: 63.06%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.035544accuracy: 84.03%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.015380accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.031240accuracy: 21.09%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.002385accuracy: 42.10%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.021430accuracy: 63.09%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.022418accuracy: 84.09%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002488accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.029825accuracy: 21.15%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.006910accuracy: 42.15%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.002509accuracy: 63.22%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.007567accuracy: 84.27%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.057016accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.009483accuracy: 21.25%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.120370accuracy: 42.31%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.026395accuracy: 63.41%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.023557accuracy: 84.42%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.037393accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.063984accuracy: 21.23%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.011501accuracy: 42.33%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.025787accuracy: 63.43%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.005666accuracy: 84.52%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.013966accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.021114accuracy: 21.22%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.140632accuracy: 42.34%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.029727accuracy: 63.44%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.015777accuracy: 84.55%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.025142accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.052260accuracy: 21.25%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.150038accuracy: 42.36%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.008479accuracy: 63.49%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.004497accuracy: 84.61%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.008720accuracy: 0.11%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.038948accuracy: 21.27%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.021316accuracy: 42.43%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.029343accuracy: 63.57%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.006275accuracy: 84.70%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.016327accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.016869accuracy: 21.29%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.013892accuracy: 42.46%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.005253accuracy: 63.62%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.014342accuracy: 84.77%\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307495accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.342472accuracy: 18.27%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.243130accuracy: 37.65%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.293062accuracy: 57.47%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.151733accuracy: 77.43%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.081000accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.124317accuracy: 20.35%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.248334accuracy: 40.64%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.172968accuracy: 61.02%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.212171accuracy: 81.47%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.116064accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.069387accuracy: 20.67%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.089653accuracy: 41.26%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.083230accuracy: 61.85%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.105948accuracy: 82.45%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038208accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.045977accuracy: 20.84%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.125878accuracy: 41.54%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.067018accuracy: 62.27%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.147873accuracy: 82.97%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.086282accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.096191accuracy: 20.96%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.057069accuracy: 41.78%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.083771accuracy: 62.60%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.063275accuracy: 83.37%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.023071accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.057423accuracy: 21.01%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.129884accuracy: 41.92%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.095329accuracy: 62.84%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.103784accuracy: 83.71%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.073607accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.043797accuracy: 21.03%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.107680accuracy: 42.00%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.080141accuracy: 62.92%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.026565accuracy: 83.80%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.014636accuracy: 0.11%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.029502accuracy: 21.09%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.009715accuracy: 42.13%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.020134accuracy: 63.11%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.071878accuracy: 84.01%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.011890accuracy: 0.11%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.206980accuracy: 21.15%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.028487accuracy: 42.15%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.042201accuracy: 63.17%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.025384accuracy: 84.17%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.016290accuracy: 0.11%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.057387accuracy: 21.15%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.095075accuracy: 42.23%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.021683accuracy: 63.23%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.015964accuracy: 84.26%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.001697accuracy: 0.11%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.134678accuracy: 21.21%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.023297accuracy: 42.25%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.016131accuracy: 63.38%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.017817accuracy: 84.39%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.098197accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.012256accuracy: 21.21%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.033833accuracy: 42.30%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.009431accuracy: 63.41%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.033713accuracy: 84.47%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.003971accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.014186accuracy: 21.25%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.015901accuracy: 42.33%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.013049accuracy: 63.46%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.045088accuracy: 84.56%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.060557accuracy: 0.10%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.003645accuracy: 21.22%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.017713accuracy: 42.34%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.050209accuracy: 63.44%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.005820accuracy: 84.56%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000852accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.019672accuracy: 21.26%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.008274accuracy: 42.38%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.003947accuracy: 63.50%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.036220accuracy: 84.63%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.073105accuracy: 0.10%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.003303accuracy: 21.25%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.042218accuracy: 42.40%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.004240accuracy: 63.57%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.011215accuracy: 84.73%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.004437accuracy: 0.11%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.001386accuracy: 21.25%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.007291accuracy: 42.41%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.002828accuracy: 63.58%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.212604accuracy: 84.70%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.002124accuracy: 0.11%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.020625accuracy: 21.25%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.003931accuracy: 42.42%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.002953accuracy: 63.58%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.076736accuracy: 84.70%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.044773accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.008304accuracy: 21.27%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.010199accuracy: 42.44%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.002498accuracy: 63.60%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.076045accuracy: 84.79%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000725accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.075396accuracy: 21.29%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.001554accuracy: 42.45%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.044872accuracy: 63.62%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.026008accuracy: 84.80%\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.313648accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.389387accuracy: 18.52%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.142899accuracy: 38.23%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.234305accuracy: 58.18%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.242135accuracy: 78.36%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.146280accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.059673accuracy: 20.55%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.365706accuracy: 40.96%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.052090accuracy: 61.39%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.052299accuracy: 81.86%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.254966accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.027106accuracy: 20.75%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.174155accuracy: 41.41%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.044999accuracy: 62.00%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.117621accuracy: 82.61%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.103820accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.127931accuracy: 20.85%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.123979accuracy: 41.59%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.151871accuracy: 62.20%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.164452accuracy: 82.90%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.222810accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.036119accuracy: 20.85%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.052285accuracy: 41.65%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.048276accuracy: 62.38%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.116313accuracy: 83.11%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.056553accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.065728accuracy: 20.98%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.029147accuracy: 41.77%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.007931accuracy: 62.48%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.060292accuracy: 83.21%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.035630accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.179727accuracy: 20.97%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.046971accuracy: 41.75%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.101445accuracy: 62.55%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009292accuracy: 83.35%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.173968accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.017192accuracy: 20.97%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.074025accuracy: 41.81%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.009880accuracy: 62.69%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.209564accuracy: 83.53%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.149312accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.035341accuracy: 21.01%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.028016accuracy: 41.94%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.037868accuracy: 62.82%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.038011accuracy: 83.60%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.037012accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.053033accuracy: 20.95%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.066839accuracy: 41.85%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.106455accuracy: 62.69%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.182055accuracy: 83.51%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.048547accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.158214accuracy: 20.97%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.079331accuracy: 41.86%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.049612accuracy: 62.75%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.033285accuracy: 83.58%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.053863accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.213903accuracy: 21.01%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.051610accuracy: 41.90%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.021969accuracy: 62.78%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.029840accuracy: 83.68%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.010238accuracy: 0.11%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.092808accuracy: 20.96%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.089604accuracy: 41.84%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.038655accuracy: 62.70%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.166175accuracy: 83.53%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.092080accuracy: 0.10%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.035599accuracy: 21.03%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.027185accuracy: 41.92%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.101412accuracy: 62.83%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.081767accuracy: 83.65%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.015775accuracy: 0.11%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.161290accuracy: 21.07%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.002928accuracy: 41.99%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.439537accuracy: 62.83%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.045080accuracy: 83.69%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.020343accuracy: 0.10%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.011310accuracy: 21.06%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.105133accuracy: 41.99%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.128905accuracy: 62.87%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.194297accuracy: 83.69%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.087404accuracy: 0.10%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.026409accuracy: 21.08%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.141285accuracy: 41.98%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.045641accuracy: 62.83%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.383720accuracy: 83.68%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.069312accuracy: 0.10%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.003173accuracy: 21.07%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.057898accuracy: 41.97%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.115850accuracy: 62.82%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.050051accuracy: 83.74%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.100816accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.011058accuracy: 21.07%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.115460accuracy: 41.95%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.008744accuracy: 62.83%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.104053accuracy: 83.69%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.108009accuracy: 0.10%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.081776accuracy: 21.07%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.022650accuracy: 41.97%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.165131accuracy: 62.88%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.055582accuracy: 83.75%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.043931accuracy: 0.10%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.122154accuracy: 21.07%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.252609accuracy: 42.04%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.012585accuracy: 62.94%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.043385accuracy: 83.77%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.089110accuracy: 0.10%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.065902accuracy: 21.02%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.136485accuracy: 41.94%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.041070accuracy: 62.81%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.154023accuracy: 83.75%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.131911accuracy: 0.10%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.043876accuracy: 21.05%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.044824accuracy: 41.92%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.036048accuracy: 62.83%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.070614accuracy: 83.69%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.010146accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.065143accuracy: 21.11%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.033137accuracy: 42.00%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.018112accuracy: 62.92%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.061725accuracy: 83.83%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.006418accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.006298accuracy: 21.08%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.006115accuracy: 41.99%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.011901accuracy: 62.85%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.001256accuracy: 83.75%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.100483accuracy: 0.10%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.180462accuracy: 20.97%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.078026accuracy: 41.83%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.166402accuracy: 62.73%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.033992accuracy: 83.56%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.011600accuracy: 0.11%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.007395accuracy: 21.03%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.003146accuracy: 41.96%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.177527accuracy: 62.87%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.195472accuracy: 83.77%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.139887accuracy: 0.10%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.022319accuracy: 21.03%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.027916accuracy: 42.00%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.012819accuracy: 62.95%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.117215accuracy: 83.81%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.087301accuracy: 0.10%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.022867accuracy: 21.01%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.007686accuracy: 41.84%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.138280accuracy: 62.73%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.054334accuracy: 83.66%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.017733accuracy: 0.11%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.007520accuracy: 21.03%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.009350accuracy: 41.98%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.055903accuracy: 62.87%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.015819accuracy: 83.72%\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.290082accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.436153accuracy: 18.42%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.255244accuracy: 38.03%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.208248accuracy: 58.03%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.136333accuracy: 78.04%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.195075accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.122654accuracy: 20.52%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.095261accuracy: 40.82%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.036312accuracy: 61.24%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.112888accuracy: 81.74%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.167072accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.115467accuracy: 20.70%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.104669accuracy: 41.28%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.043370accuracy: 61.79%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.201034accuracy: 82.36%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.044304accuracy: 0.11%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.152663accuracy: 20.81%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.123147accuracy: 41.44%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.223584accuracy: 62.03%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.079975accuracy: 82.59%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.018232accuracy: 0.11%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.116639accuracy: 20.86%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.009427accuracy: 41.52%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.196805accuracy: 62.15%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.107422accuracy: 82.86%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.040198accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.017458accuracy: 20.77%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.005640accuracy: 41.49%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.314668accuracy: 62.17%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.209497accuracy: 82.81%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.060955accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.097121accuracy: 20.85%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.133616accuracy: 41.53%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.100762accuracy: 62.25%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.049088accuracy: 82.93%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.023924accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.098086accuracy: 20.82%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.056291accuracy: 41.49%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.124322accuracy: 62.16%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.110128accuracy: 82.80%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.049636accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.007291accuracy: 20.89%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.092052accuracy: 41.67%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.095144accuracy: 62.41%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.065073accuracy: 83.17%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.180597accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.146463accuracy: 20.91%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.035505accuracy: 41.64%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.064267accuracy: 62.30%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.118984accuracy: 83.06%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.147079accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.099534accuracy: 20.79%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.206895accuracy: 41.55%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.131144accuracy: 62.27%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.084471accuracy: 83.01%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.087550accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.028885accuracy: 20.83%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.020801accuracy: 41.50%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.017368accuracy: 62.24%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.046884accuracy: 82.89%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.172580accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.079622accuracy: 20.91%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.032573accuracy: 41.73%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.085404accuracy: 62.46%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.081106accuracy: 83.11%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.098228accuracy: 0.10%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.010568accuracy: 20.93%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.110605accuracy: 41.77%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.070224accuracy: 62.50%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.020897accuracy: 83.25%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.071670accuracy: 0.10%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.124653accuracy: 20.88%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.038264accuracy: 41.62%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.029345accuracy: 62.38%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.098071accuracy: 83.18%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.071439accuracy: 0.10%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.045295accuracy: 20.88%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.176142accuracy: 41.70%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.063009accuracy: 62.49%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.092112accuracy: 83.26%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.142517accuracy: 0.10%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.082655accuracy: 20.96%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.248808accuracy: 41.72%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.079061accuracy: 62.51%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.087000accuracy: 83.30%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.134093accuracy: 0.10%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.109750accuracy: 20.93%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.080071accuracy: 41.70%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.168551accuracy: 62.48%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.028592accuracy: 83.19%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.015209accuracy: 0.11%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.050434accuracy: 20.93%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.037346accuracy: 41.75%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.102615accuracy: 62.51%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.041329accuracy: 83.18%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.016629accuracy: 0.11%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.025592accuracy: 20.92%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.025641accuracy: 41.73%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.093349accuracy: 62.52%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.047485accuracy: 83.25%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.013387accuracy: 0.11%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.073915accuracy: 20.91%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.139885accuracy: 41.61%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.066327accuracy: 62.35%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.226028accuracy: 83.14%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.070528accuracy: 0.10%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.134845accuracy: 20.86%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.028816accuracy: 41.64%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.114691accuracy: 62.44%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.078037accuracy: 83.18%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.069430accuracy: 0.10%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.078428accuracy: 20.88%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.043881accuracy: 41.67%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.038126accuracy: 62.39%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.057755accuracy: 83.23%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.127383accuracy: 0.10%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.024085accuracy: 20.87%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.032759accuracy: 41.64%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.011496accuracy: 62.47%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.034624accuracy: 83.22%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.014217accuracy: 0.11%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.170961accuracy: 20.88%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.021023accuracy: 41.63%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.031481accuracy: 62.42%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.009359accuracy: 83.20%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.047950accuracy: 0.10%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.076533accuracy: 20.95%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.089743accuracy: 41.72%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.081773accuracy: 62.51%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.064794accuracy: 83.22%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.028297accuracy: 0.10%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.156713accuracy: 20.92%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.085784accuracy: 41.73%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.160202accuracy: 62.57%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.046836accuracy: 83.36%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.095513accuracy: 0.10%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.090272accuracy: 20.92%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.039919accuracy: 41.69%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.193750accuracy: 62.45%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.055993accuracy: 83.22%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.118072accuracy: 0.10%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.091363accuracy: 20.95%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.008046accuracy: 41.70%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.030241accuracy: 62.46%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.266129accuracy: 83.09%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.117504accuracy: 0.10%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.113231accuracy: 20.86%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.025602accuracy: 41.68%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.051918accuracy: 62.50%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.050346accuracy: 83.26%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.072309accuracy: 0.10%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.066071accuracy: 20.91%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.077575accuracy: 41.68%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.029519accuracy: 62.38%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.042037accuracy: 83.07%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.049633accuracy: 0.10%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.050337accuracy: 20.85%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.233619accuracy: 41.62%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.210327accuracy: 62.30%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.089121accuracy: 83.07%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.029123accuracy: 0.10%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.086708accuracy: 20.89%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.216586accuracy: 41.65%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.099444accuracy: 62.32%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.177446accuracy: 83.03%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.085442accuracy: 0.10%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.118042accuracy: 20.77%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.073639accuracy: 41.52%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.154600accuracy: 62.28%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.072812accuracy: 82.90%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.050265accuracy: 0.10%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.152326accuracy: 20.89%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.159172accuracy: 41.62%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.156897accuracy: 62.29%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.119932accuracy: 83.03%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.104234accuracy: 0.10%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.031469accuracy: 20.81%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.072545accuracy: 41.57%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.029100accuracy: 62.23%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.028010accuracy: 82.85%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.100884accuracy: 0.10%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.092058accuracy: 20.78%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.067051accuracy: 41.46%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.090674accuracy: 62.17%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.063616accuracy: 82.92%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.076542accuracy: 0.10%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.093585accuracy: 20.91%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.076975accuracy: 41.64%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.014309accuracy: 62.28%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.051290accuracy: 82.99%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.085446accuracy: 0.10%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.058409accuracy: 20.74%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.107214accuracy: 41.41%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.172538accuracy: 61.96%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.188753accuracy: 82.65%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.048371accuracy: 0.10%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.074081accuracy: 20.90%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.143849accuracy: 41.42%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.094122accuracy: 62.02%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.052969accuracy: 82.62%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.047821accuracy: 0.10%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.012496accuracy: 20.82%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.092222accuracy: 41.47%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.049331accuracy: 62.09%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.046107accuracy: 82.69%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.066850accuracy: 0.10%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.050639accuracy: 20.73%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.098631accuracy: 41.32%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.153180accuracy: 61.98%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.107679accuracy: 82.64%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.061927accuracy: 0.10%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.254812accuracy: 20.69%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.104201accuracy: 41.42%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.041702accuracy: 61.94%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.114554accuracy: 82.59%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.082107accuracy: 0.10%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.124641accuracy: 20.78%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.046315accuracy: 41.39%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.024064accuracy: 62.03%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.080608accuracy: 82.50%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.053738accuracy: 0.10%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.072272accuracy: 20.76%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.095534accuracy: 41.27%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.101480accuracy: 61.85%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.044137accuracy: 82.42%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.056772accuracy: 0.10%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.097529accuracy: 20.66%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.180034accuracy: 41.31%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.260457accuracy: 61.80%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.053269accuracy: 82.37%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.110218accuracy: 0.10%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.177121accuracy: 20.68%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.073969accuracy: 41.32%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.017905accuracy: 61.84%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.169006accuracy: 82.37%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.117414accuracy: 0.10%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.106326accuracy: 20.59%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.040168accuracy: 41.11%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.112025accuracy: 61.62%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.141319accuracy: 81.99%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.308871accuracy: 0.10%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.125330accuracy: 20.60%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.036367accuracy: 41.12%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.331735accuracy: 61.45%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.044307accuracy: 81.86%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.136868accuracy: 0.10%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.096390accuracy: 20.68%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.101191accuracy: 41.10%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.024852accuracy: 61.61%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.150895accuracy: 82.11%\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305723accuracy: 0.01%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.445804accuracy: 18.20%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.255268accuracy: 37.69%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.204001accuracy: 57.47%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.140538accuracy: 77.49%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116730accuracy: 0.10%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.255702accuracy: 20.28%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.196008accuracy: 40.52%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.132262accuracy: 60.75%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.085221accuracy: 80.92%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.031751accuracy: 0.10%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.142439accuracy: 20.40%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.463307accuracy: 40.74%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.043688accuracy: 61.11%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.284066accuracy: 81.45%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.325036accuracy: 0.10%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.036122accuracy: 20.52%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.196548accuracy: 40.91%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.087187accuracy: 61.33%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.143065accuracy: 81.69%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.368564accuracy: 0.10%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.150653accuracy: 20.45%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.133422accuracy: 40.85%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.368659accuracy: 61.25%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.398014accuracy: 81.62%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.088892accuracy: 0.10%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.115003accuracy: 20.59%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.270414accuracy: 40.90%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.218517accuracy: 61.23%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.159497accuracy: 81.65%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.101213accuracy: 0.10%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.150644accuracy: 20.60%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.100342accuracy: 41.02%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.131925accuracy: 61.42%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.078920accuracy: 81.93%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.052712accuracy: 0.10%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.054403accuracy: 20.57%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.115893accuracy: 41.03%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.029697accuracy: 61.45%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.196741accuracy: 81.94%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.147301accuracy: 0.10%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.141689accuracy: 20.65%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.056557accuracy: 41.23%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.422159accuracy: 61.73%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.169063accuracy: 82.26%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.074441accuracy: 0.10%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.064107accuracy: 20.65%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.097723accuracy: 41.16%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.078078accuracy: 61.63%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.149855accuracy: 82.13%\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.066044accuracy: 0.10%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.117854accuracy: 20.52%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.171607accuracy: 40.97%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.157007accuracy: 61.43%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.049446accuracy: 81.99%\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.152636accuracy: 0.10%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.089170accuracy: 20.59%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.081732accuracy: 40.97%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.066492accuracy: 61.57%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.108125accuracy: 82.10%\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.086012accuracy: 0.10%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.117260accuracy: 20.81%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.202494accuracy: 41.31%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.127072accuracy: 61.78%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.108077accuracy: 82.23%\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.244999accuracy: 0.10%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.496529accuracy: 20.68%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.101778accuracy: 41.20%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.109892accuracy: 61.64%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.080858accuracy: 82.19%\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.331352accuracy: 0.10%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.068597accuracy: 20.67%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.170164accuracy: 41.22%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.110670accuracy: 61.65%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.081059accuracy: 82.13%\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.117242accuracy: 0.10%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.160592accuracy: 20.60%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.138778accuracy: 41.18%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.132854accuracy: 61.66%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.092803accuracy: 82.21%\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.088240accuracy: 0.10%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.093416accuracy: 20.60%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.141849accuracy: 41.12%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.305072accuracy: 61.60%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.232158accuracy: 82.15%\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.308627accuracy: 0.09%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.180475accuracy: 20.60%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.038986accuracy: 41.05%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.136827accuracy: 61.52%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.078399accuracy: 82.05%\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.110131accuracy: 0.10%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.104365accuracy: 20.68%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.125228accuracy: 41.14%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.111997accuracy: 61.63%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.033609accuracy: 82.19%\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.089701accuracy: 0.10%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.071039accuracy: 20.70%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.118488accuracy: 41.25%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.209982accuracy: 61.75%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.034379accuracy: 82.30%\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.057178accuracy: 0.10%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.043005accuracy: 20.66%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.199925accuracy: 41.17%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.076901accuracy: 61.65%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.025102accuracy: 82.11%\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.095863accuracy: 0.10%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.059521accuracy: 20.54%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.104697accuracy: 41.10%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.226255accuracy: 61.56%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.164782accuracy: 82.01%\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.022466accuracy: 0.11%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.090238accuracy: 20.66%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.214344accuracy: 41.04%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.144223accuracy: 61.55%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.151806accuracy: 81.97%\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.026121accuracy: 0.11%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.172100accuracy: 20.65%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.130462accuracy: 41.23%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.071593accuracy: 61.78%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.048268accuracy: 82.21%\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.147466accuracy: 0.10%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.117369accuracy: 20.58%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.141612accuracy: 41.09%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.125137accuracy: 61.62%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.031094accuracy: 82.06%\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.207037accuracy: 0.10%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.129221accuracy: 20.58%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.083641accuracy: 41.10%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.062096accuracy: 61.64%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.129297accuracy: 82.08%\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.117071accuracy: 0.10%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.088506accuracy: 20.55%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.195083accuracy: 40.97%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.111543accuracy: 61.40%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.043605accuracy: 81.95%\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.195378accuracy: 0.10%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.068794accuracy: 20.59%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.166906accuracy: 41.02%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.007331accuracy: 61.36%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.071747accuracy: 81.81%\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.088184accuracy: 0.10%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.125301accuracy: 20.51%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.140042accuracy: 40.92%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.117360accuracy: 61.36%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.101216accuracy: 81.66%\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.045322accuracy: 0.10%\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.115787accuracy: 20.56%\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.101060accuracy: 41.06%\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.143049accuracy: 61.42%\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.090329accuracy: 81.84%\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.110184accuracy: 0.10%\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.277698accuracy: 20.56%\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.154051accuracy: 40.94%\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.097378accuracy: 61.33%\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.082307accuracy: 81.75%\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.093904accuracy: 0.10%\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.088398accuracy: 20.42%\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.058081accuracy: 40.83%\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.077916accuracy: 61.24%\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.222084accuracy: 81.66%\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.095340accuracy: 0.10%\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.213425accuracy: 20.37%\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.202817accuracy: 40.69%\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.114005accuracy: 61.04%\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.082871accuracy: 81.46%\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.114156accuracy: 0.10%\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.064472accuracy: 20.50%\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.080065accuracy: 40.85%\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.055406accuracy: 61.21%\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.079031accuracy: 81.59%\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.074208accuracy: 0.10%\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.127745accuracy: 20.53%\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.259135accuracy: 40.80%\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.122240accuracy: 61.19%\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.080046accuracy: 81.58%\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.038365accuracy: 0.11%\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.178913accuracy: 20.57%\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.019679accuracy: 40.99%\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.128432accuracy: 61.31%\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.271884accuracy: 81.70%\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.104294accuracy: 0.10%\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.243155accuracy: 20.40%\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.094955accuracy: 40.82%\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.327016accuracy: 61.27%\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.083855accuracy: 81.61%\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.100755accuracy: 0.10%\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.137555accuracy: 20.51%\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.251718accuracy: 40.77%\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.133232accuracy: 61.12%\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.033900accuracy: 81.50%\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.083053accuracy: 0.10%\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.066450accuracy: 20.44%\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.190901accuracy: 40.71%\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.177877accuracy: 61.11%\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.220728accuracy: 81.35%\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.157445accuracy: 0.10%\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.109543accuracy: 20.32%\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.188795accuracy: 40.63%\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.204807accuracy: 60.88%\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.076781accuracy: 81.14%\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.237292accuracy: 0.10%\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.190489accuracy: 20.51%\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.066852accuracy: 40.74%\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.093934accuracy: 61.09%\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.090676accuracy: 81.26%\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.244040accuracy: 0.10%\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.045788accuracy: 20.38%\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.193991accuracy: 40.64%\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.106676accuracy: 60.86%\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.036060accuracy: 81.14%\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.233110accuracy: 0.10%\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.319227accuracy: 20.38%\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.071245accuracy: 40.64%\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.220558accuracy: 60.83%\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.186150accuracy: 81.00%\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.229983accuracy: 0.10%\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.047019accuracy: 20.18%\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.069287accuracy: 40.41%\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.148175accuracy: 60.62%\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.165341accuracy: 80.90%\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.044043accuracy: 0.10%\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.144053accuracy: 20.36%\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.071321accuracy: 40.66%\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.110225accuracy: 60.75%\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.256743accuracy: 80.81%\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.214735accuracy: 0.10%\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.238518accuracy: 20.28%\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.146512accuracy: 40.39%\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.131441accuracy: 60.70%\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.169570accuracy: 80.93%\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.145283accuracy: 0.10%\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.115603accuracy: 20.30%\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.121757accuracy: 40.43%\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.096686accuracy: 60.49%\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.087373accuracy: 80.64%\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.161355accuracy: 0.10%\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.215046accuracy: 20.22%\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.162337accuracy: 40.38%\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.182683accuracy: 60.52%\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.220337accuracy: 80.69%\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.118983accuracy: 0.10%\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.116760accuracy: 20.27%\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.199755accuracy: 40.42%\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.063658accuracy: 60.57%\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.253840accuracy: 80.68%\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.150670accuracy: 0.10%\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.068577accuracy: 20.29%\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.314808accuracy: 40.33%\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.083888accuracy: 60.34%\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.077724accuracy: 80.41%\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.212013accuracy: 0.10%\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.167449accuracy: 20.09%\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.076831accuracy: 40.24%\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.259109accuracy: 60.34%\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.198774accuracy: 80.36%\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.202039accuracy: 0.10%\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.114696accuracy: 20.24%\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.223303accuracy: 40.43%\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.094630accuracy: 60.45%\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.228160accuracy: 80.58%\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.105252accuracy: 0.10%\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.129936accuracy: 20.24%\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.097051accuracy: 40.27%\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.352238accuracy: 60.34%\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.303508accuracy: 80.48%\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.065693accuracy: 0.10%\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.194450accuracy: 19.94%\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.342072accuracy: 39.80%\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.337031accuracy: 59.75%\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.164229accuracy: 79.77%\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.075922accuracy: 0.10%\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.092194accuracy: 20.20%\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.168179accuracy: 40.08%\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.327869accuracy: 60.07%\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.145623accuracy: 79.97%\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.351690accuracy: 0.10%\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.096942accuracy: 20.05%\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.333722accuracy: 39.92%\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.167671accuracy: 59.88%\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.207812accuracy: 79.63%\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.120401accuracy: 0.10%\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.054643accuracy: 20.06%\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.199140accuracy: 40.16%\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.173437accuracy: 60.08%\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.170982accuracy: 79.96%\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.158143accuracy: 0.10%\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.121595accuracy: 19.98%\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.443062accuracy: 39.84%\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.307700accuracy: 59.84%\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.457028accuracy: 79.84%\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.314034accuracy: 0.10%\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.139522accuracy: 19.98%\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.357147accuracy: 39.56%\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.318929accuracy: 59.30%\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.268613accuracy: 79.14%\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.256946accuracy: 0.10%\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.192320accuracy: 19.84%\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.100182accuracy: 39.84%\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.145073accuracy: 59.74%\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.317588accuracy: 79.54%\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.379739accuracy: 0.10%\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 0.233997accuracy: 19.80%\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 0.150905accuracy: 39.73%\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 0.343909accuracy: 59.47%\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 0.303399accuracy: 79.27%\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.250708accuracy: 0.10%\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 0.332129accuracy: 20.03%\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 0.390730accuracy: 39.76%\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 0.143635accuracy: 59.71%\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 0.177401accuracy: 79.56%\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 0.161038accuracy: 0.10%\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 0.129612accuracy: 19.84%\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 0.168748accuracy: 39.61%\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 0.128974accuracy: 59.31%\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 0.348080accuracy: 79.26%\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 0.301024accuracy: 0.10%\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 0.295352accuracy: 19.88%\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 0.136665accuracy: 39.70%\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 0.388703accuracy: 59.45%\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 0.270160accuracy: 79.39%\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 0.188173accuracy: 0.10%\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 0.271452accuracy: 19.82%\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 0.182452accuracy: 39.32%\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 0.303405accuracy: 59.00%\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 0.365219accuracy: 78.59%\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.413362accuracy: 0.09%\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 0.144439accuracy: 19.86%\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 0.187328accuracy: 39.68%\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 0.352415accuracy: 59.43%\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 0.389070accuracy: 78.89%\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 0.414440accuracy: 0.10%\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 0.165570accuracy: 19.74%\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 0.267876accuracy: 39.58%\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 0.148058accuracy: 59.30%\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 0.357716accuracy: 78.88%\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 0.142958accuracy: 0.10%\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 0.205330accuracy: 19.76%\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 0.211371accuracy: 39.64%\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 0.316514accuracy: 59.28%\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 0.133379accuracy: 78.89%\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 0.226598accuracy: 0.10%\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 0.274105accuracy: 19.65%\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 0.283742accuracy: 39.11%\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 0.510138accuracy: 58.62%\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 0.375752accuracy: 78.31%\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.119311accuracy: 0.10%\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 0.576231accuracy: 19.86%\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 0.317636accuracy: 39.58%\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 0.373188accuracy: 59.41%\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 0.401781accuracy: 79.14%\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.418563accuracy: 0.09%\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 0.305121accuracy: 19.81%\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.376617accuracy: 39.34%\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 0.243686accuracy: 58.94%\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 0.460365accuracy: 78.40%\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.242297accuracy: 0.10%\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 0.342907accuracy: 19.57%\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 0.244059accuracy: 39.24%\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 0.090102accuracy: 59.04%\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 0.394412accuracy: 78.74%\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 0.347226accuracy: 0.10%\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 0.440662accuracy: 19.49%\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 0.496498accuracy: 39.14%\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 0.233012accuracy: 58.68%\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 0.459313accuracy: 78.16%\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.172390accuracy: 0.10%\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 0.262480accuracy: 19.88%\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 0.269453accuracy: 39.41%\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 0.234316accuracy: 58.85%\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 0.124404accuracy: 78.54%\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.211023accuracy: 0.10%\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 0.429792accuracy: 19.36%\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 0.304264accuracy: 38.84%\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 0.459679accuracy: 58.42%\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 0.292858accuracy: 77.83%\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.175229accuracy: 0.10%\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 0.396975accuracy: 19.71%\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 0.258127accuracy: 39.29%\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 0.320303accuracy: 58.70%\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 0.550169accuracy: 78.08%\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.206047accuracy: 0.10%\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 0.376983accuracy: 19.52%\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 0.283586accuracy: 39.20%\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 0.493489accuracy: 58.72%\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 0.345312accuracy: 78.25%\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.212615accuracy: 0.10%\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 0.467397accuracy: 19.41%\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 0.309419accuracy: 39.02%\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 0.050123accuracy: 58.54%\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 0.410668accuracy: 78.02%\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.250588accuracy: 0.10%\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 0.502215accuracy: 19.48%\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 0.519014accuracy: 39.00%\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 0.212903accuracy: 58.57%\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 0.381632accuracy: 78.08%\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 0.402601accuracy: 0.10%\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 0.459618accuracy: 19.33%\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 0.526283accuracy: 38.80%\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 0.178743accuracy: 58.09%\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 0.439338accuracy: 77.59%\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.253843accuracy: 0.10%\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 0.324286accuracy: 19.44%\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 0.488769accuracy: 38.84%\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 0.531483accuracy: 58.14%\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 0.159179accuracy: 77.45%\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.254984accuracy: 0.10%\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 0.192028accuracy: 19.81%\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 0.431099accuracy: 39.35%\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 0.464956accuracy: 58.78%\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 0.431620accuracy: 78.22%\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 0.330739accuracy: 0.10%\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 0.106564accuracy: 19.62%\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 0.662098accuracy: 39.01%\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 0.530757accuracy: 58.22%\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 0.257291accuracy: 77.48%\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.277670accuracy: 0.10%\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 0.327905accuracy: 19.62%\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 0.463897accuracy: 38.93%\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 0.272084accuracy: 58.42%\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 0.606992accuracy: 78.04%\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.256500accuracy: 0.10%\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 0.381945accuracy: 19.51%\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 0.274020accuracy: 38.83%\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 0.324019accuracy: 58.43%\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 0.102985accuracy: 77.88%\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.656570accuracy: 0.09%\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 0.340228accuracy: 19.44%\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 0.807299accuracy: 38.80%\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 0.844203accuracy: 58.08%\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 0.368758accuracy: 77.41%\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.196055accuracy: 0.10%\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 0.402179accuracy: 19.24%\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 0.266015accuracy: 38.31%\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 0.195867accuracy: 57.56%\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 0.573945accuracy: 77.00%\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.438140accuracy: 0.10%\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 0.479278accuracy: 19.47%\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 0.252177accuracy: 38.75%\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 0.427557accuracy: 57.92%\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 0.044771accuracy: 77.24%\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.677447accuracy: 0.09%\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 0.703915accuracy: 19.33%\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 0.172501accuracy: 38.68%\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 0.869690accuracy: 58.11%\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 0.217732accuracy: 77.39%\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.220732accuracy: 0.10%\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 0.132066accuracy: 19.36%\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 0.283669accuracy: 38.86%\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 0.190070accuracy: 58.30%\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 0.368633accuracy: 77.77%\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 0.207105accuracy: 0.10%\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 0.129609accuracy: 19.57%\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 0.126495accuracy: 39.06%\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 0.334072accuracy: 58.59%\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 0.271985accuracy: 78.11%\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.370640accuracy: 0.10%\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 0.392526accuracy: 19.61%\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 0.318029accuracy: 39.02%\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 0.355749accuracy: 58.48%\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 0.460266accuracy: 78.02%\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 0.437586accuracy: 0.09%\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 0.382412accuracy: 19.42%\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 0.566163accuracy: 38.68%\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 0.229807accuracy: 58.10%\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 0.378481accuracy: 77.42%\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 0.541292accuracy: 0.10%\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 0.443349accuracy: 19.66%\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 0.523709accuracy: 39.06%\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 0.234102accuracy: 58.55%\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 0.366163accuracy: 78.03%\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.350123accuracy: 0.10%\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 0.259435accuracy: 19.61%\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 0.444136accuracy: 39.19%\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 0.424935accuracy: 58.74%\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 0.250596accuracy: 78.19%\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 0.159918accuracy: 0.10%\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 0.546889accuracy: 19.55%\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 0.281467accuracy: 38.91%\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 0.427299accuracy: 58.20%\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 0.319610accuracy: 77.41%\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.250769accuracy: 0.10%\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 0.059029accuracy: 19.19%\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 0.727578accuracy: 38.38%\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 0.805041accuracy: 57.47%\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 0.156380accuracy: 76.83%\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.260334accuracy: 0.10%\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 0.100503accuracy: 19.50%\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 0.209548accuracy: 38.62%\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 0.290608accuracy: 57.97%\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 0.307188accuracy: 77.20%\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.352486accuracy: 0.10%\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 0.831655accuracy: 19.57%\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 0.369013accuracy: 38.73%\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 0.262049accuracy: 57.62%\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 0.572454accuracy: 76.68%\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.412371accuracy: 0.09%\n",
      "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 0.466963accuracy: 19.52%\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 0.428299accuracy: 38.97%\n",
      "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 0.643925accuracy: 58.23%\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 0.356386accuracy: 77.25%\n"
     ]
    }
   ],
   "source": [
    "# Model configurations\n",
    "model_configs = {\n",
    "    'Model_1_Underfit': {\n",
    "        'hidden_size': [64, 32, 16],  # Very shallow, only 1 small hidden layer\n",
    "        'lr': 1e-4,  # Lower learning rate\n",
    "        'epochs': 5,  # Fewer epochs\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Underfitted: Too simple (1 layer, 32 units)'\n",
    "    },\n",
    "    'Model_2_Slight_Underfit': {\n",
    "        'hidden_size': [256, 128, 64],  # 2 small layers\n",
    "        'lr': 5e-4,\n",
    "        'epochs': 8,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Slightly underfitted: Simple architecture'\n",
    "    },\n",
    "    'Model_3_Well_Trained': {\n",
    "        'hidden_size': [512, 256, 128],  # Moderate depth and width\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.2,  # Some regularization\n",
    "        'description': 'Well-trained: Balanced architecture with dropout'\n",
    "    },\n",
    "    'Model_4_Well_Trained_Deep': {\n",
    "        'hidden_size': [1024, 512, 256],  # Deeper but with dropout\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 20,\n",
    "        'dropout': 0.3,  # More dropout for regularization\n",
    "        'description': 'Well-trained: Deeper with good regularization'\n",
    "    },\n",
    "    'Model_5_Overfit': {\n",
    "        'hidden_size': [2048, 1024, 1024],  # Very deep and wide\n",
    "        'lr': 1e-3,  # Higher learning rate\n",
    "        'epochs': 30,  # Many epochs\n",
    "        'dropout': 0.0,  # No regularization\n",
    "        'description': 'Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_6_Extra_Overfit': {\n",
    "        'hidden_size': [4096, 2048, 1024],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 50,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_7_Extra_Overfit': {\n",
    "        'hidden_size': [8192, 4096, 2048],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 100,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model1 = geluLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model1.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model1, device, train_loader, optimizer, epoch)\n",
    "    model1.save(f'models/MNIST_model/gelu_{model_name}.pth')\n",
    "    \n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model2 = SigmoidLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model2.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model2, device, train_loader, optimizer, epoch)\n",
    "    model2.save(f'models/MNIST_model/sigmoid_{model_name}.pth')\n",
    "    \n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model3 = tanhLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model3.parameters(), lr=config['lr'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model3, device, train_loader, optimizer, epoch)\n",
    "    model3.save(f'models/MNIST_model/tanh_{model_name}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56501ce",
   "metadata": {},
   "source": [
    "# GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "014d2324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 53,018\n",
      "model name: Model_1_Underfit, test accuracy: 93.94%\n",
      "per column magnitude pruning test accuracy: 91.42%, sparsity: 0.3632\n",
      "per row magnitude pruning test accuracy: 91.05%, sparsity: 0.3424\n",
      "per block magnitude pruning test accuracy: 92.45%, sparsity: 0.3702\n",
      "mean column mean pruning test accuracy: 71.88%, sparsity: 0.3663\n",
      "mean row mean pruning test accuracy: 81.79%, sparsity: 0.3702\n",
      "mean block mean pruning test accuracy: 89.87%, sparsity: 0.3702\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 242,762\n",
      "model name: Model_2_Slight_Underfit, test accuracy: 97.85%\n",
      "per column magnitude pruning test accuracy: 97.83%, sparsity: 0.4287\n",
      "per row magnitude pruning test accuracy: 97.86%, sparsity: 0.3519\n",
      "per block magnitude pruning test accuracy: 97.98%, sparsity: 0.4283\n",
      "mean column mean pruning test accuracy: 97.42%, sparsity: 0.4169\n",
      "mean row mean pruning test accuracy: 97.66%, sparsity: 0.4283\n",
      "mean block mean pruning test accuracy: 97.87%, sparsity: 0.4283\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 567,434\n",
      "model name: Model_3_Well_Trained, test accuracy: 98.32%\n",
      "per column magnitude pruning test accuracy: 98.27%, sparsity: 0.4029\n",
      "per row magnitude pruning test accuracy: 98.34%, sparsity: 0.3462\n",
      "per block magnitude pruning test accuracy: 98.32%, sparsity: 0.4028\n",
      "mean column mean pruning test accuracy: 98.36%, sparsity: 0.3980\n",
      "mean row mean pruning test accuracy: 98.31%, sparsity: 0.4028\n",
      "mean block mean pruning test accuracy: 98.41%, sparsity: 0.4028\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 1,462,538\n",
      "model name: Model_4_Well_Trained_Deep, test accuracy: 98.52%\n",
      "per column magnitude pruning test accuracy: 98.50%, sparsity: 0.3982\n",
      "per row magnitude pruning test accuracy: 98.56%, sparsity: 0.3504\n",
      "per block magnitude pruning test accuracy: 98.53%, sparsity: 0.3985\n",
      "mean column mean pruning test accuracy: 98.55%, sparsity: 0.3957\n",
      "mean row mean pruning test accuracy: 98.46%, sparsity: 0.3985\n",
      "mean block mean pruning test accuracy: 98.51%, sparsity: 0.3985\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 4,765,706\n",
      "model name: Model_5_Overfit, test accuracy: 98.28%\n",
      "per column magnitude pruning test accuracy: 98.16%, sparsity: 0.4700\n",
      "per row magnitude pruning test accuracy: 97.70%, sparsity: 0.4170\n",
      "per block magnitude pruning test accuracy: 98.05%, sparsity: 0.4911\n",
      "mean column mean pruning test accuracy: 95.53%, sparsity: 0.4444\n",
      "mean row mean pruning test accuracy: 97.63%, sparsity: 0.4911\n",
      "mean block mean pruning test accuracy: 97.84%, sparsity: 0.4911\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 13,714,442\n",
      "model name: Model_6_Extra_Overfit, test accuracy: 98.27%\n",
      "per column magnitude pruning test accuracy: 95.87%, sparsity: 0.5453\n",
      "per row magnitude pruning test accuracy: 97.09%, sparsity: 0.4664\n",
      "per block magnitude pruning test accuracy: 96.65%, sparsity: 0.5625\n",
      "mean column mean pruning test accuracy: 90.75%, sparsity: 0.4733\n",
      "mean row mean pruning test accuracy: 97.40%, sparsity: 0.5625\n",
      "mean block mean pruning test accuracy: 97.60%, sparsity: 0.5625\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 48,400,394\n",
      "model name: Model_7_Extra_Overfit, test accuracy: 98.29%\n",
      "per column magnitude pruning test accuracy: 89.76%, sparsity: 0.6444\n",
      "per row magnitude pruning test accuracy: 97.69%, sparsity: 0.5415\n",
      "per block magnitude pruning test accuracy: 98.19%, sparsity: 0.6549\n",
      "mean column mean pruning test accuracy: 60.39%, sparsity: 0.4968\n",
      "mean row mean pruning test accuracy: 96.37%, sparsity: 0.6549\n",
      "mean block mean pruning test accuracy: 97.89%, sparsity: 0.6549\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = geluLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/gelu_{model_name}.pth')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0bbbb",
   "metadata": {},
   "source": [
    "# SIGMOID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d75d39a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 53,018\n",
      "model name: Model_1_Underfit, test accuracy: 54.06%\n",
      "per column magnitude pruning test accuracy: 43.62%, sparsity: 0.3973\n",
      "per row magnitude pruning test accuracy: 48.35%, sparsity: 0.3054\n",
      "per block magnitude pruning test accuracy: 48.04%, sparsity: 0.3974\n",
      "mean column mean pruning test accuracy: 43.38%, sparsity: 0.3962\n",
      "mean row mean pruning test accuracy: 50.95%, sparsity: 0.3974\n",
      "mean block mean pruning test accuracy: 51.08%, sparsity: 0.3974\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 242,762\n",
      "model name: Model_2_Slight_Underfit, test accuracy: 97.36%\n",
      "per column magnitude pruning test accuracy: 97.18%, sparsity: 0.4310\n",
      "per row magnitude pruning test accuracy: 96.60%, sparsity: 0.3604\n",
      "per block magnitude pruning test accuracy: 96.48%, sparsity: 0.4310\n",
      "mean column mean pruning test accuracy: 97.10%, sparsity: 0.4385\n",
      "mean row mean pruning test accuracy: 95.76%, sparsity: 0.4310\n",
      "mean block mean pruning test accuracy: 96.57%, sparsity: 0.4310\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 567,434\n",
      "model name: Model_3_Well_Trained, test accuracy: 98.04%\n",
      "per column magnitude pruning test accuracy: 98.01%, sparsity: 0.4431\n",
      "per row magnitude pruning test accuracy: 97.53%, sparsity: 0.3656\n",
      "per block magnitude pruning test accuracy: 97.73%, sparsity: 0.4456\n",
      "mean column mean pruning test accuracy: 97.78%, sparsity: 0.4462\n",
      "mean row mean pruning test accuracy: 96.85%, sparsity: 0.4456\n",
      "mean block mean pruning test accuracy: 97.74%, sparsity: 0.4456\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 1,462,538\n",
      "model name: Model_4_Well_Trained_Deep, test accuracy: 98.07%\n",
      "per column magnitude pruning test accuracy: 98.11%, sparsity: 0.4368\n",
      "per row magnitude pruning test accuracy: 97.55%, sparsity: 0.3644\n",
      "per block magnitude pruning test accuracy: 97.83%, sparsity: 0.4423\n",
      "mean column mean pruning test accuracy: 97.42%, sparsity: 0.4386\n",
      "mean row mean pruning test accuracy: 97.75%, sparsity: 0.4423\n",
      "mean block mean pruning test accuracy: 97.66%, sparsity: 0.4423\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 4,765,706\n",
      "model name: Model_5_Overfit, test accuracy: 98.27%\n",
      "per column magnitude pruning test accuracy: 98.25%, sparsity: 0.4083\n",
      "per row magnitude pruning test accuracy: 96.85%, sparsity: 0.3805\n",
      "per block magnitude pruning test accuracy: 97.06%, sparsity: 0.4275\n",
      "mean column mean pruning test accuracy: 89.58%, sparsity: 0.4175\n",
      "mean row mean pruning test accuracy: 97.08%, sparsity: 0.4275\n",
      "mean block mean pruning test accuracy: 95.57%, sparsity: 0.4275\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 13,714,442\n",
      "model name: Model_6_Extra_Overfit, test accuracy: 98.22%\n",
      "per column magnitude pruning test accuracy: 98.11%, sparsity: 0.4639\n",
      "per row magnitude pruning test accuracy: 95.45%, sparsity: 0.4402\n",
      "per block magnitude pruning test accuracy: 96.20%, sparsity: 0.4822\n",
      "mean column mean pruning test accuracy: 85.12%, sparsity: 0.4320\n",
      "mean row mean pruning test accuracy: 95.66%, sparsity: 0.4822\n",
      "mean block mean pruning test accuracy: 94.65%, sparsity: 0.4822\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 48,400,394\n",
      "model name: Model_7_Extra_Overfit, test accuracy: 98.11%\n",
      "per column magnitude pruning test accuracy: 97.76%, sparsity: 0.6069\n",
      "per row magnitude pruning test accuracy: 93.37%, sparsity: 0.5747\n",
      "per block magnitude pruning test accuracy: 95.43%, sparsity: 0.6238\n",
      "mean column mean pruning test accuracy: 87.00%, sparsity: 0.4559\n",
      "mean row mean pruning test accuracy: 86.00%, sparsity: 0.6238\n",
      "mean block mean pruning test accuracy: 92.44%, sparsity: 0.6238\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SigmoidLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/sigmoid_{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3431c",
   "metadata": {},
   "source": [
    "# TANH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ad7b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 53,018\n",
      "model name: Model_1_Underfit, test accuracy: 94.62%\n",
      "per column magnitude pruning test accuracy: 94.59%, sparsity: 0.3589\n",
      "per row magnitude pruning test accuracy: 94.49%, sparsity: 0.3349\n",
      "per block magnitude pruning test accuracy: 94.54%, sparsity: 0.3589\n",
      "mean column mean pruning test accuracy: 94.42%, sparsity: 0.3594\n",
      "mean row mean pruning test accuracy: 94.51%, sparsity: 0.3589\n",
      "mean block mean pruning test accuracy: 94.49%, sparsity: 0.3589\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 242,762\n",
      "model name: Model_2_Slight_Underfit, test accuracy: 97.71%\n",
      "per column magnitude pruning test accuracy: 97.76%, sparsity: 0.4156\n",
      "per row magnitude pruning test accuracy: 97.73%, sparsity: 0.3551\n",
      "per block magnitude pruning test accuracy: 97.82%, sparsity: 0.4156\n",
      "mean column mean pruning test accuracy: 97.77%, sparsity: 0.4194\n",
      "mean row mean pruning test accuracy: 97.73%, sparsity: 0.4156\n",
      "mean block mean pruning test accuracy: 97.79%, sparsity: 0.4156\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 567,434\n",
      "model name: Model_3_Well_Trained, test accuracy: 98.28%\n",
      "per column magnitude pruning test accuracy: 98.31%, sparsity: 0.4050\n",
      "per row magnitude pruning test accuracy: 98.31%, sparsity: 0.3532\n",
      "per block magnitude pruning test accuracy: 98.27%, sparsity: 0.4050\n",
      "mean column mean pruning test accuracy: 98.30%, sparsity: 0.4042\n",
      "mean row mean pruning test accuracy: 98.29%, sparsity: 0.4050\n",
      "mean block mean pruning test accuracy: 98.27%, sparsity: 0.4050\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 1,462,538\n",
      "model name: Model_4_Well_Trained_Deep, test accuracy: 98.34%\n",
      "per column magnitude pruning test accuracy: 98.25%, sparsity: 0.4008\n",
      "per row magnitude pruning test accuracy: 98.33%, sparsity: 0.3569\n",
      "per block magnitude pruning test accuracy: 98.30%, sparsity: 0.4009\n",
      "mean column mean pruning test accuracy: 98.22%, sparsity: 0.4008\n",
      "mean row mean pruning test accuracy: 98.31%, sparsity: 0.4009\n",
      "mean block mean pruning test accuracy: 98.29%, sparsity: 0.4009\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 4,765,706\n",
      "model name: Model_5_Overfit, test accuracy: 97.18%\n",
      "per column magnitude pruning test accuracy: 96.95%, sparsity: 0.4027\n",
      "per row magnitude pruning test accuracy: 96.20%, sparsity: 0.3678\n",
      "per block magnitude pruning test accuracy: 96.33%, sparsity: 0.4027\n",
      "mean column mean pruning test accuracy: 96.91%, sparsity: 0.4113\n",
      "mean row mean pruning test accuracy: 95.54%, sparsity: 0.4027\n",
      "mean block mean pruning test accuracy: 96.29%, sparsity: 0.4027\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 13,714,442\n",
      "model name: Model_6_Extra_Overfit, test accuracy: 94.79%\n",
      "per column magnitude pruning test accuracy: 92.64%, sparsity: 0.4086\n",
      "per row magnitude pruning test accuracy: 80.77%, sparsity: 0.3761\n",
      "per block magnitude pruning test accuracy: 77.75%, sparsity: 0.4087\n",
      "mean column mean pruning test accuracy: 95.08%, sparsity: 0.3966\n",
      "mean row mean pruning test accuracy: 82.73%, sparsity: 0.4087\n",
      "mean block mean pruning test accuracy: 78.39%, sparsity: 0.4087\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 48,400,394\n",
      "model name: Model_7_Extra_Overfit, test accuracy: 90.92%\n",
      "per column magnitude pruning test accuracy: 78.91%, sparsity: 0.4139\n",
      "per row magnitude pruning test accuracy: 44.04%, sparsity: 0.3884\n",
      "per block magnitude pruning test accuracy: 46.15%, sparsity: 0.4139\n",
      "mean column mean pruning test accuracy: 76.27%, sparsity: 0.3799\n",
      "mean row mean pruning test accuracy: 42.73%, sparsity: 0.4139\n",
      "mean block mean pruning test accuracy: 46.25%, sparsity: 0.4139\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = tanhLinearModel(\n",
    "        input_size=28*28, \n",
    "        output_size=10, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/MNIST_model/tanh_{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc344e",
   "metadata": {},
   "source": [
    "# different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ebdec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset registry ---------------------------------------------------------\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_loaders(dataset_name, batch_size=128, test_batch_size=1000, data_root='./data'):\n",
    "    \"\"\"\n",
    "    Returns: train_loader, test_loader, input_size, num_classes, meta (dict)\n",
    "    \"\"\"\n",
    "    name = dataset_name.lower()\n",
    "    meta = {}\n",
    "\n",
    "    # Generic normalizations (safe defaults). If you want canonical stats, compute them once.\n",
    "    NORM_1C = transforms.Normalize((0.5,), (0.5,))\n",
    "    NORM_3C = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "    if name == 'mnist':\n",
    "        # (You already have this; included for completeness.)\n",
    "        tfm = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        train = datasets.MNIST(data_root, train=True, download=True, transform=tfm)\n",
    "        test  = datasets.MNIST(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "\n",
    "    elif name == 'fashionmnist':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_1C])\n",
    "        train = datasets.FashionMNIST(data_root, train=True, download=True, transform=tfm)\n",
    "        test  = datasets.FashionMNIST(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "\n",
    "    elif name == 'kmnist':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_1C])\n",
    "        train = datasets.KMNIST(data_root, train=True, download=True, transform=tfm)\n",
    "        test  = datasets.KMNIST(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "\n",
    "    elif name in ('emnist_balanced', 'emnist'):\n",
    "        # EMNIST Balanced has 47 classes. If digits look rotated, add a Rotate(90) or permute.\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_1C])\n",
    "        train = datasets.EMNIST(data_root, split='balanced', train=True, download=True, transform=tfm)\n",
    "        test  = datasets.EMNIST(data_root, split='balanced', train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 47\n",
    "        meta['note'] = 'EMNIST images can appear rotated; for visualization add a 90-degree rotate.'\n",
    "\n",
    "    elif name == 'qmnist':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_1C])\n",
    "        train = datasets.QMNIST(data_root, what='train', download=True, transform=tfm)\n",
    "        test  = datasets.QMNIST(data_root, what='test',  download=True, transform=tfm)\n",
    "        inp, ncls = 28*28, 10\n",
    "\n",
    "    elif name == 'svhn':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.SVHN(data_root, split='train', download=True, transform=tfm)\n",
    "        test  = datasets.SVHN(data_root, split='test',  download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 10\n",
    "\n",
    "    elif name == 'cifar10':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.CIFAR10(data_root, train=True,  download=True, transform=tfm)\n",
    "        test  = datasets.CIFAR10(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 10\n",
    "\n",
    "    elif name == 'cifar100':\n",
    "        tfm = transforms.Compose([transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.CIFAR100(data_root, train=True,  download=True, transform=tfm)\n",
    "        test  = datasets.CIFAR100(data_root, train=False, download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 100\n",
    "\n",
    "    elif name in ('stl10', 'stl10_32'):\n",
    "        # Downsample to 32x32 to keep input dim manageable for MLPs.\n",
    "        tfm = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                  transforms.ToTensor(), NORM_3C])\n",
    "        train = datasets.STL10(data_root, split='train', download=True, transform=tfm)\n",
    "        test  = datasets.STL10(data_root, split='test',  download=True, transform=tfm)\n",
    "        inp, ncls = 32*32*3, 10\n",
    "        meta['note'] = 'Original STL10 is 96x96; here we resize to 32x32 for MLPs.'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=test_batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, test_loader, inp, ncls, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183222a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(784) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301900\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.036388\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.881040\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.946243\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.810716\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.790399\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.487468\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.820323\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.619663\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.601959\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(784) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.312079\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.659324\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.573802\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.325238\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.299133\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.243351\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.234403\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.124476\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.140553\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.238442\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.094316\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.971892\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.040067\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.063190\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.958386\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.983973\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(784) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.306737\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.717267\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.495490\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.666589\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.428449\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.573127\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.240962\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.296742\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.297594\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.361862\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.376019\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.415982\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.232967\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.200629\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.136025\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.152041\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.192253\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.138119\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.188474\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.179722\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.139202\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.103296\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.038503\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.020965\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.956598\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.950905\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.007788\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.958842\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.032420\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.049688\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(784) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301678\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.857476\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.567301\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.393992\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.518678\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.412701\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.255128\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.285777\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.295816\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.441990\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.251959\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.282417\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.057896\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.095237\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.005693\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.109574\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.167832\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.264064\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.091904\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.997954\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.138259\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.948999\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.887709\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.049266\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.939973\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.107214\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.840921\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.966027\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.949237\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.894278\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.887744\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.022845\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.782061\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.907205\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.704335\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.794753\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.800668\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.811529\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.666211\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.911167\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302386\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.522375\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.394708\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.496101\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.300208\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.281507\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.115365\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.270350\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.961468\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.029790\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.988809\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.095760\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.908292\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.894757\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.731122\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.868838\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.831187\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.784750\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.687233\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.729139\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.691628\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.610353\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.519903\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.488918\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.527719\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.525627\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.454545\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.390635\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.523196\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.457566\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.358781\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.500840\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.309702\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.336072\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.270607\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.384312\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.349119\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.356288\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.249279\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.294640\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.328769\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.285047\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.284724\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.320797\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.253249\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.298301\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.194837\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.182980\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.191285\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.202037\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.310922\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.293145\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.188350\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.300079\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.225322\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.325422\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.224710\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.222959\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.190489\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.220394\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.303260\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.622963\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.388842\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.317347\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.251878\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.453599\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.010934\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.339780\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.095153\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.285224\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.016041\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.125633\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.892968\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.129301\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.895766\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.071059\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.835295\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.739871\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.637808\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.857160\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.742003\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.610888\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.678999\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.650448\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.443888\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.785767\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.585628\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.661323\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.549209\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.484460\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.404359\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.435528\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.414849\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.602168\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.460793\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.310828\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.339953\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.461238\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.285776\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.328602\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.423617\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.301258\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.382007\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.344608\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.336048\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.395535\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.351491\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.427966\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.222363\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.215653\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.242311\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.387747\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.260504\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.447213\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.245650\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.262757\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.266984\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.468357\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.292477\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.276301\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.251774\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.283830\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.190633\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.334332\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.102844\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.359063\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.235905\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.151977\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.276107\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.217811\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.218619\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.165479\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.407816\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.346287\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.177689\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.238960\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.267077\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.200351\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.180182\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.112619\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.141248\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.217614\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.107128\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.294735\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.116065\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.332559\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.138364\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.162156\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.124608\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.221150\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.124301\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.190266\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.116524\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.129529\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.177963\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.106430\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.220096\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.175204\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.110887\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.198568\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(784) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302104\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.763355\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.629124\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.487206\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.260937\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.150447\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.325345\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.321714\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.227061\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.078470\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.060474\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.917242\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.029771\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.087253\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.949843\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.877624\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.944280\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.008625\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.849054\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.750507\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.727371\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.753793\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.733589\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.806783\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.748327\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.591191\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.686932\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.610177\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.596572\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.444883\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.404584\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.622267\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.394815\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.632987\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.566878\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.526583\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.316677\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.473868\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.302244\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.352912\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.328305\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.482832\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.308329\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.384661\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.362866\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.584559\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.274639\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.527190\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.224563\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.409681\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.328822\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.324181\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.258385\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.272336\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.505145\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.418288\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.325461\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.412985\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.252388\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.353916\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.329793\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.213631\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.330196\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.379681\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.270700\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.464213\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.217599\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.178851\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.268774\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.176786\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.256153\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.313206\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.330844\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.432182\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.263435\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.319122\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.146404\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.338848\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.226727\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.216228\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.237589\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.288688\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.244864\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.278798\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.317201\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.401103\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.335643\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.247321\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.365885\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.128137\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.218278\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.328697\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.241097\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.179738\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.385821\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.265174\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.229797\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.157021\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.149176\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.421605\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.181197\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.389116\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.215118\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.299048\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.198456\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.216582\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.458844\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.278744\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.187253\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.211333\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.153341\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.221160\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.230990\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.144314\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.261641\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.305986\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.127647\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.153144\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.163335\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.181466\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.198359\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.325530\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.192197\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.327492\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.100669\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.285150\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.189347\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.196107\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.254493\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.386394\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.184690\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.273676\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.175986\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.091073\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.302510\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.295740\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.162920\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.283472\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.197435\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.423622\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.242449\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.245742\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.137968\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.219741\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.106915\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.161738\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.270959\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.166886\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.148537\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.277883\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.124355\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.302236\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.239515\n",
      "Train Epoch: 77 [25600/50000 (51%)]\tLoss: 0.148321\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.347412\n",
      "Train Epoch: 78 [25600/50000 (51%)]\tLoss: 0.177017\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.117976\n",
      "Train Epoch: 79 [25600/50000 (51%)]\tLoss: 0.139786\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.029013\n",
      "Train Epoch: 80 [25600/50000 (51%)]\tLoss: 0.182124\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.183249\n",
      "Train Epoch: 81 [25600/50000 (51%)]\tLoss: 0.297962\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.079903\n",
      "Train Epoch: 82 [25600/50000 (51%)]\tLoss: 0.356163\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.112120\n",
      "Train Epoch: 83 [25600/50000 (51%)]\tLoss: 0.474907\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.196505\n",
      "Train Epoch: 84 [25600/50000 (51%)]\tLoss: 0.140974\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.194437\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 0.167371\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.141129\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 0.109691\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.172588\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 0.192882\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.178527\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 0.243920\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.168762\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 0.374417\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.076214\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 0.106494\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.196202\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 0.137331\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.139297\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.306610\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.225016\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.163021\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.113975\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 0.250914\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.197375\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 0.055841\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.137344\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.159940\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.104595\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.200730\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.058564\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.147812\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.302057\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 0.291858\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.082904\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 0.107678\n"
     ]
    }
   ],
   "source": [
    "# Model configurations\n",
    "model_configs = {\n",
    "    'Model_1_Underfit': {\n",
    "        'hidden_size': [64, 64, 32, 32, 16],  # Very shallow, only 1 small hidden layer\n",
    "        'lr': 1e-4,  # Lower learning rate\n",
    "        'epochs': 5,  # Fewer epochs\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Underfitted: Too simple (1 layer, 32 units)'\n",
    "    },\n",
    "    'Model_2_Slight_Underfit': {\n",
    "        'hidden_size': [256, 256, 128, 128, 64],  # 2 small layers\n",
    "        'lr': 5e-4,\n",
    "        'epochs': 10,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Slightly underfitted: Simple architecture'\n",
    "    },\n",
    "    'Model_3_Well_Trained': {\n",
    "        'hidden_size': [512, 512, 256, 256, 128],  # Moderate depth and width\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 15,\n",
    "        'dropout': 0.2,  # Some regularization\n",
    "        'description': 'Well-trained: Balanced architecture with dropout'\n",
    "    },\n",
    "    'Model_4_Well_Trained_Deep': {\n",
    "        'hidden_size': [1024, 1024, 512, 512, 256],  # Deeper but with dropout\n",
    "        'lr': 3e-4,\n",
    "        'epochs': 20,\n",
    "        'dropout': 0.3,  # More dropout for regularization\n",
    "        'description': 'Well-trained: Deeper with good regularization'\n",
    "    },\n",
    "    'Model_5_Overfit': {\n",
    "        'hidden_size': [2048, 2048, 1024, 1024, 512],  # Very deep and wide\n",
    "        'lr': 1e-3,  # Higher learning rate\n",
    "        'epochs': 30,  # Many epochs\n",
    "        'dropout': 0.0,  # No regularization\n",
    "        'description': 'Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_6_Extra_Overfit': {\n",
    "        'hidden_size': [4096, 4096, 2048, 2048, 1024],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 50,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    },\n",
    "    'Model_7_Extra_Overfit': {\n",
    "        'hidden_size': [8192, 8192, 4096, 4096, 2048],  # Extremely deep and wide\n",
    "        'lr': 1e-3,\n",
    "        'epochs': 100,\n",
    "        'dropout': 0.0,\n",
    "        'description': 'Extra Overfitted: Very complex without regularization'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "all_results = {}\n",
    "dataset_name = 'cifar10'\n",
    "train_loader, test_loader, input_size, num_classes, meta = get_loaders(dataset_name)\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input(784) -> {' -> '.join(map(str, config['hidden_size']))} -> Output(10)\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size, \n",
    "        output_size=num_classes, \n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
    "    model.save(f'models/{dataset_name}/{model_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2228ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(3072) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 199,450\n",
      "model name: Model_1_Underfit, test accuracy: 44.58%\n",
      "per column magnitude pruning test accuracy: 42.93%, sparsity: 0.3662\n",
      "per row magnitude pruning test accuracy: 43.67%, sparsity: 0.3573\n",
      "per block magnitude pruning test accuracy: 44.01%, sparsity: 0.3662\n",
      "mean column mean pruning test accuracy: 40.26%, sparsity: 0.3594\n",
      "mean row mean pruning test accuracy: 40.94%, sparsity: 0.3662\n",
      "mean block mean pruning test accuracy: 42.95%, sparsity: 0.3662\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(3072) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 828,490\n",
      "model name: Model_2_Slight_Underfit, test accuracy: 54.38%\n",
      "per column magnitude pruning test accuracy: 53.99%, sparsity: 0.3867\n",
      "per row magnitude pruning test accuracy: 53.78%, sparsity: 0.3706\n",
      "per block magnitude pruning test accuracy: 53.81%, sparsity: 0.3866\n",
      "mean column mean pruning test accuracy: 52.83%, sparsity: 0.3808\n",
      "mean row mean pruning test accuracy: 52.81%, sparsity: 0.3866\n",
      "mean block mean pruning test accuracy: 54.04%, sparsity: 0.3866\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(3072) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 1,738,890\n",
      "model name: Model_3_Well_Trained, test accuracy: 56.62%\n",
      "per column magnitude pruning test accuracy: 55.62%, sparsity: 0.3810\n",
      "per row magnitude pruning test accuracy: 56.06%, sparsity: 0.3667\n",
      "per block magnitude pruning test accuracy: 56.19%, sparsity: 0.3807\n",
      "mean column mean pruning test accuracy: 55.78%, sparsity: 0.3774\n",
      "mean row mean pruning test accuracy: 55.89%, sparsity: 0.3807\n",
      "mean block mean pruning test accuracy: 56.05%, sparsity: 0.3807\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(3072) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 3,805,450\n",
      "model name: Model_4_Well_Trained_Deep, test accuracy: 56.90%\n",
      "per column magnitude pruning test accuracy: 56.55%, sparsity: 0.3793\n",
      "per row magnitude pruning test accuracy: 56.52%, sparsity: 0.3666\n",
      "per block magnitude pruning test accuracy: 56.61%, sparsity: 0.3785\n",
      "mean column mean pruning test accuracy: 55.79%, sparsity: 0.3755\n",
      "mean row mean pruning test accuracy: 56.54%, sparsity: 0.3785\n",
      "mean block mean pruning test accuracy: 56.64%, sparsity: 0.3785\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 9,451,530\n",
      "model name: Model_5_Overfit, test accuracy: 53.85%\n",
      "per column magnitude pruning test accuracy: 52.08%, sparsity: 0.4430\n",
      "per row magnitude pruning test accuracy: 52.57%, sparsity: 0.4136\n",
      "per block magnitude pruning test accuracy: 52.86%, sparsity: 0.4437\n",
      "mean column mean pruning test accuracy: 53.09%, sparsity: 0.3888\n",
      "mean row mean pruning test accuracy: 52.07%, sparsity: 0.4437\n",
      "mean block mean pruning test accuracy: 53.13%, sparsity: 0.4437\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 23,086,090\n",
      "model name: Model_6_Extra_Overfit, test accuracy: 53.84%\n",
      "per column magnitude pruning test accuracy: 52.83%, sparsity: 0.5022\n",
      "per row magnitude pruning test accuracy: 51.42%, sparsity: 0.4664\n",
      "per block magnitude pruning test accuracy: 51.67%, sparsity: 0.4977\n",
      "mean column mean pruning test accuracy: 50.59%, sparsity: 0.3848\n",
      "mean row mean pruning test accuracy: 51.22%, sparsity: 0.4977\n",
      "mean block mean pruning test accuracy: 52.83%, sparsity: 0.4977\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 67,143,690\n",
      "model name: Model_7_Extra_Overfit, test accuracy: 54.74%\n",
      "per column magnitude pruning test accuracy: 53.70%, sparsity: 0.6367\n",
      "per row magnitude pruning test accuracy: 45.86%, sparsity: 0.5812\n",
      "per block magnitude pruning test accuracy: 45.80%, sparsity: 0.6350\n",
      "mean column mean pruning test accuracy: 42.42%, sparsity: 0.3734\n",
      "mean row mean pruning test accuracy: 51.18%, sparsity: 0.6350\n",
      "mean block mean pruning test accuracy: 54.74%, sparsity: 0.6350\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'cifar10'\n",
    "train_loader, test_loader, input_size, num_classes, meta = get_loaders(dataset_name)\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input({input_size}) -> {' -> '.join(map(str, config['hidden_size']))} -> Output({num_classes})\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    test_loss, test_accuracy, origin_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    \n",
    "    result['model_name'].append(model_name)\n",
    "    result['test_accuracy'].append(test_accuracy)\n",
    "    result['model_sparsity'].append(0.0)\n",
    "    \n",
    "    # magnitude\n",
    "    pc_model, pc_neff = model_pc(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pc_model))\n",
    "    \n",
    "    pr_model, pr_neff = model_pr(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pr_model))\n",
    "    \n",
    "    pb_model, pb_neff = model_block(model, renormalize=False, beta=1.0, method='magnitude')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_magnitude\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(pb_model))\n",
    "\n",
    "    # mean\n",
    "    mean_pc_model, mean_pc_neff = model_pc(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pc_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pc_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pc_model))\n",
    "\n",
    "    mean_pr_model, mean_pr_neff = model_pr(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pr_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pr_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pr_model))\n",
    "\n",
    "    mean_pb_model, mean_pb_neff = model_block(model, renormalize=False, beta=1.0, method='mean')\n",
    "    test_loss, test_accuracy, accuracy_mean = test(mean_pb_model, device, test_loader, times=5)\n",
    "    result['model_name'].append(f\"{model_name}_pb_1_mean\")\n",
    "    result['test_accuracy'].append(accuracy_mean)\n",
    "    result['model_sparsity'].append(model_sparsity(mean_pb_model))\n",
    "\n",
    "    # summary\n",
    "    print(f\"model name: {model_name}, test accuracy: {origin_test_accuracy:.2f}%\")\n",
    "    print(f\"per column magnitude pruning test accuracy: {result['test_accuracy'][-6]:.2f}%, sparsity: {result['model_sparsity'][-4]:.4f}\")\n",
    "    print(f\"per row magnitude pruning test accuracy: {result['test_accuracy'][-5]:.2f}%, sparsity: {result['model_sparsity'][-3]:.4f}\")\n",
    "    print(f\"per block magnitude pruning test accuracy: {result['test_accuracy'][-4]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean column mean pruning test accuracy: {result['test_accuracy'][-3]:.2f}%, sparsity: {result['model_sparsity'][-2]:.4f}\")\n",
    "    print(f\"mean row mean pruning test accuracy: {result['test_accuracy'][-2]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n",
    "    print(f\"mean block mean pruning test accuracy: {result['test_accuracy'][-1]:.2f}%, sparsity: {result['model_sparsity'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4074023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model_1_Underfit: Underfitted: Too simple (1 layer, 32 units)\n",
      "Architecture: Input(3072) -> 64 -> 32 -> 16 -> Output(10)\n",
      "Learning rate: 0.0001, Epochs: 5, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 199,450\n",
      "Model Name: Model_1_Underfit, Test Accuracy: 44.58%\n",
      "Renormalized Model test accuracy: 43.75%, Sparsity: 0.36\n",
      "Model test accuracy: 43.67%, Sparsity: 0.36\n",
      "\n",
      "============================================================\n",
      "Training Model_2_Slight_Underfit: Slightly underfitted: Simple architecture\n",
      "Architecture: Input(3072) -> 256 -> 128 -> 64 -> Output(10)\n",
      "Learning rate: 0.0005, Epochs: 8, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 828,490\n",
      "Model Name: Model_2_Slight_Underfit, Test Accuracy: 54.38%\n",
      "Renormalized Model test accuracy: 53.02%, Sparsity: 0.38\n",
      "Model test accuracy: 53.78%, Sparsity: 0.38\n",
      "\n",
      "============================================================\n",
      "Training Model_3_Well_Trained: Well-trained: Balanced architecture with dropout\n",
      "Architecture: Input(3072) -> 512 -> 256 -> 128 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 15, Dropout: 0.2\n",
      "============================================================\n",
      "Total parameters: 1,738,890\n",
      "Model Name: Model_3_Well_Trained, Test Accuracy: 56.62%\n",
      "Renormalized Model test accuracy: 56.00%, Sparsity: 0.38\n",
      "Model test accuracy: 56.06%, Sparsity: 0.38\n",
      "\n",
      "============================================================\n",
      "Training Model_4_Well_Trained_Deep: Well-trained: Deeper with good regularization\n",
      "Architecture: Input(3072) -> 1024 -> 512 -> 256 -> Output(10)\n",
      "Learning rate: 0.0003, Epochs: 20, Dropout: 0.3\n",
      "============================================================\n",
      "Total parameters: 3,805,450\n",
      "Model Name: Model_4_Well_Trained_Deep, Test Accuracy: 56.90%\n",
      "Renormalized Model test accuracy: 56.14%, Sparsity: 0.38\n",
      "Model test accuracy: 56.52%, Sparsity: 0.38\n",
      "\n",
      "============================================================\n",
      "Training Model_5_Overfit: Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 2048 -> 1024 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 30, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 9,451,530\n",
      "Model Name: Model_5_Overfit, Test Accuracy: 53.85%\n",
      "Renormalized Model test accuracy: 52.41%, Sparsity: 0.39\n",
      "Model test accuracy: 52.57%, Sparsity: 0.39\n",
      "\n",
      "============================================================\n",
      "Training Model_6_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 4096 -> 2048 -> 1024 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 50, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 23,086,090\n",
      "Model Name: Model_6_Extra_Overfit, Test Accuracy: 53.84%\n",
      "Renormalized Model test accuracy: 51.38%, Sparsity: 0.39\n",
      "Model test accuracy: 51.42%, Sparsity: 0.39\n",
      "\n",
      "============================================================\n",
      "Training Model_7_Extra_Overfit: Extra Overfitted: Very complex without regularization\n",
      "Architecture: Input(3072) -> 8192 -> 4096 -> 2048 -> Output(10)\n",
      "Learning rate: 0.001, Epochs: 100, Dropout: 0.0\n",
      "============================================================\n",
      "Total parameters: 67,143,690\n",
      "Model Name: Model_7_Extra_Overfit, Test Accuracy: 54.74%\n",
      "Renormalized Model test accuracy: 45.66%, Sparsity: 0.39\n",
      "Model test accuracy: 45.86%, Sparsity: 0.39\n"
     ]
    }
   ],
   "source": [
    "renormal_result = {\n",
    "    'test_accuracy': [],\n",
    "    'model_sparsity': [],\n",
    "}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}: {config['description']}\")\n",
    "    print(f\"Architecture: Input({input_size}) -> {' -> '.join(map(str, config['hidden_size']))} -> Output({num_classes})\")\n",
    "    print(f\"Learning rate: {config['lr']}, Epochs: {config['epochs']}, Dropout: {config['dropout']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = LinearModel(\n",
    "        input_size=input_size,\n",
    "        output_size=num_classes,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    model.load(f'models/{dataset_name}/{model_name}.pth')\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "    test_loss, test_accuracy, model_test_accuracy = test(model, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(model_test_accuracy)\n",
    "    renormal_result['model_sparsity'].append(0.0)\n",
    "\n",
    "    row_pruning_renormalize, renormalize_neff = model_pr(model, renormalize=True)\n",
    "    row_pruning, neff = model_pr(model, renormalize=False)\n",
    "\n",
    "    # Test the pruned models\n",
    "    test_loss, test_accuracy, accuracy_mean = test(row_pruning_renormalize, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(accuracy_mean)\n",
    "    renormal_result['model_sparsity'].append(model_sparsity(row_pruning_renormalize))\n",
    "\n",
    "    test_loss, test_accuracy, accuracy_mean = test(row_pruning, device, test_loader, times=5)\n",
    "    renormal_result['test_accuracy'].append(accuracy_mean)\n",
    "    renormal_result['model_sparsity'].append(model_sparsity(row_pruning))\n",
    "\n",
    "    print(f\"Model Name: {model_name}, Test Accuracy: {model_test_accuracy:.2f}%\")\n",
    "    print(f\"Renormalized Model test accuracy: {renormal_result['test_accuracy'][-2]:.2f}%, Sparsity: {renormal_result['model_sparsity'][-2]:.2f}\")\n",
    "    print(f\"Model test accuracy: {renormal_result['test_accuracy'][-1]:.2f}%, Sparsity: {renormal_result['model_sparsity'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387bcaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
